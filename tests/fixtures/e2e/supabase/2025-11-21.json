{
	"date": "2025-11-21",
	"commits": [
		{
			"sha": "2023b2632a6b977a1e73056fa9103e3c103c85c9",
			"message": "Chore: added RLS tests  (#40689)\n\n* added RLS tests\n\n* removed index clicking for label and added unrestricted tests\n\n* updated PR feedback",
			"user": "awaseem",
			"timestamp": "2025-11-21T20:10:47Z",
			"author": {
				"name": "Ali Waseem",
				"email": "waseema393@gmail.com",
				"username": "awaseem"
			},
			"files": {
				"added": ["e2e/studio/features/rls-policies.spec.ts"],
				"modified": [
					"apps/studio/components/interfaces/Auth/Policies/Policies.tsx",
					"apps/studio/components/interfaces/Auth/Policies/PolicyTableRow/PolicyRow.tsx",
					"apps/studio/components/interfaces/Auth/Policies/PolicyTableRow/PolicyTableRowHeader.tsx",
					"e2e/studio/playwright.config.ts"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Auth/Policies/Policies.tsx b/apps/studio/components/interfaces/Auth/Policies/Policies.tsx\nindex 8be311b6446c7..c1a02eae47390 100644\n--- a/apps/studio/components/interfaces/Auth/Policies/Policies.tsx\n+++ b/apps/studio/components/interfaces/Auth/Policies/Policies.tsx\n@@ -154,7 +154,12 @@ export const Policies = ({\n             {tables.map((table) => {\n               const isVisible = visibleTableIds.has(table.id)\n               return (\n-                <section key={table.id} hidden={!isVisible} aria-hidden={!isVisible}>\n+                <section\n+                  key={table.id}\n+                  hidden={!isVisible}\n+                  aria-hidden={!isVisible}\n+                  data-testid={`policy-table-${table.name}`}\n+                >\n                   <PolicyTableRow\n                     table={table}\n                     isLocked={schema === 'realtime' ? true : isLocked}\ndiff --git a/apps/studio/components/interfaces/Auth/Policies/PolicyTableRow/PolicyRow.tsx b/apps/studio/components/interfaces/Auth/Policies/PolicyTableRow/PolicyRow.tsx\nindex c938d273cd164..cae263d3abc62 100644\n--- a/apps/studio/components/interfaces/Auth/Policies/PolicyTableRow/PolicyRow.tsx\n+++ b/apps/studio/components/interfaces/Auth/Policies/PolicyTableRow/PolicyRow.tsx\n@@ -111,7 +111,12 @@ export const PolicyRow = ({\n         {!isLocked && (\n           <DropdownMenu>\n             <DropdownMenuTrigger asChild>\n-              <Button type=\"default\" className=\"px-1.5\" icon={<MoreVertical />} />\n+              <Button\n+                type=\"default\"\n+                className=\"px-1.5\"\n+                icon={<MoreVertical />}\n+                data-testid={`policy-${policy.name}-actions-button`}\n+              />\n             </DropdownMenuTrigger>\n             <DropdownMenuContent side=\"bottom\" align=\"end\" className=\"w-52\">\n               <DropdownMenuItem className=\"gap-x-2\" onClick={() => onSelectEditPolicy(policy)}>\ndiff --git a/apps/studio/components/interfaces/Auth/Policies/PolicyTableRow/PolicyTableRowHeader.tsx b/apps/studio/components/interfaces/Auth/Policies/PolicyTableRow/PolicyTableRowHeader.tsx\nindex 7c83c698b1ec5..341c60d06d619 100644\n--- a/apps/studio/components/interfaces/Auth/Policies/PolicyTableRow/PolicyTableRowHeader.tsx\n+++ b/apps/studio/components/interfaces/Auth/Policies/PolicyTableRow/PolicyTableRowHeader.tsx\n@@ -74,6 +74,7 @@ export const PolicyTableRowHeader = ({\n                 type=\"default\"\n                 disabled={!canToggleRLS}\n                 onClick={() => onSelectToggleRLS(table)}\n+                data-testid={`${table.name}-toggle-rls`}\n                 tooltip={{\n                   content: {\n                     side: 'bottom',\n@@ -90,6 +91,7 @@ export const PolicyTableRowHeader = ({\n               type=\"default\"\n               disabled={!canToggleRLS || !canCreatePolicies}\n               onClick={() => onSelectCreatePolicy(table)}\n+              data-testid={`${table.name}-create-policy`}\n               tooltip={{\n                 content: {\n                   side: 'bottom',\ndiff --git a/e2e/studio/features/rls-policies.spec.ts b/e2e/studio/features/rls-policies.spec.ts\nnew file mode 100644\nindex 0000000000000..3615d61618e45\n--- /dev/null\n+++ b/e2e/studio/features/rls-policies.spec.ts\n@@ -0,0 +1,441 @@\n+import { expect, Page } from '@playwright/test'\n+import { test } from '../utils/test.js'\n+import { toUrl } from '../utils/to-url.js'\n+import { createApiResponseWaiter, waitForApiResponse } from '../utils/wait-for-response.js'\n+\n+const policyTableName = 'pw_rls_policy_test_table'\n+const policySelectName = 'pw_test_select_policy'\n+const policyInsertName = 'pw_test_insert_policy'\n+const policyUpdateName = 'pw_test_update_policy'\n+const policyDeleteName = 'pw_test_delete_policy'\n+\n+/**\n+ * Helper function to create a test table for RLS policies\n+ */\n+const createTestTable = async (page: Page, ref: string) => {\n+  await page.goto(toUrl(`/project/${ref}/editor`))\n+  await page.waitForTimeout(1000)\n+\n+  // Check if table already exists\n+  const tableExists =\n+    (await page.getByRole('button', { name: `View ${policyTableName}` }).count()) > 0\n+\n+  if (!tableExists) {\n+    await page.getByRole('button', { name: 'New table', exact: true }).click()\n+    await page.getByTestId('table-name-input').fill(policyTableName)\n+    await page.getByRole('button', { name: 'Save' }).click()\n+\n+    await expect(\n+      page.getByText(`Table ${policyTableName} is good to go!`),\n+      'Table creation confirmation should be visible'\n+    ).toBeVisible({ timeout: 50000 })\n+  }\n+}\n+\n+/**\n+ * Helper function to delete the test table\n+ */\n+const deleteTestTable = async (page: Page, ref: string) => {\n+  await page.goto(toUrl(`/project/${ref}/editor`))\n+  await page.waitForTimeout(1000)\n+\n+  const tableExists =\n+    (await page.getByRole('button', { name: `View ${policyTableName}` }).count()) > 0\n+\n+  if (tableExists) {\n+    await page.getByLabel(`View ${policyTableName}`).nth(0).click()\n+    // Open the row actions menu (three dots) using the same selector pattern as table-editor.spec.ts.\n+    // This avoids brittle index-based selection and ignores the Unrestricted badge button.\n+    await page\n+      .getByLabel(`View ${policyTableName}`)\n+      .locator('button[aria-haspopup=\"menu\"]')\n+      .click({ force: true })\n+    await page.getByText('Delete table').click()\n+    await page.getByRole('checkbox', { name: 'Drop table with cascade?' }).click()\n+    await page.getByRole('button', { name: 'Delete' }).click()\n+\n+    await expect(\n+      page.getByText(`Successfully deleted table \"${policyTableName}\"`),\n+      'Table deletion confirmation should be visible'\n+    ).toBeVisible({ timeout: 50000 })\n+  }\n+}\n+\n+/**\n+ * Helper function to navigate to policies page and wait for it to load\n+ */\n+const navigateToPoliciesPage = async (page: Page, ref: string) => {\n+  const wait = createApiResponseWaiter(page, 'pg-meta', ref, 'policies')\n+  await page.goto(toUrl(`/project/${ref}/auth/policies`))\n+  await wait\n+  await page.waitForTimeout(500)\n+}\n+\n+/**\n+ * Helper function to delete a policy if it exists\n+ */\n+const deletePolicyIfExists = async (page: Page, ref: string, policyNameToDelete: string) => {\n+  // Look for the policy in the table\n+  const policyButton = page.getByRole('button', { name: policyNameToDelete })\n+  const policyExists = (await policyButton.count()) > 0\n+\n+  if (policyExists) {\n+    // Click the policy row actions button\n+    await page.getByTestId(`policy-${policyNameToDelete}-actions-button`).click()\n+    await page.waitForTimeout(200)\n+\n+    // Click delete\n+    await page.getByText('Delete', { exact: true }).click()\n+    await page.waitForTimeout(200)\n+\n+    const waitForDeletion = waitForApiResponse(page, 'pg-meta', ref, 'query?key=')\n+    // Confirm deletion\n+    await page.getByRole('button', { name: 'Delete' }).click()\n+\n+    // Wait for deletion to complete\n+    await waitForDeletion\n+\n+    await expect(\n+      page.getByText('Successfully removed policy'),\n+      'Policy deletion confirmation should be visible'\n+    ).toBeVisible({ timeout: 50000 })\n+\n+    await page.waitForTimeout(500)\n+  }\n+}\n+\n+test.describe.serial('RLS Policies', () => {\n+  let page: Page\n+\n+  test.beforeAll(async ({ browser, ref }) => {\n+    page = await browser.newPage()\n+\n+    // Create test table\n+    await createTestTable(page, ref)\n+\n+    // Navigate to policies page\n+    await navigateToPoliciesPage(page, ref)\n+  })\n+\n+  test.afterAll(async ({ ref }) => {\n+    // Clean up: delete test table\n+    await deleteTestTable(page, ref)\n+    await page.close()\n+  })\n+\n+  test.describe('Policies Page', () => {\n+    test('should display policies page correctly', async ({ ref }) => {\n+      await navigateToPoliciesPage(page, ref)\n+\n+      // Check page elements\n+      await expect(page.getByRole('heading', { name: 'Policies' })).toBeVisible()\n+      await expect(\n+        page.getByText('Manage Row Level Security policies for your tables')\n+      ).toBeVisible()\n+\n+      // Check schema selector is present\n+      await expect(page.getByRole('button', { name: 'schema public' })).toBeVisible()\n+\n+      // Check search/filter input is present\n+      await expect(page.getByPlaceholder('Filter tables and policies')).toBeVisible()\n+\n+      // Check the test table is visible\n+      await expect(page.getByText(policyTableName)).toBeVisible()\n+    })\n+\n+    test('should filter tables and policies by search', async ({ ref }) => {\n+      await navigateToPoliciesPage(page, ref)\n+\n+      const searchInput = page.getByPlaceholder('Filter tables and policies')\n+\n+      // Search for the test table\n+      await searchInput.fill(policyTableName)\n+      await page.waitForTimeout(500)\n+\n+      // Test table should be visible\n+      await expect(page.getByText(policyTableName)).toBeVisible()\n+\n+      // Clear search\n+      await searchInput.fill('')\n+      await page.waitForTimeout(500)\n+    })\n+\n+    test('should switch between schemas', async ({ ref }) => {\n+      await navigateToPoliciesPage(page, ref)\n+\n+      // Click schema selector\n+      await page.getByRole('button', { name: 'schema public' }).click()\n+\n+      // Select auth schema\n+      await page.getByRole('option', { name: 'auth' }).click()\n+      await page.waitForTimeout(1000)\n+\n+      // Should see auth schema tables\n+      await expect(page.getByRole('heading', { name: 'users', exact: true })).toBeVisible()\n+\n+      // Switch back to public\n+      await page.getByRole('button', { name: 'schema auth' }).click()\n+      await page.getByRole('option', { name: 'public', exact: true }).click()\n+      await page.waitForTimeout(1000)\n+    })\n+  })\n+\n+  test.describe('Table editor RLS badge', () => {\n+    test('shows Unrestricted badge when RLS is disabled for public table', async ({ ref }) => {\n+      // First, ensure RLS is disabled for the test table via the Policies page\n+      await navigateToPoliciesPage(page, ref)\n+\n+      // Wait for the test table row to appear in the policies list\n+      await expect(\n+        page.getByRole('heading', { name: policyTableName, exact: true }),\n+        'Test table heading should be visible on policies page'\n+      ).toBeVisible({ timeout: 50000 })\n+\n+      const toggleRlsButton = page.getByTestId(`${policyTableName}-toggle-rls`)\n+\n+      // If RLS is currently enabled, the toggle button label will be \"Disable RLS\"\n+      const toggleLabel = (await toggleRlsButton.innerText()) ?? ''\n+      if (toggleLabel.includes('Disable RLS')) {\n+        await toggleRlsButton.click()\n+\n+        // A confirmation modal appears when toggling RLS from the policies page\n+        await expect(\n+          page.getByRole('heading', { name: 'Confirm to disable Row Level Security' }),\n+          'RLS disable confirmation modal should appear'\n+        ).toBeVisible({ timeout: 50000 })\n+\n+        // Confirm disabling RLS\n+        await page.getByRole('button', { name: 'Confirm' }).click()\n+\n+        // After confirming, the toggle button text should change to \"Enable RLS\"\n+        await expect(\n+          toggleRlsButton,\n+          'Toggle should switch to \"Enable RLS\" after disabling RLS'\n+        ).toHaveText(/Enable RLS/, { timeout: 50000 })\n+      }\n+\n+      // Navigate to the table editor for the public schema so we can see the sidebar badge\n+      await page.goto(toUrl(`/project/${ref}/editor?schema=public`))\n+      await page.waitForTimeout(1000)\n+\n+      // In the table sidebar, the test table should have an \"Unrestricted\" badge\n+      const tableRow = page.getByRole('button', { name: `View ${policyTableName}` })\n+      await expect(\n+        tableRow,\n+        'Test table should be visible in the table editor sidebar'\n+      ).toBeVisible({ timeout: 50000 })\n+\n+      const unrestrictedBadge = tableRow.getByText('Unrestricted', { exact: true })\n+      await expect(\n+        unrestrictedBadge,\n+        'Unrestricted badge should be visible for public tables with RLS disabled'\n+      ).toBeVisible({ timeout: 50000 })\n+\n+      // Hover the badge to verify the tooltip explains the risk\n+      await unrestrictedBadge.hover()\n+      await expect(\n+        page.getByText(/Data is publicly accessible via API/i),\n+        'Tooltip should describe unrestricted public access when RLS is disabled'\n+      ).toBeVisible({ timeout: 10000 })\n+    })\n+  })\n+\n+  test.describe('Create RLS Policy', () => {\n+    test('should create a SELECT policy successfully', async ({ ref }) => {\n+      await navigateToPoliciesPage(page, ref)\n+\n+      // Delete policy if it exists from previous run\n+      await deletePolicyIfExists(page, ref, policySelectName)\n+\n+      // Find the test table and click \"Create policy\"\n+      await page.getByTestId(`${policyTableName}-create-policy`).click()\n+\n+      // Wait for dialog to open\n+      await expect(\n+        page.getByRole('heading', { name: 'Create a new Row Level Security policy' }),\n+        'Policy creation dialog should open'\n+      ).toBeVisible()\n+\n+      // Fill in policy name\n+      await page.getByRole('textbox', { name: 'Policy Name' }).fill(policySelectName)\n+\n+      // Verify the table is already selected (should be the table we clicked from)\n+      await expect(page.getByRole('button', { name: `public.${policyTableName}` })).toBeVisible()\n+\n+      // SELECT should be selected by default\n+      await expect(page.getByRole('radio', { name: 'SELECT' })).toBeChecked()\n+\n+      // Fill in USING clause - allow all access\n+      const editor = page.getByRole('textbox', { name: 'Editor content;Press Alt+F1' })\n+      await editor.fill('true')\n+\n+      // Save policy\n+      await page.getByRole('button', { name: 'Save policy' }).click()\n+\n+      // Wait for success message\n+      await expect(\n+        page.getByText('Successfully created new policy'),\n+        'Policy creation success message should be visible'\n+      ).toBeVisible({ timeout: 50000 })\n+\n+      // Verify policy appears in the list\n+      await expect(page.getByRole('button', { name: policySelectName })).toBeVisible()\n+\n+      // Verify policy details\n+      const policyRow = page.locator(`tr:has-text(\"${policySelectName}\")`)\n+      await expect(policyRow.locator('code').filter({ hasText: /^SELECT$/ })).toBeVisible()\n+      await expect(policyRow.locator('code').filter({ hasText: /^public$/ })).toBeVisible()\n+    })\n+\n+    test('should create an INSERT policy with authenticated role', async ({ ref }) => {\n+      await navigateToPoliciesPage(page, ref)\n+\n+      // Delete policy if it exists\n+      await deletePolicyIfExists(page, ref, policyInsertName)\n+\n+      // Open create policy dialog\n+      await page.getByTestId(`${policyTableName}-create-policy`).click()\n+\n+      await expect(\n+        page.getByRole('heading', { name: 'Create a new Row Level Security policy' })\n+      ).toBeVisible()\n+\n+      // Fill in policy name\n+      await page.getByRole('textbox', { name: 'Policy Name' }).fill(policyInsertName)\n+\n+      // Select INSERT command\n+      await page.getByRole('radio', { name: 'INSERT' }).click()\n+\n+      // Select target role - authenticated\n+      await page.getByText('Defaults to all (public) roles if none selected').click()\n+      await page.getByRole('option', { name: 'authenticated' }).click()\n+\n+      // Close the dropdown\n+      await page.keyboard.press('Escape')\n+\n+      // Fill in WITH CHECK clause - allow all inserts\n+      const editor = page.getByRole('textbox', { name: 'Editor content;Press Alt+F1' })\n+      await editor.fill('true')\n+\n+      // Save policy\n+      await page.getByRole('button', { name: 'Save policy' }).click()\n+\n+      // Wait for success\n+      await expect(page.getByText('Successfully created new policy')).toBeVisible({\n+        timeout: 50000,\n+      })\n+\n+      // Verify policy appears with correct details\n+      await expect(page.getByRole('button', { name: policyInsertName })).toBeVisible()\n+      const policyRow = page.locator(`tr:has-text(\"${policyInsertName}\")`)\n+      await expect(policyRow.locator('code').filter({ hasText: /^INSERT$/ })).toBeVisible()\n+      await expect(policyRow.locator('code').filter({ hasText: /^authenticated$/ })).toBeVisible()\n+    })\n+\n+    test('should create an UPDATE policy with custom condition', async ({ ref }) => {\n+      await navigateToPoliciesPage(page, ref)\n+\n+      // Delete policy if it exists\n+      await deletePolicyIfExists(page, ref, policyUpdateName)\n+\n+      // Open create policy dialog\n+      await page.getByTestId(`${policyTableName}-create-policy`).click()\n+\n+      await expect(\n+        page.getByRole('heading', { name: 'Create a new Row Level Security policy' })\n+      ).toBeVisible()\n+\n+      // Fill in policy name\n+      await page.getByRole('textbox', { name: 'Policy Name' }).fill(policyUpdateName)\n+\n+      // Select UPDATE command\n+      await page.getByRole('radio', { name: 'UPDATE' }).click()\n+\n+      // Select authenticated role\n+      await page.getByText('Defaults to all (public) roles if none selected').click()\n+      await page.getByRole('option', { name: 'authenticated' }).click()\n+      await page.keyboard.press('Escape')\n+\n+      // Fill in USING clause (UPDATE has both USING and WITH CHECK editors, so use first)\n+      const editor = page.getByRole('textbox', { name: 'Editor content;Press Alt+F1' }).first()\n+      await editor.fill('true')\n+\n+      // Save policy\n+      await page.getByRole('button', { name: 'Save policy' }).click()\n+\n+      // Wait for success\n+      await expect(page.getByText('Successfully created new policy')).toBeVisible({\n+        timeout: 50000,\n+      })\n+\n+      // Verify policy appears\n+      await expect(page.getByRole('button', { name: policyUpdateName })).toBeVisible()\n+      const policyRow = page.locator(`tr:has-text(\"${policyUpdateName}\")`)\n+      await expect(policyRow.locator('code').filter({ hasText: /^UPDATE$/ })).toBeVisible()\n+    })\n+\n+    test('should create a DELETE policy', async ({ ref }) => {\n+      await navigateToPoliciesPage(page, ref)\n+\n+      // Delete policy if it exists\n+      await deletePolicyIfExists(page, ref, policyDeleteName)\n+\n+      // Open create policy dialog\n+      await page.getByTestId(`${policyTableName}-create-policy`).click()\n+\n+      await expect(\n+        page.getByRole('heading', { name: 'Create a new Row Level Security policy' })\n+      ).toBeVisible()\n+\n+      // Fill in policy name\n+      await page.getByRole('textbox', { name: 'Policy Name' }).fill(policyDeleteName)\n+\n+      // Select DELETE command\n+      await page.getByRole('radio', { name: 'DELETE' }).click()\n+\n+      // Select authenticated role\n+      await page.getByText('Defaults to all (public) roles if none selected').click()\n+      await page.getByRole('option', { name: 'authenticated' }).click()\n+      await page.keyboard.press('Escape')\n+\n+      // Fill in USING clause\n+      const editor = page.getByRole('textbox', { name: 'Editor content;Press Alt+F1' })\n+      await editor.fill('true')\n+\n+      // Save policy\n+      await page.getByRole('button', { name: 'Save policy' }).click()\n+\n+      // Wait for success\n+      await expect(page.getByText('Successfully created new policy')).toBeVisible({\n+        timeout: 50000,\n+      })\n+\n+      // Verify policy appears\n+      await expect(page.getByRole('button', { name: policyDeleteName })).toBeVisible()\n+      const policyRow = page.locator(`tr:has-text(\"${policyDeleteName}\")`)\n+      await expect(policyRow.locator('code').filter({ hasText: /^DELETE$/ })).toBeVisible()\n+    })\n+\n+    test('should cancel policy creation', async ({ ref }) => {\n+      await navigateToPoliciesPage(page, ref)\n+\n+      // Open create policy dialog\n+      await page.getByTestId(`${policyTableName}-create-policy`).click()\n+\n+      await expect(\n+        page.getByRole('heading', { name: 'Create a new Row Level Security policy' })\n+      ).toBeVisible()\n+\n+      // Fill in some data\n+      await page.getByRole('textbox', { name: 'Policy Name' }).fill('policy_to_cancel')\n+\n+      // Click cancel\n+      await page.getByRole('button', { name: 'Cancel' }).click()\n+\n+      // Dialog should close\n+      await expect(\n+        page.getByRole('heading', { name: 'Create a new Row Level Security policy' })\n+      ).not.toBeVisible()\n+    })\n+  })\n+})\ndiff --git a/e2e/studio/playwright.config.ts b/e2e/studio/playwright.config.ts\nindex b99cb159e6100..abf43c3bc9a60 100644\n--- a/e2e/studio/playwright.config.ts\n+++ b/e2e/studio/playwright.config.ts\n@@ -58,5 +58,6 @@ export default defineConfig({\n     command: 'pnpm --workspace-root run e2e:setup',\n     port: WEB_SERVER_PORT,\n     timeout: WEB_SERVER_TIMEOUT,\n+    reuseExistingServer: true,\n   },\n })\n",
			"diffSize": 20666,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "5d3493914a1512dc370df0869c25dec27f267ead",
			"message": "Fix: added check to ensure github is connected before showing the logo on branch (#40687)\n\nadded check to ensure github is connected before showing the logo on branch",
			"user": "awaseem",
			"timestamp": "2025-11-21T19:48:53Z",
			"author": {
				"name": "Ali Waseem",
				"email": "waseema393@gmail.com",
				"username": "awaseem"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/BranchManagement/BranchPanels.tsx",
					"apps/studio/components/interfaces/BranchManagement/Overview.tsx",
					"apps/studio/pages/project/[ref]/branches/index.tsx",
					"apps/studio/pages/project/[ref]/branches/merge-requests.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/BranchManagement/BranchPanels.tsx b/apps/studio/components/interfaces/BranchManagement/BranchPanels.tsx\nindex 55285d3368d81..629739d8ef42b 100644\n--- a/apps/studio/components/interfaces/BranchManagement/BranchPanels.tsx\n+++ b/apps/studio/components/interfaces/BranchManagement/BranchPanels.tsx\n@@ -62,6 +62,7 @@ interface BranchRowProps {\n   repo: string\n   label?: string | ReactNode\n   branch: Branch\n+  isGithubConnected: boolean\n   rowLink?: string\n   external?: boolean\n   rowActions?: ReactNode\n@@ -69,6 +70,7 @@ interface BranchRowProps {\n \n export const BranchRow = ({\n   branch,\n+  isGithubConnected,\n   label,\n   repo,\n   rowLink,\n@@ -87,7 +89,7 @@ export const BranchRow = ({\n   return (\n     <div className=\"w-full flex items-center justify-between px-4 py-2.5 hover:bg-surface-100\">\n       <div className=\"flex items-center gap-x-3\">\n-        {branch.git_branch && (\n+        {branch.git_branch && isGithubConnected && (\n           <ButtonTooltip\n             asChild\n             type=\"default\"\ndiff --git a/apps/studio/components/interfaces/BranchManagement/Overview.tsx b/apps/studio/components/interfaces/BranchManagement/Overview.tsx\nindex 64ef6818baefa..11b3b5f781f01 100644\n--- a/apps/studio/components/interfaces/BranchManagement/Overview.tsx\n+++ b/apps/studio/components/interfaces/BranchManagement/Overview.tsx\n@@ -38,6 +38,7 @@ import { EditBranchModal } from './EditBranchModal'\n import { PreviewBranchesEmptyState } from './EmptyStates'\n \n interface OverviewProps {\n+  isGithubConnected: boolean\n   isLoading: boolean\n   isSuccess: boolean\n   repo: string\n@@ -49,6 +50,7 @@ interface OverviewProps {\n }\n \n export const Overview = ({\n+  isGithubConnected,\n   isLoading,\n   isSuccess,\n   repo,\n@@ -71,6 +73,7 @@ export const Overview = ({\n         {isSuccess && mainBranch !== undefined && (\n           <BranchRow\n             branch={mainBranch}\n+            isGithubConnected={isGithubConnected}\n             label={\n               <div className=\"flex items-center gap-x-2\">\n                 <Shield size={14} strokeWidth={1.5} className=\"text-warning\" />\n@@ -109,6 +112,7 @@ export const Overview = ({\n           persistentBranches.map((branch) => {\n             return (\n               <BranchRow\n+                isGithubConnected={isGithubConnected}\n                 key={branch.id}\n                 repo={repo}\n                 branch={branch}\n@@ -135,6 +139,7 @@ export const Overview = ({\n           ephemeralBranches.map((branch) => {\n             return (\n               <BranchRow\n+                isGithubConnected={isGithubConnected}\n                 key={branch.id}\n                 repo={repo}\n                 branch={branch}\ndiff --git a/apps/studio/pages/project/[ref]/branches/index.tsx b/apps/studio/pages/project/[ref]/branches/index.tsx\nindex c7ef6910775bd..5805ad4ce2e9c 100644\n--- a/apps/studio/pages/project/[ref]/branches/index.tsx\n+++ b/apps/studio/pages/project/[ref]/branches/index.tsx\n@@ -77,6 +77,8 @@ const BranchesPage: NextPageWithLayout = () => {\n   const isLoading = isLoadingConnections || isLoadingBranches\n   const isSuccess = isSuccessConnections && isSuccessBranches\n \n+  const isGithubConnected = githubConnection !== undefined\n+\n   const { mutate: deleteBranch, isPending: isDeleting } = useBranchDeleteMutation({\n     onSuccess: () => {\n       toast.success('Successfully deleted branch')\n@@ -145,6 +147,7 @@ const BranchesPage: NextPageWithLayout = () => {\n \n                   {!isError && (\n                     <Overview\n+                      isGithubConnected={isGithubConnected}\n                       isLoading={isLoading}\n                       isSuccess={isSuccess}\n                       repo={repo}\ndiff --git a/apps/studio/pages/project/[ref]/branches/merge-requests.tsx b/apps/studio/pages/project/[ref]/branches/merge-requests.tsx\nindex f045acb4a0ca8..ebed655e87705 100644\n--- a/apps/studio/pages/project/[ref]/branches/merge-requests.tsx\n+++ b/apps/studio/pages/project/[ref]/branches/merge-requests.tsx\n@@ -89,6 +89,8 @@ const MergeRequestsPage: NextPageWithLayout = () => {\n \n   const isError = isErrorConnections || isErrorBranches\n \n+  const isGithubConnected = githubConnection !== undefined\n+\n   const { mutate: sendEvent } = useSendEventMutation()\n \n   const { mutate: updateBranch, isPending: isUpdating } = useBranchUpdateMutation({\n@@ -228,6 +230,7 @@ const MergeRequestsPage: NextPageWithLayout = () => {\n                             : `/project/${branch.project_ref}/merge`\n                           return (\n                             <BranchRow\n+                              isGithubConnected={isGithubConnected}\n                               key={branch.id}\n                               label={\n                                 <div className=\"flex items-center gap-x-4\">\n",
			"diffSize": 4827,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "b3746282165ec5ea7ab7886967cc547fc2d7d069",
			"message": "Chore/small fix vectors (#40693)\n\n* Flip vectors enabled features to true\n\n* Fix enabled logic",
			"user": "joshenlim",
			"timestamp": "2025-11-21T18:19:04Z",
			"author": {
				"name": "Joshen Lim",
				"email": "joshenlimek@gmail.com",
				"username": "joshenlim"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/Storage/StorageMenuV2.tsx",
					"apps/studio/data/config/project-storage-config-query.ts",
					"packages/common/enabled-features/enabled-features.json"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Storage/StorageMenuV2.tsx b/apps/studio/components/interfaces/Storage/StorageMenuV2.tsx\nindex 3e2a5b6b64bc6..7a86d184d62e8 100644\n--- a/apps/studio/components/interfaces/Storage/StorageMenuV2.tsx\n+++ b/apps/studio/components/interfaces/Storage/StorageMenuV2.tsx\n@@ -5,6 +5,7 @@ import {\n   useIsAnalyticsBucketsEnabled,\n   useIsVectorBucketsEnabled,\n } from 'data/config/project-storage-config-query'\n+import { useIsFeatureEnabled } from 'hooks/misc/useIsFeatureEnabled'\n import { Badge, Menu } from 'ui'\n import { BUCKET_TYPES } from './Storage.constants'\n import { useStorageV2Page } from './Storage.utils'\n@@ -13,38 +14,47 @@ export const StorageMenuV2 = () => {\n   const { ref } = useParams()\n   const page = useStorageV2Page()\n \n+  const { storageAnalytics, storageVectors } = useIsFeatureEnabled([\n+    'storage:analytics',\n+    'storage:vectors',\n+  ])\n+\n   const isAnalyticsBucketsEnabled = useIsAnalyticsBucketsEnabled({ projectRef: ref })\n   const isVectorBucketsEnabled = useIsVectorBucketsEnabled({ projectRef: ref })\n \n+  const bucketTypes = Object.entries(BUCKET_TYPES).filter(([key, config]) => {\n+    if (key === 'analytics') return storageAnalytics\n+    if (key === 'vectors') return storageVectors\n+    return IS_PLATFORM || (!IS_PLATFORM && !config.platformOnly)\n+  })\n+\n   return (\n     <Menu type=\"pills\" className=\"my-6 flex flex-grow flex-col\">\n       <div className=\"space-y-6\">\n         <div className=\"mx-3\">\n           <Menu.Group title={<span className=\"uppercase font-mono\">Manage</span>} />\n \n-          {Object.entries(BUCKET_TYPES)\n-            .filter(([_, config]) => IS_PLATFORM || (!IS_PLATFORM && !config.platformOnly))\n-            .map(([type, config]) => {\n-              const isSelected = page === type\n-              const isAlphaEnabled =\n-                (type === 'analytics' && isAnalyticsBucketsEnabled) ||\n-                (type === 'vectors' && isVectorBucketsEnabled)\n+          {bucketTypes.map(([type, config]) => {\n+            const isSelected = page === type\n+            const isAlphaEnabled =\n+              (type === 'analytics' && isAnalyticsBucketsEnabled) ||\n+              (type === 'vectors' && isVectorBucketsEnabled)\n \n-              return (\n-                <Link key={type} href={`/project/${ref}/storage/${type}`}>\n-                  <Menu.Item rounded active={isSelected}>\n-                    <div className=\"flex items-center justify-between\">\n-                      <p className=\"truncate\">{config.displayName}</p>\n-                      {isAlphaEnabled && (\n-                        <Badge variant=\"default\" size=\"small\">\n-                          New\n-                        </Badge>\n-                      )}\n-                    </div>\n-                  </Menu.Item>\n-                </Link>\n-              )\n-            })}\n+            return (\n+              <Link key={type} href={`/project/${ref}/storage/${type}`}>\n+                <Menu.Item rounded active={isSelected}>\n+                  <div className=\"flex items-center justify-between\">\n+                    <p className=\"truncate\">{config.displayName}</p>\n+                    {isAlphaEnabled && (\n+                      <Badge variant=\"default\" size=\"small\">\n+                        New\n+                      </Badge>\n+                    )}\n+                  </div>\n+                </Menu.Item>\n+              </Link>\n+            )\n+          })}\n         </div>\n \n         {IS_PLATFORM && (\ndiff --git a/apps/studio/data/config/project-storage-config-query.ts b/apps/studio/data/config/project-storage-config-query.ts\nindex 3a789af2ce7dd..3b460103e9bbb 100644\n--- a/apps/studio/data/config/project-storage-config-query.ts\n+++ b/apps/studio/data/config/project-storage-config-query.ts\n@@ -3,7 +3,6 @@ import { useQuery } from '@tanstack/react-query'\n import { useFlag } from 'common'\n import { components } from 'data/api'\n import { get, handleError } from 'data/fetchers'\n-import { useIsFeatureEnabled } from 'hooks/misc/useIsFeatureEnabled'\n import { IS_PLATFORM } from 'lib/constants'\n import type { ResponseError, UseCustomQueryOptions } from 'types'\n import { configKeys } from './keys'\n@@ -55,15 +54,13 @@ export const useProjectStorageConfigQuery = <TData = ProjectStorageConfigData>(\n   })\n \n export const useIsAnalyticsBucketsEnabled = ({ projectRef }: { projectRef?: string }) => {\n-  const { storageAnalytics } = useIsFeatureEnabled(['storage:analytics'])\n   const { data } = useProjectStorageConfigQuery({ projectRef })\n   const isIcebergCatalogEnabled = !!data?.features.icebergCatalog?.enabled\n-  return storageAnalytics && isIcebergCatalogEnabled\n+  return isIcebergCatalogEnabled\n }\n \n export const useIsVectorBucketsEnabled = ({ projectRef }: { projectRef?: string }) => {\n-  const { storageVectors } = useIsFeatureEnabled(['storage:vectors'])\n   // [Joshen] Temp using feature flag - will need to shift to storage config like analytics bucket once ready\n   const isVectorBucketsEnabled = useFlag('storageAnalyticsVector')\n-  return storageVectors && isVectorBucketsEnabled\n+  return isVectorBucketsEnabled\n }\ndiff --git a/packages/common/enabled-features/enabled-features.json b/packages/common/enabled-features/enabled-features.json\nindex 5c5155fd6539a..e303f1b1ad78c 100644\n--- a/packages/common/enabled-features/enabled-features.json\n+++ b/packages/common/enabled-features/enabled-features.json\n@@ -122,7 +122,7 @@\n   \"sdk:swift\": true,\n \n   \"storage:analytics\": true,\n-  \"storage:vectors\": false,\n+  \"storage:vectors\": true,\n \n   \"search:fullIndex\": true,\n \n",
			"diffSize": 5579,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "e067920f6fe4c948131d71b4392f7939b4afc89c",
			"message": "re:invent landing page (#40683)\n\n* re:invent landing page\n\n* change day 1 name\n\n* add event entry\n\n* upd copy\n\n* upd links\n\n* format",
			"user": "stylessh",
			"timestamp": "2025-11-21T17:10:34Z",
			"author": {
				"name": "Alan Daniel",
				"email": "stylesshjs@gmail.com",
				"username": "stylessh"
			},
			"files": {
				"added": [
					"apps/www/_events/2025-12-01__aws-reinvent-2025.mdx",
					"apps/www/data/aws-reinvent-2025.tsx",
					"apps/www/pages/aws-reinvent-2025.tsx"
				],
				"modified": ["packages/ui/src/components/Button/Button.tsx"],
				"removed": []
			},
			"diff": "diff --git a/apps/www/_events/2025-12-01__aws-reinvent-2025.mdx b/apps/www/_events/2025-12-01__aws-reinvent-2025.mdx\nnew file mode 100644\nindex 0000000000000..0ffb77df42879\n--- /dev/null\n+++ b/apps/www/_events/2025-12-01__aws-reinvent-2025.mdx\n@@ -0,0 +1,107 @@\n+---\n+title: Supabase at AWS re:Invent 2025\n+subtitle: Build in a weekend. Scale to millions.\n+description: >-\n+  Join Supabase at AWS re:Invent 2025 in Las Vegas. Visit us at Booth #1857 for demos,\n+  daily giveaways, and exclusive networking events. Learn how to build AI-native applications\n+  with our open-source Postgres platform built on AWS. Features keynote appearance by \n+  Supabase CEO Paul Copplestone, exclusive cocktail reception with Felicis, and AI After Dark\n+  networking event with Vercel, Slack, and Baseten.\n+type: conference\n+onDemand: false\n+disable_page_build: false\n+link:\n+  href: '/aws-reinvent-2025'\n+  target: _self\n+main_cta:\n+  label: 'Book a meeting'\n+  url: 'https://forms.supabase.com/reinvent'\n+  target: _blank\n+date: '2025-12-01T16:00:00.000-08:00'\n+end_date: '2025-12-04T18:00:00.000-08:00'\n+timezone: America/Los_Angeles\n+duration: 4 days\n+location: 'Las Vegas, NV - Booth #1857'\n+categories:\n+  - conference\n+hosts:\n+  - name: Supabase\n+    avatar_url: 'https://github.com/supabase.png'\n+speakers: 'paul_copplestone'\n+og_image: '/images/events/aws-reinvent-2025-og.png'\n+tags:\n+  - aws\n+  - enterprise\n+  - conference\n+  - ai\n+  - networking\n+---\n+\n+## About AWS re:Invent 2025\n+\n+AWS re:Invent is the premier cloud computing conference where the global cloud community comes together to learn, connect, and be inspired. Join Supabase at this year's event to discover how our open-source Postgres platform, built on AWS, empowers developers to build and scale applications from prototype to production.\n+\n+### What to Expect at Our Booth\n+\n+Visit us at **Booth #1857** in the Expo Hall throughout the conference for:\n+\n+- **Live Demos**: See Supabase in action with real-world use cases\n+- **Daily Giveaways**: Enter to win exclusive Supabase swag and prizes\n+- **Expert Consultations**: Get your technical questions answered by our engineers\n+- **Free Enterprise Assessment**: Learn how to optimize your innovation workflow\n+\n+### Featured Events\n+\n+#### December 2 - Keynote Appearance\n+\n+Supabase CEO and Founder Paul Copplestone will be a featured guest in Mai-Lan Tomsen Bukovec's keynote at the Venetian, Palazzo Ballroom B (1:00 PM - 2:00 PM).\n+\n+#### December 2 - Exclusive Cocktail Reception\n+\n+Join us for an exclusive cocktail reception brought to you by Supabase and Felicis (5:30 PM - 8:30 PM). Limited space available - [apply to attend](https://forms.gle/supabase-felicis-reception).\n+\n+#### December 3 - AI After Dark\n+\n+Don't miss AI After Dark, brought to you by Supabase, Vercel, Slack, and Baseten (6:30 PM - 9:30 PM). Network with AI innovators and industry leaders. [Apply to attend](https://forms.gle/ai-after-dark).\n+\n+### Why Supabase?\n+\n+Supabase is the open-source Firebase alternative that gives you:\n+\n+- **100% Postgres Database**: No forks, just pure Postgres with all its power and extensions\n+- **Built-in Authentication**: Secure auth with social logins, magic links, and Row Level Security\n+- **Realtime Subscriptions**: Build collaborative apps with live data synchronization\n+- **Edge Functions**: Deploy serverless functions globally with Deno\n+- **Vector Embeddings**: Native pgvector support for AI/ML applications\n+- **Storage**: S3-compatible object storage for files, images, and videos\n+\n+### Powering the AI Revolution\n+\n+Supabase powers the world's leading AI coding agents, including:\n+\n+- Lovable\n+- Bolt\n+- Figma Make\n+- Vercel v0\n+\n+Learn how these teams leverage Supabase to build and scale AI-native applications.\n+\n+### Book Your Meeting\n+\n+Schedule a dedicated meeting with our team to discuss:\n+\n+- Your specific use case and requirements\n+- Architecture and scaling strategies\n+- Security and compliance needs\n+- Migration paths from other platforms\n+- Custom enterprise solutions\n+\n+[Book your meeting now](https://calendly.com/supabase-enterprise) to secure your spot.\n+\n+### Connect With Us\n+\n+- **Location**: Booth #1857, Expo Hall\n+- **Dates**: December 1-4, 2025\n+- **Daily Hours**: 10:00 AM - 6:00 PM (except Dec 1: 4:00 PM - 7:00 PM)\n+\n+Don't miss this opportunity to see how Supabase can accelerate your development and help you build in a weekend and scale to millions.\ndiff --git a/apps/www/data/aws-reinvent-2025.tsx b/apps/www/data/aws-reinvent-2025.tsx\nnew file mode 100644\nindex 0000000000000..b1554c59f1627\n--- /dev/null\n+++ b/apps/www/data/aws-reinvent-2025.tsx\n@@ -0,0 +1,427 @@\n+import { Calendar, MapPin, Users, Sparkles, Gift, MessageSquare, Timer, Check } from 'lucide-react'\n+import { CubeIcon } from '@heroicons/react/outline'\n+import { Image } from 'ui'\n+import dynamic from 'next/dynamic'\n+import MainProducts from './MainProducts'\n+import { PRODUCT_SHORTNAMES } from 'shared-data/products'\n+\n+const AuthVisual = dynamic(() => import('components/Products/AuthVisual'))\n+const FunctionsVisual = dynamic(() => import('components/Products/FunctionsVisual'))\n+const RealtimeVisual = dynamic(() => import('components/Products/RealtimeVisual'))\n+\n+export type EventScheduleItem = {\n+  date: string\n+  time: string\n+  title: string\n+  description?: string\n+  location?: string\n+  type: 'booth' | 'keynote' | 'networking' | 'giveaway'\n+  cta?: {\n+    label: string\n+    href: string\n+  }\n+}\n+\n+export type HeroSectionProps = {\n+  id?: string\n+  title: string\n+  subtitle?: string\n+  h1: React.ReactNode\n+  subheader: React.ReactNode[]\n+  image?: any\n+  ctas: Array<{\n+    label: string\n+    href: string\n+    type?:\n+      | 'primary'\n+      | 'secondary'\n+      | 'default'\n+      | 'alternative'\n+      | 'outline'\n+      | 'text'\n+      | 'link'\n+      | 'warning'\n+      | 'danger'\n+      | 'dashed'\n+      | null\n+      | undefined\n+  }>\n+}\n+\n+const data = {\n+  metadata: {\n+    metaTitle: 'Supabase at AWS re:Invent 2025 | December 1-4, Las Vegas',\n+    metaDescription:\n+      'Meet Supabase at AWS re:Invent 2025. Visit us at Booth #1857, join our exclusive events, and learn how to build in a weekend and scale to millions.',\n+  },\n+  heroSection: {\n+    id: 'hero',\n+    title: 'Supabase at AWS re:Invent 2025',\n+    h1: (\n+      <>\n+        <span className=\"block text-foreground lg:text-3xl lg:leading-[1.5]\">\n+          The complete Postgres platform.\n+        </span>\n+        <span className=\"block text-foreground lg:text-3xl lg:leading-[1.5]\">On AWS.</span>\n+      </>\n+    ),\n+    subheader: [\n+      <>\n+        December 1-4, 2025 — Las Vegas, NV —{' '}\n+        <span className=\"text-foreground font-medium\">Booth #1857</span>\n+      </>,\n+      <>\n+        Supabase is the open-source Postgres development platform built to run on AWS\n+        infrastructure. Get a complete backend with Database, Auth, Storage, Edge Functions, and\n+        Real-Time in minutes. Deploy globally across AWS regions with enterprise-grade security,\n+        compliance, and the performance AWS customers expect. Use Foreign Data Wrappers to connect\n+        to your existing AWS data stack.\n+      </>,\n+    ],\n+    ctas: [\n+      {\n+        label: 'Book a Meeting',\n+        href: 'https://forms.supabase.com/reinvent',\n+        type: 'primary' as const,\n+      },\n+      {\n+        label: 'Visit our Booth (#1857)',\n+        href: '#schedule',\n+        type: 'secondary' as const,\n+      },\n+    ],\n+  },\n+  consultationSection: {\n+    id: 'consultation',\n+    title: 'Free enterprise innovation assessment',\n+    description:\n+      'Get expert guidance from a Supabase Engineer on how to prototype faster, integrate securely, and scale with confidence.',\n+    features: [\n+      'Review of innovation workflow and infrastructure',\n+      'Guidance on adding AI-native tools to your stack',\n+      'Advice on how to go from prototype to production',\n+      'Recommendations on security, compliance, and scale',\n+      'Best practices from other innovation teams',\n+    ],\n+    cta: {\n+      label: 'Book your assessment',\n+      href: 'https://forms.supabase.com/reinvent',\n+    },\n+  },\n+  scheduleSection: {\n+    id: 'schedule',\n+    title: 'Where to find us at AWS re:Invent',\n+    subtitle: 'Join us for exclusive events, demos, and networking opportunities',\n+    schedule: [\n+      // December 1\n+      {\n+        date: 'December 01',\n+        time: '4:00 PM - 7:00 PM',\n+        title: 'Welcome to Day 1',\n+        description:\n+          'Meet us at Booth #1857. Watch a demo and collect your ticket for our Daily Giveaway.',\n+        location: 'Expo Hall - Booth #1857',\n+        type: 'booth',\n+      },\n+      // December 2\n+      {\n+        date: 'December 02',\n+        time: '10:00 AM - 6:00 PM',\n+        title: 'Welcome to Day 2',\n+        description:\n+          'Meet us at Booth #1857. Watch a demo and collect your ticket for our Daily Giveaway.',\n+        location: 'Expo Hall - Booth #1857',\n+        type: 'booth',\n+      },\n+      {\n+        date: 'December 02',\n+        time: '1:00 PM - 2:00 PM',\n+        title: 'AWS Keynote Feature',\n+        description:\n+          \"Supabase CEO and Founder Paul Copplestone will be a featured guest in Mai-Lan Tomsen Bukovec's keynote.\",\n+        location: 'Venetian, Palazzo Ballroom B',\n+        type: 'keynote',\n+      },\n+      {\n+        date: 'December 02',\n+        time: '5:30 PM - 8:30 PM',\n+        title: 'Exclusive Cocktail Reception',\n+        description: 'Exclusive cocktail reception brought to you by Supabase and Felicis.',\n+        location: 'Private Venue',\n+        type: 'networking',\n+        cta: {\n+          label: 'Apply to attend',\n+          href: 'https://gatsby.events/felicis/rsvp/register?e=aws-re-invent-reset-cocktails-and-conversation-with-supabase-tines-mother-duck-semgrep-felicis&ref=supabase',\n+        },\n+      },\n+      // December 3\n+      {\n+        date: 'December 03',\n+        time: '10:00 AM - 6:00 PM',\n+        title: 'Welcome to Day 3',\n+        description:\n+          'Meet us at Booth #1857. Watch a demo and collect your ticket for our Daily Giveaway.',\n+        location: 'Expo Hall - Booth #1857',\n+        type: 'booth',\n+      },\n+      {\n+        date: 'December 03',\n+        time: '6:30 PM - 9:30 PM',\n+        title: 'AI After Dark',\n+        description: 'AI After Dark. Brought to you by Supabase, Vercel, Slack, and Baseten.',\n+        location: 'Private Venue',\n+        type: 'networking',\n+        cta: {\n+          label: 'Apply to attend',\n+          href: 'https://luma.com/4nhjbjak?utm_source=supabase',\n+        },\n+      },\n+      // December 4\n+      {\n+        date: 'December 04',\n+        time: '10:00 AM - 6:00 PM',\n+        title: 'Final Day & Giveaway',\n+        description:\n+          'Meet us at Booth #1857. Watch a demo and collect your ticket for our Daily Giveaway.',\n+        location: 'Expo Hall - Booth #1857',\n+        type: 'booth',\n+      },\n+    ] as EventScheduleItem[],\n+  },\n+  platform: {\n+    id: 'postgres-platform',\n+    title: (\n+      <>\n+        Supabase helps you <span className=\"text-foreground\">build</span>\n+      </>\n+    ),\n+    subheading: 'Supabase includes everything you need to create the winning app.',\n+    features: [\n+      {\n+        id: 'database',\n+        title: 'Database',\n+        isDatabase: true,\n+        icon: MainProducts[PRODUCT_SHORTNAMES.DATABASE].icon,\n+        subheading: (\n+          <>\n+            <span className=\"text-foreground\">A fully managed Postgres database.</span>\n+            <br /> No forks: 100% pure Postgres.\n+          </>\n+        ),\n+        className: 'lg:col-span-2 flex-col lg:flex-row px-4 lg:pr-0',\n+        image: (\n+          <div className=\"relative w-full max-w-xl pt-8\">\n+            <div className=\"w-full h-full rounded-t-lg lg:rounded-tr-none overflow-hidden border-t border-l border-r lg:border-r-0 bg-surface-75\">\n+              <table className=\"min-w-full m-0\">\n+                <thead className=\"p-0\">\n+                  <tr className=\"border-b\">\n+                    <th className=\"py-2 px-4 text-left text-xs font-mono font-normal tracking-widest text-[#A0A0A0]\">\n+                      NAME\n+                    </th>\n+                    <th className=\"py-2 px-4 text-left text-xs font-mono font-normal tracking-widest text-[#A0A0A0]\">\n+                      PUBLICATION\n+                    </th>\n+                  </tr>\n+                </thead>\n+                <tbody className=\"bg-surface-100\">\n+                  {[\n+                    { name: 'Jon Meyers', pub: 'All', active: false },\n+                    { name: 'Chris Martin', pub: 'All', active: true },\n+                    { name: 'Amy Quek', pub: 'No', active: false },\n+                    { name: 'Riccardo Bussetti', pub: 'No', active: false },\n+                    { name: 'Beng Eu', pub: 'All', active: false },\n+                    { name: 'Tyler Hillery', pub: 'All', active: false },\n+                  ].map((row) => (\n+                    <tr\n+                      key={row.name}\n+                      className=\"group/row hover:bg-selection hover:text-foreground transition-colors cursor-pointer\"\n+                    >\n+                      <td className=\"py-2 px-4 whitespace-nowrap\">{row.name}</td>\n+                      <td className=\"py-2 px-4 whitespace-nowrap\">{row.pub}</td>\n+                    </tr>\n+                  ))}\n+                </tbody>\n+              </table>\n+            </div>\n+            <div\n+              className=\"\n+                absolute pointer-events-none\n+                w-full h-full\n+                inset-0 top-auto\n+                bg-[linear-gradient(to_bottom,transparent_0%,hsl(var(--background-default))_100%)]\n+              \"\n+            />\n+          </div>\n+        ),\n+        highlights: (\n+          <ul className=\"hidden lg:flex flex-col gap-1 text-sm\">\n+            <li>\n+              <Check className=\"inline text-foreground-light h-4 w-4\" /> 100% portable\n+            </li>\n+            <li>\n+              <Check className=\"inline text-foreground-light h-4 w-4\" /> Built-in Auth with RLS\n+            </li>\n+            <li>\n+              <Check className=\"inline text-foreground-light h-4 w-4\" /> Easy to extend\n+            </li>\n+          </ul>\n+        ),\n+      },\n+      {\n+        id: 'authentication',\n+        title: 'Authentication',\n+        icon: MainProducts[PRODUCT_SHORTNAMES.AUTHENTICATION].icon,\n+        subheading: (\n+          <>\n+            <span className=\"text-foreground\">Secure authentication</span> with email/password,\n+            magic links, OAuth (Google, GitHub, Twitter, etc.), SAML, SSO, and phone/SMS OTP.\n+          </>\n+        ),\n+        className: '!border-l-0 sm:!border-l sm:!border-t-0',\n+        image: <AuthVisual className=\"2xl:!-bottom-20\" />,\n+      },\n+      {\n+        id: 'rbac',\n+        title: 'Role-Based Access Control',\n+        icon: 'M17.6874 22.888V20.3886C17.6874 17.5888 15.4178 15.3192 12.618 15.3192C9.8182 15.3192 7.54852 17.5888 7.54852 20.3886V22.888M21.5531 11.5235C21.8189 14.1669 20.9393 16.9038 18.9141 18.9289C18.5359 19.3072 18.1328 19.6455 17.7101 19.9438M20.8038 8.70448C20.3598 7.71036 19.7299 6.77911 18.9141 5.96334C15.3338 2.38299 9.52889 2.38299 5.94855 5.96334C4.17501 7.73687 3.28 10.0562 3.26352 12.3807M24.0875 13.1161L23.2046 12.2332C22.3264 11.355 20.9026 11.355 20.0244 12.2332L19.1415 13.1161M0.875198 10.9503L1.75809 11.8331C2.63629 12.7113 4.06012 12.7113 4.93832 11.8331L5.82121 10.9503M7.49904 20.4919C5.77226 19.4557 4.37848 17.8555 3.62143 15.8584M15.6799 12.1942C15.6799 13.9201 14.2808 15.3192 12.5549 15.3192C10.829 15.3192 9.42993 13.9201 9.42993 12.1942C9.42993 10.4683 10.829 9.06917 12.5549 9.06917C14.2808 9.06917 15.6799 10.4683 15.6799 12.1942Z',\n+        subheading: <>Secure your data properly.</>,\n+        className: '!border-l-0',\n+        image: (\n+          <Image\n+            draggable={false}\n+            src={{\n+              dark: '/images/solutions/neon/rbac-dark.png',\n+              light: '/images/solutions/neon/rbac-light.png',\n+            }}\n+            alt=\"Role Based Access Control diagram\"\n+            width={100}\n+            height={100}\n+            quality={100}\n+            containerClassName=\"md:mb-4 -mt-12 sm:mt-0\"\n+          />\n+        ),\n+      },\n+      {\n+        id: 'realtime',\n+        title: 'Realtime',\n+        icon: MainProducts[PRODUCT_SHORTNAMES.REALTIME].icon,\n+        subheading: (\n+          <>\n+            Postgres replication enables{' '}\n+            <span className=\"text-foreground\">live sync functionality</span> for collaborative\n+            applications.\n+          </>\n+        ),\n+        className: '!border-l-0 sm:!border-l',\n+        image: (\n+          <RealtimeVisual className=\"[&_.visual-overlay]:bg-[linear-gradient(to_top,transparent_0%,transparent_50%,hsl(var(--background-default))_75%)]\" />\n+        ),\n+      },\n+      {\n+        id: 'storage',\n+        title: 'Storage',\n+        icon: MainProducts[PRODUCT_SHORTNAMES.STORAGE].icon,\n+        subheading: (\n+          <>\n+            <span className=\"text-foreground\">Scalable S3-compatible</span> object storage for\n+            managing files, images, and videos.\n+          </>\n+        ),\n+        className: '!border-l-0 lg:!border-l',\n+        image: (\n+          <Image\n+            draggable={false}\n+            src={{\n+              dark: '/images/solutions/neon/storage-dark.png',\n+              light: '/images/solutions/neon/storage-light.png',\n+            }}\n+            alt=\"Storage\"\n+            width={1000}\n+            height={1000}\n+            quality={100}\n+            containerClassName=\"md:mb-4\"\n+            className=\"opacity-[0.99]\"\n+            style={{\n+              imageRendering: 'revert-layer',\n+            }}\n+          />\n+        ),\n+      },\n+      {\n+        id: 'edge-functions',\n+        title: 'Edge Functions',\n+        icon: MainProducts[PRODUCT_SHORTNAMES.FUNCTIONS].icon,\n+        subheading: (\n+          <>\n+            Serverless functions <span className=\"text-foreground\">powered by Deno</span>, deployed\n+            globally for low-latency execution.\n+          </>\n+        ),\n+        className: '!border-l-0 sm:!border-l lg:!border-l-0',\n+        image: <FunctionsVisual className=\"\" />,\n+      },\n+      {\n+        id: 'vectors',\n+        title: 'Vectors',\n+        icon: 'M4.13477 12.8129C4.13477 14.1481 4.43245 15.4138 4.96506 16.5471M12.925 4.02271C11.5644 4.02271 10.276 4.33184 9.12614 4.88371M21.7152 12.8129C21.7152 11.4644 21.4115 10.1867 20.8688 9.0447M12.925 21.6032C14.2829 21.6032 15.5689 21.2952 16.717 20.7454M16.717 20.7454C17.2587 21.5257 18.1612 22.0366 19.1831 22.0366C20.84 22.0366 22.1831 20.6935 22.1831 19.0366C22.1831 17.3798 20.84 16.0366 19.1831 16.0366C17.5263 16.0366 16.1831 17.3798 16.1831 19.0366C16.1831 19.6716 16.3804 20.2605 16.717 20.7454ZM4.96506 16.5471C4.16552 17.086 3.63965 17.9999 3.63965 19.0366C3.63965 20.6935 4.98279 22.0366 6.63965 22.0366C8.2965 22.0366 9.63965 20.6935 9.63965 19.0366C9.63965 17.3798 8.2965 16.0366 6.63965 16.0366C6.01951 16.0366 5.44333 16.2248 4.96506 16.5471ZM9.12614 4.88371C8.58687 4.08666 7.67444 3.56274 6.63965 3.56274C4.98279 3.56274 3.63965 4.90589 3.63965 6.56274C3.63965 8.2196 4.98279 9.56274 6.63965 9.56274C8.2965 9.56274 9.63965 8.2196 9.63965 6.56274C9.63965 5.94069 9.45032 5.36285 9.12614 4.88371ZM20.8688 9.0447C21.6621 8.50486 22.1831 7.59464 22.1831 6.56274C22.1831 4.90589 20.84 3.56274 19.1831 3.56274C17.5263 3.56274 16.1831 4.90589 16.1831 6.56274C16.1831 8.2196 17.5263 9.56274 19.1831 9.56274C19.8081 9.56274 20.3884 9.37165 20.8688 9.0447Z',\n+        subheading: (\n+          <>\n+            <span className=\"text-foreground\">pgvector extension</span> for AI/ML applications,\n+            enabling fast semantic search and embedding storage.\n+          </>\n+        ),\n+        className: '!border-l-0 lg:!border-l',\n+        image: (\n+          <Image\n+            draggable={false}\n+            src={{\n+              dark: '/images/solutions/neon/vectors-dark.png',\n+              light: '/images/solutions/neon/vectors-light.png',\n+            }}\n+            alt=\"Vector embeddings\"\n+            width={100}\n+            height={100}\n+            quality={100}\n+          />\n+        ),\n+      },\n+      {\n+        id: 'row-level-security',\n+        title: 'Row Level Security',\n+        icon: '',\n+        subheading: (\n+          <>\n+            <span className=\"text-foreground\">Granular access control policies</span> to secure data\n+            at the row level.\n+          </>\n+        ),\n+        image: (\n+          <Image\n+            draggable={false}\n+            src={{\n+              dark: '/images/solutions/neon/rls-dark.svg',\n+              light: '/images/solutions/neon/rls-light.svg',\n+            }}\n+            alt=\"Row Level Security\"\n+            width={100}\n+            height={100}\n+            quality={100}\n+            containerClassName=\"-mt-8 sm:mt-0 mb-8\"\n+          />\n+        ),\n+      },\n+    ],\n+  },\n+  ctaSection: {\n+    id: 'cta',\n+    title: 'Take Supabase for a spin at Booth #1857',\n+    subtitle:\n+      'See how the fastest teams build and scale on Supabase. Get a demo, meet our team, and enter our daily giveaway.',\n+    cta: {\n+      label: 'Book a meeting',\n+      href: 'https://forms.supabase.com/reinvent',\n+    },\n+  },\n+}\n+\n+export default data\ndiff --git a/apps/www/pages/aws-reinvent-2025.tsx b/apps/www/pages/aws-reinvent-2025.tsx\nnew file mode 100644\nindex 0000000000000..ffe365344fec7\n--- /dev/null\n+++ b/apps/www/pages/aws-reinvent-2025.tsx\n@@ -0,0 +1,178 @@\n+import { NextPage } from 'next'\n+import dynamic from 'next/dynamic'\n+import { NextSeo } from 'next-seo'\n+import { Calendar, MapPin, Clock, Users, ChevronRight, CheckCircle } from 'lucide-react'\n+import Link from 'next/link'\n+import { Button, Badge } from 'ui'\n+\n+import Layout from 'components/Layouts/Default'\n+import SectionContainer from 'components/Layouts/SectionContainer'\n+import data from 'data/aws-reinvent-2025'\n+\n+const ProductHeader = dynamic(() => import('components/Sections/ProductHeader2'))\n+const PlatformSection = dynamic(() => import('components/Solutions/PlatformSection'))\n+\n+const AWSReInvent2025: NextPage = () => {\n+  return (\n+    <>\n+      <NextSeo\n+        title={data.metadata.metaTitle}\n+        description={data.metadata.metaDescription}\n+        openGraph={{\n+          title: data.metadata.metaTitle,\n+          description: data.metadata.metaDescription,\n+          url: `https://supabase.com/aws-reinvent-2025`,\n+        }}\n+      />\n+      <Layout className=\"overflow-visible\">\n+        <ProductHeader {...data.heroSection} />\n+\n+        {/* Free Consultation Section */}\n+        <section id={data.consultationSection.id} className=\"relative py-16 md:py-24\">\n+          <SectionContainer>\n+            <div className=\"max-w-4xl mx-auto\">\n+              <div className=\"bg-surface-100 rounded-2xl p-8 border border-muted\">\n+                <Badge className=\"mb-4\">Free Consultation</Badge>\n+                <h2 className=\"text-3xl md:text-4xl font-medium mb-6\">\n+                  {data.consultationSection.title}\n+                </h2>\n+                <p className=\"text-foreground-light text-lg mb-8\">\n+                  {data.consultationSection.description}\n+                </p>\n+                <ul className=\"space-y-3 mb-8\">\n+                  {data.consultationSection.features.map((feature, idx) => (\n+                    <li key={idx} className=\"flex items-start gap-3\">\n+                      <CheckCircle className=\"size-4 lg:size-5 text-brand mt-1 lg:mt-0.5 shrink-0\" />\n+                      <span className=\"text-foreground-light\">{feature}</span>\n+                    </li>\n+                  ))}\n+                </ul>\n+                <Button\n+                  type=\"primary\"\n+                  size=\"large\"\n+                  iconRight={<ChevronRight className=\"size-3\" />}\n+                  asChild\n+                >\n+                  <Link href={data.consultationSection.cta.href} target=\"_blank\">\n+                    {data.consultationSection.cta.label}\n+                  </Link>\n+                </Button>\n+              </div>\n+            </div>\n+          </SectionContainer>\n+        </section>\n+\n+        {/* Schedule Section */}\n+        <section id={data.scheduleSection.id} className=\"relative py-16 md:py-24\">\n+          <SectionContainer className=\"lg:!py-0\">\n+            <div className=\"lg:text-center mb-12\">\n+              <h2 className=\"text-3xl md:text-4xl font-medium mb-4\">\n+                {data.scheduleSection.title}\n+              </h2>\n+              <p className=\"text-foreground-light text-lg max-w-2xl mx-auto\">\n+                {data.scheduleSection.subtitle}\n+              </p>\n+            </div>\n+\n+            <div className=\"max-w-4xl mx-auto\">\n+              {/* Group events by date */}\n+              {['December 01', 'December 02', 'December 03', 'December 04'].map((date) => {\n+                const dayEvents = data.scheduleSection.schedule.filter(\n+                  (event) => event.date === date\n+                )\n+\n+                return (\n+                  <div key={date} className=\"mb-8\">\n+                    <div className=\"flex items-center gap-2 mb-4\">\n+                      <h3 className=\"text-xl font-medium\">{date}</h3>\n+                    </div>\n+\n+                    <div className=\"space-y-4\">\n+                      {dayEvents.map((event, idx) => (\n+                        <div\n+                          key={idx}\n+                          className=\"bg-surface-100 rounded-lg p-5 border border-muted\"\n+                        >\n+                          <div className=\"flex flex-col md:flex-row md:items-start md:justify-between gap-4\">\n+                            <div className=\"flex-1\">\n+                              <div className=\"flex items-center gap-3 mb-2\">\n+                                <div className=\"flex items-center gap-2 text-sm text-foreground-light\">\n+                                  <Clock className=\"w-4 h-4\" />\n+                                  <span className=\"font-mono\">{event.time}</span>\n+                                </div>\n+                                {event.type === 'keynote' && <Badge variant=\"brand\">Keynote</Badge>}\n+                                {event.type === 'networking' && (\n+                                  <Badge variant=\"default\">Networking</Badge>\n+                                )}\n+                              </div>\n+\n+                              <h4 className=\"text-lg font-medium mb-1\">{event.title}</h4>\n+\n+                              {event.description && (\n+                                <p className=\"text-foreground-light mb-4\">{event.description}</p>\n+                              )}\n+\n+                              {event.location && (\n+                                <div className=\"flex items-center gap-2 text-sm text-foreground-light\">\n+                                  <MapPin className=\"w-4 h-4\" />\n+                                  <span>{event.location}</span>\n+                                </div>\n+                              )}\n+                            </div>\n+\n+                            {event.cta && (\n+                              <Button\n+                                type=\"default\"\n+                                size=\"small\"\n+                                iconRight={<ChevronRight className=\"w-3 h-3\" />}\n+                                asChild\n+                              >\n+                                <Link href={event.cta.href} target=\"_blank\">\n+                                  {event.cta.label}\n+                                </Link>\n+                              </Button>\n+                            )}\n+                          </div>\n+                        </div>\n+                      ))}\n+                    </div>\n+                  </div>\n+                )\n+              })}\n+            </div>\n+          </SectionContainer>\n+        </section>\n+\n+        {/* Platform Section */}\n+        <PlatformSection\n+          id={data.platform.id}\n+          title={data.platform.title}\n+          subheading={data.platform.subheading}\n+          features={data.platform.features}\n+        />\n+\n+        {/* Footer Info Section */}\n+        <section className=\"relative py-16\">\n+          <SectionContainer>\n+            <div className=\"text-center max-w-3xl mx-auto\">\n+              <h3 className=\"text-2xl md:text-4xl font-medium mb-4\">\n+                Talk to our team and see how Supabase can help you build faster.\n+              </h3>\n+\n+              <p className=\"text-foreground-light text-lg mb-8\">\n+                Accelerate your business growth and app development using Supabase scale.\n+              </p>\n+              <Button type=\"default\" size=\"large\" asChild>\n+                <Link href={data.consultationSection.cta.href} target=\"_blank\">\n+                  Book a meeting\n+                </Link>\n+              </Button>\n+            </div>\n+          </SectionContainer>\n+        </section>\n+      </Layout>\n+    </>\n+  )\n+}\n+\n+export default AWSReInvent2025\ndiff --git a/packages/ui/src/components/Button/Button.tsx b/packages/ui/src/components/Button/Button.tsx\nindex 9fb253e6f8e8a..81c5c0366d650 100644\n--- a/packages/ui/src/components/Button/Button.tsx\n+++ b/packages/ui/src/components/Button/Button.tsx\n@@ -9,21 +9,21 @@ import { cn } from '../../lib/utils/cn'\n \n export type ButtonVariantProps = VariantProps<typeof buttonVariants>\n const buttonVariants = cva(\n-  `relative \n+  `relative\n   flex items-center justify-center\n-  cursor-pointer \n-  inline-flex \n-  items-center \n-  space-x-2 \n-  text-center \n-  font-regular \n-  ease-out \n-  duration-200 \n+  cursor-pointer\n+  inline-flex\n+  items-center\n+  space-x-2\n+  text-center\n+  font-regular\n+  ease-out\n+  duration-200\n   rounded-md\n-  outline-none \n-  transition-all \n-  outline-0 \n-  focus-visible:outline-4 \n+  outline-none\n+  transition-all\n+  outline-0\n+  focus-visible:outline-4\n   focus-visible:outline-offset-1\n   border\n   `,\n@@ -31,7 +31,7 @@ const buttonVariants = cva(\n     variants: {\n       type: {\n         primary: `\n-          bg-brand-400 dark:bg-brand-500 \n+          bg-brand-400 dark:bg-brand-500\n           hover:bg-brand/80 dark:hover:bg-brand/50\n           text-foreground\n           border-brand-500/75 dark:border-brand/30\n",
			"diffSize": 30518,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "1e8dcac8dfbcccfb2b41bd62283d2ab89d519f70",
			"message": "Updated wording to make the banner page not confusing (#40688)",
			"user": "awaseem",
			"timestamp": "2025-11-21T16:20:02Z",
			"author": {
				"name": "Ali Waseem",
				"email": "waseema393@gmail.com",
				"username": "awaseem"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/layouts/AppLayout/NoticeBanner.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/layouts/AppLayout/NoticeBanner.tsx b/apps/studio/components/layouts/AppLayout/NoticeBanner.tsx\nindex e15a5e0ca2d51..4e037219cf76d 100644\n--- a/apps/studio/components/layouts/AppLayout/NoticeBanner.tsx\n+++ b/apps/studio/components/layouts/AppLayout/NoticeBanner.tsx\n@@ -44,7 +44,8 @@ export const NoticeBanner = () => {\n       <div className=\"items-center flex flex-row gap-3 z-[1]\">\n         <WarningIcon className=\"z-[1] flex-shrink-0\" />\n         <div className=\"flex-1 text-xs sm:text-sm z-[1] text-warning\">\n-          Urgent Dashboard and Management API maintenance currently in progress. For full details,{' '}\n+          Urgent Dashboard and Management API maintenance between 23:00 UTC on Nov 21, 2025 and\n+          23:00 UTC on Nov 23, 2025. For full details,{' '}\n           <Link\n             href=\"https://status.supabase.com/incidents/z0l2157y33xk\"\n             target=\"_blank\"\n",
			"diffSize": 928,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "11aa71bc2a861003e5bc120845f6f2c71662569a",
			"message": "fix(edge functions secrets): allow read-only role to read secrets metadata (#40667)\n\nAccording to our API permissions model, the read-only role can also read\nsecrets metadata (the actual secret itself is not viewable by anybdoy).\nUpdating the frontend UI to match.",
			"user": "charislam",
			"timestamp": "2025-11-21T15:57:34Z",
			"author": {
				"name": "Charis",
				"email": "26616127+charislam@users.noreply.github.com",
				"username": "charislam"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/Functions/EdgeFunctionSecrets/EdgeFunctionSecrets.tsx",
					"apps/studio/package.json",
					"apps/studio/pages/project/[ref]/functions/secrets.tsx",
					"pnpm-lock.yaml"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Functions/EdgeFunctionSecrets/EdgeFunctionSecrets.tsx b/apps/studio/components/interfaces/Functions/EdgeFunctionSecrets/EdgeFunctionSecrets.tsx\nindex f2676c19a5d0e..a2ece5a8550d7 100644\n--- a/apps/studio/components/interfaces/Functions/EdgeFunctionSecrets/EdgeFunctionSecrets.tsx\n+++ b/apps/studio/components/interfaces/Functions/EdgeFunctionSecrets/EdgeFunctionSecrets.tsx\n@@ -18,22 +18,25 @@ import AddNewSecretForm from './AddNewSecretForm'\n import EdgeFunctionSecret from './EdgeFunctionSecret'\n import { EditSecretSheet } from './EditSecretSheet'\n \n-const EdgeFunctionSecrets = () => {\n+export const EdgeFunctionSecrets = () => {\n   const { ref: projectRef } = useParams()\n   const [searchString, setSearchString] = useState('')\n \n   // Track the ID being deleted to exclude it from error checking\n   const deletingSecretNameRef = useRef<string | null>(null)\n \n-  const { can: canReadSecrets, isLoading: isLoadingPermissions } = useAsyncCheckPermissions(\n-    PermissionAction.SECRETS_READ,\n+  const { can: canReadSecrets, isLoading: isLoadingSecretsPermissions } = useAsyncCheckPermissions(\n+    PermissionAction.FUNCTIONS_SECRET_READ,\n     '*'\n   )\n   const { can: canUpdateSecrets } = useAsyncCheckPermissions(PermissionAction.SECRETS_WRITE, '*')\n \n-  const { data, error, isLoading, isSuccess, isError } = useSecretsQuery({\n-    projectRef: projectRef,\n-  })\n+  const { data, error, isLoading, isSuccess, isError } = useSecretsQuery(\n+    {\n+      projectRef: projectRef,\n+    },\n+    { enabled: canReadSecrets }\n+  )\n \n   const { setValue: setSelectedSecretToEdit, value: selectedSecretToEdit } =\n     useQueryStateWithSelect({\n@@ -82,10 +85,14 @@ const EdgeFunctionSecrets = () => {\n     <TableHead key=\"actions\" />,\n   ]\n \n+  const showLoadingState = isLoadingSecretsPermissions || (canReadSecrets && isLoading)\n+\n   return (\n     <>\n-      {isLoading || isLoadingPermissions ? (\n+      {showLoadingState ? (\n         <GenericSkeletonLoader />\n+      ) : !canReadSecrets ? (\n+        <NoPermission resourceText=\"view this project's edge function secrets\" />\n       ) : (\n         <>\n           {isError && <AlertError error={error} subject=\"Failed to retrieve project secrets\" />}\n@@ -187,5 +194,3 @@ const EdgeFunctionSecrets = () => {\n     </>\n   )\n }\n-\n-export default EdgeFunctionSecrets\ndiff --git a/apps/studio/package.json b/apps/studio/package.json\nindex 3c341cdfdfaa7..00cf144cafd15 100644\n--- a/apps/studio/package.json\n+++ b/apps/studio/package.json\n@@ -62,7 +62,7 @@\n     \"@supabase/mcp-utils\": \"^0.2.0\",\n     \"@supabase/pg-meta\": \"workspace:*\",\n     \"@supabase/realtime-js\": \"catalog:\",\n-    \"@supabase/shared-types\": \"0.1.80\",\n+    \"@supabase/shared-types\": \"0.1.83\",\n     \"@supabase/sql-to-rest\": \"^0.1.6\",\n     \"@supabase/supabase-js\": \"catalog:\",\n     \"@tanstack/react-query\": \"^4.42.0\",\ndiff --git a/apps/studio/pages/project/[ref]/functions/secrets.tsx b/apps/studio/pages/project/[ref]/functions/secrets.tsx\nindex d9df3ec1e5202..cd1222e4aff74 100644\n--- a/apps/studio/pages/project/[ref]/functions/secrets.tsx\n+++ b/apps/studio/pages/project/[ref]/functions/secrets.tsx\n@@ -1,4 +1,4 @@\n-import EdgeFunctionSecrets from 'components/interfaces/Functions/EdgeFunctionSecrets/EdgeFunctionSecrets'\n+import { EdgeFunctionSecrets } from 'components/interfaces/Functions/EdgeFunctionSecrets/EdgeFunctionSecrets'\n import { FunctionsSecretsEmptyStateLocal } from 'components/interfaces/Functions/FunctionsEmptyState'\n import DefaultLayout from 'components/layouts/DefaultLayout'\n import EdgeFunctionsLayout from 'components/layouts/EdgeFunctionsLayout/EdgeFunctionsLayout'\ndiff --git a/pnpm-lock.yaml b/pnpm-lock.yaml\nindex 678941251979b..f1389b0c0fa8b 100644\n--- a/pnpm-lock.yaml\n+++ b/pnpm-lock.yaml\n@@ -859,8 +859,8 @@ importers:\n         specifier: 'catalog:'\n         version: 2.83.0\n       '@supabase/shared-types':\n-        specifier: 0.1.80\n-        version: 0.1.80\n+        specifier: 0.1.83\n+        version: 0.1.83\n       '@supabase/sql-to-rest':\n         specifier: ^0.1.6\n         version: 0.1.6(encoding@0.1.13)(supports-color@8.1.1)\n@@ -8856,8 +8856,8 @@ packages:\n     resolution: {integrity: sha512-mT+QeXAD2gLoqNeQFLjTloDM62VR+VFV8OVdF8RscYpXZriBhabTLE2Auff5lkEJetFFclP1B8j+YtgrWqSmeA==}\n     engines: {node: '>=20.0.0'}\n \n-  '@supabase/shared-types@0.1.80':\n-    resolution: {integrity: sha512-U2ACit34Up5OzB53dthb50YVGcAUzkuWn0Wq9fXWDdfl4Wlp+euWKSSVUMUIQo+bf2phu3V/PmVHEWR6dpls1g==}\n+  '@supabase/shared-types@0.1.83':\n+    resolution: {integrity: sha512-hKXExQKLU9FvUCpDsMKtP/EN+qma5SL+pxd44D06OmwV1UnOUqBwgUvO0nUyF2vV32jKRNaWsf2o+IDJ3pATJA==}\n \n   '@supabase/sql-to-rest@0.1.6':\n     resolution: {integrity: sha512-06KgjeINtc6405XQvfnchBE1azEsU8G2NElfadmvVHKmHa5l2bFzjbtFbpaYgpgTzccHlcDmBaCgedVf2Gyl8Q==}\n@@ -28456,7 +28456,7 @@ snapshots:\n       - bufferutil\n       - utf-8-validate\n \n-  '@supabase/shared-types@0.1.80': {}\n+  '@supabase/shared-types@0.1.83': {}\n \n   '@supabase/sql-to-rest@0.1.6(encoding@0.1.13)(supports-color@8.1.1)':\n     dependencies:\n",
			"diffSize": 5049,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "25dc1efb9f40390e9039f578a5a122680d627585",
			"message": "Analytics: Update tracking for Advisor (#40629)\n\n* remove resolved events\n\n* Remove advisor_resolved event tracking\n\n* updated linting\n\n* updated events to be cleaner\n\n* refactored types\n\n* refactor(telemetry): rename advisor click telemetry to assistant button click\n\n---------\n\nCo-authored-by: Pamela Chia <pamelachiamayyee@gmail.com>",
			"user": "awaseem",
			"timestamp": "2025-11-21T15:53:06Z",
			"author": {
				"name": "Ali Waseem",
				"email": "waseema393@gmail.com",
				"username": "awaseem"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/HomeNew/AdvisorSection.tsx",
					"apps/studio/components/interfaces/Linter/LintDetail.tsx",
					"apps/studio/components/interfaces/Linter/LinterDataGrid.tsx",
					"apps/studio/components/ui/AdvisorPanel/AdvisorPanel.tsx",
					"packages/common/telemetry-constants.ts"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/HomeNew/AdvisorSection.tsx b/apps/studio/components/interfaces/HomeNew/AdvisorSection.tsx\nindex ffcc9d52752a9..fcd89f18fc095 100644\n--- a/apps/studio/components/interfaces/HomeNew/AdvisorSection.tsx\n+++ b/apps/studio/components/interfaces/HomeNew/AdvisorSection.tsx\n@@ -7,8 +7,7 @@ import { createLintSummaryPrompt } from 'components/interfaces/Linter/Linter.uti\n import { SIDEBAR_KEYS } from 'components/layouts/ProjectLayout/LayoutSidebar/LayoutSidebarProvider'\n import { ButtonTooltip } from 'components/ui/ButtonTooltip'\n import { Lint, useProjectLintsQuery } from 'data/lint/lint-query'\n-import { useSendEventMutation } from 'data/telemetry/send-event-mutation'\n-import { useSelectedOrganizationQuery } from 'hooks/misc/useSelectedOrganization'\n+import { useTrack } from 'lib/telemetry/track'\n import { useAdvisorStateSnapshot } from 'state/advisor-state'\n import { useAiAssistantStateSnapshot } from 'state/ai-assistant-state'\n import { useSidebarManagerSnapshot } from 'state/sidebar-manager-state'\n@@ -26,9 +25,8 @@ export const AdvisorSection = ({ showEmptyState = false }: { showEmptyState?: bo\n       enabled: !showEmptyState,\n     }\n   )\n+  const track = useTrack()\n   const snap = useAiAssistantStateSnapshot()\n-  const { mutate: sendEvent } = useSendEventMutation()\n-  const { data: organization } = useSelectedOrganizationQuery()\n   const { openSidebar } = useSidebarManagerSnapshot()\n   const { setSelectedItem } = useAdvisorStateSnapshot()\n \n@@ -51,40 +49,25 @@ export const AdvisorSection = ({ showEmptyState = false }: { showEmptyState?: bo\n \n   const handleAskAssistant = useCallback(() => {\n     openSidebar(SIDEBAR_KEYS.AI_ASSISTANT)\n-    if (projectRef && organization?.slug) {\n-      sendEvent({\n-        action: 'home_advisor_ask_assistant_clicked',\n-        properties: {\n-          issues_count: totalErrors,\n-        },\n-        groups: {\n-          project: projectRef,\n-          organization: organization.slug,\n-        },\n-      })\n-    }\n-  }, [sendEvent, openSidebar, projectRef, organization, totalErrors])\n+    track('advisor_assistant_button_clicked', {\n+      origin: 'homepage',\n+      issuesCount: totalErrors,\n+    })\n+  }, [track, openSidebar, totalErrors])\n \n   const handleCardClick = useCallback(\n     (lint: Lint) => {\n       setSelectedItem(lint.cache_key, 'lint')\n       openSidebar(SIDEBAR_KEYS.ADVISOR_PANEL)\n-      if (projectRef && organization?.slug) {\n-        sendEvent({\n-          action: 'home_advisor_issue_card_clicked',\n-          properties: {\n-            issue_category: lint.categories[0] || 'UNKNOWN',\n-            issue_name: lint.name,\n-            issues_count: totalErrors,\n-          },\n-          groups: {\n-            project: projectRef,\n-            organization: organization.slug,\n-          },\n-        })\n-      }\n+      track('advisor_detail_opened', {\n+        origin: 'homepage',\n+        advisorSource: 'lint',\n+        advisorCategory: lint.categories[0],\n+        advisorType: lint.name,\n+        advisorLevel: lint.level,\n+      })\n     },\n-    [sendEvent, setSelectedItem, openSidebar, projectRef, organization, totalErrors]\n+    [track, setSelectedItem, openSidebar]\n   )\n \n   if (showEmptyState) {\n@@ -142,19 +125,12 @@ export const AdvisorSection = ({ showEmptyState = false }: { showEmptyState?: bo\n                           name: 'Summarize lint',\n                           initialInput: createLintSummaryPrompt(lint),\n                         })\n-                        if (projectRef && organization?.slug) {\n-                          sendEvent({\n-                            action: 'home_advisor_fix_issue_clicked',\n-                            properties: {\n-                              issue_category: lint.categories[0] || 'UNKNOWN',\n-                              issue_name: lint.name,\n-                            },\n-                            groups: {\n-                              project: projectRef,\n-                              organization: organization.slug,\n-                            },\n-                          })\n-                        }\n+                        track('advisor_assistant_button_clicked', {\n+                          origin: 'homepage',\n+                          advisorCategory: lint.categories[0],\n+                          advisorType: lint.name,\n+                          advisorLevel: lint.level,\n+                        })\n                       }}\n                       tooltip={{\n                         content: { side: 'bottom', text: 'Help me fix this issue' },\ndiff --git a/apps/studio/components/interfaces/Linter/LintDetail.tsx b/apps/studio/components/interfaces/Linter/LintDetail.tsx\nindex f5c04d4d80644..334353bd70346 100644\n--- a/apps/studio/components/interfaces/Linter/LintDetail.tsx\n+++ b/apps/studio/components/interfaces/Linter/LintDetail.tsx\n@@ -4,6 +4,7 @@ import ReactMarkdown from 'react-markdown'\n import { createLintSummaryPrompt, lintInfoMap } from 'components/interfaces/Linter/Linter.utils'\n import { Lint } from 'data/lint/lint-query'\n import { DOCS_URL } from 'lib/constants'\n+import { useTrack } from 'lib/telemetry/track'\n import { ExternalLink } from 'lucide-react'\n import { useAiAssistantStateSnapshot } from 'state/ai-assistant-state'\n import { AiIconAnimation, Button } from 'ui'\n@@ -18,9 +19,26 @@ interface LintDetailProps {\n }\n \n const LintDetail = ({ lint, projectRef, onAskAssistant }: LintDetailProps) => {\n+  const track = useTrack()\n   const snap = useAiAssistantStateSnapshot()\n   const { openSidebar } = useSidebarManagerSnapshot()\n \n+  const handleAskAssistant = () => {\n+    track('advisor_assistant_button_clicked', {\n+      origin: 'lint_detail',\n+      advisorCategory: lint.categories[0],\n+      advisorType: lint.name,\n+      advisorLevel: lint.level,\n+    })\n+\n+    onAskAssistant?.()\n+    openSidebar(SIDEBAR_KEYS.AI_ASSISTANT)\n+    snap.newChat({\n+      name: 'Summarize lint',\n+      initialInput: createLintSummaryPrompt(lint),\n+    })\n+  }\n+\n   return (\n     <div>\n       <h3 className=\"text-sm mb-2\">Entity</h3>\n@@ -42,14 +60,7 @@ const LintDetail = ({ lint, projectRef, onAskAssistant }: LintDetailProps) => {\n       <div className=\"flex items-center gap-2\">\n         <Button\n           icon={<AiIconAnimation className=\"scale-75 w-3 h-3\" />}\n-          onClick={() => {\n-            onAskAssistant?.()\n-            openSidebar(SIDEBAR_KEYS.AI_ASSISTANT)\n-            snap.newChat({\n-              name: 'Summarize lint',\n-              initialInput: createLintSummaryPrompt(lint),\n-            })\n-          }}\n+          onClick={handleAskAssistant}\n         >\n           Ask Assistant\n         </Button>\ndiff --git a/apps/studio/components/interfaces/Linter/LinterDataGrid.tsx b/apps/studio/components/interfaces/Linter/LinterDataGrid.tsx\nindex ae9bcad47b1d4..07817830d7e4f 100644\n--- a/apps/studio/components/interfaces/Linter/LinterDataGrid.tsx\n+++ b/apps/studio/components/interfaces/Linter/LinterDataGrid.tsx\n@@ -1,5 +1,5 @@\n import { X } from 'lucide-react'\n-import { useRef, useState } from 'react'\n+import { useRef } from 'react'\n import DataGrid, { Column, DataGridHandle, Row } from 'react-data-grid'\n import ReactMarkdown from 'react-markdown'\n \n@@ -13,6 +13,7 @@ import {\n } from 'components/interfaces/Linter/Linter.utils'\n import { Lint } from 'data/lint/lint-query'\n import { useRouter } from 'next/router'\n+import { useTrack } from 'lib/telemetry/track'\n import { Button, ResizableHandle, ResizablePanel, ResizablePanelGroup, cn } from 'ui'\n import { GenericSkeletonLoader } from 'ui-patterns/ShimmeringLoader'\n import { EntityTypeIcon } from './Linter.utils'\n@@ -34,6 +35,7 @@ const LinterDataGrid = ({\n   const gridRef = useRef<DataGridHandle>(null)\n   const { ref } = useParams()\n   const router = useRouter()\n+  const track = useTrack()\n \n   const lintCols = [\n     {\n@@ -148,6 +150,14 @@ const LinterDataGrid = ({\n                       gridRef.current?.scrollToCell({ idx: 0, rowIdx: idx })\n                       const { id, ...rest } = router.query\n                       router.push({ ...router, query: { ...rest, id: props.row.cache_key } })\n+\n+                      track('advisor_detail_opened', {\n+                        origin: 'advisors_page',\n+                        advisorSource: 'lint',\n+                        advisorCategory: props.row.categories[0],\n+                        advisorType: props.row.name,\n+                        advisorLevel: props.row.level,\n+                      })\n                     }\n                   }}\n                 />\ndiff --git a/apps/studio/components/ui/AdvisorPanel/AdvisorPanel.tsx b/apps/studio/components/ui/AdvisorPanel/AdvisorPanel.tsx\nindex cd57b2400be52..083e50217fbc9 100644\n--- a/apps/studio/components/ui/AdvisorPanel/AdvisorPanel.tsx\n+++ b/apps/studio/components/ui/AdvisorPanel/AdvisorPanel.tsx\n@@ -12,6 +12,7 @@ import { useNotificationsV2UpdateMutation } from 'data/notifications/notificatio\n import { useSelectedOrganizationQuery } from 'hooks/misc/useSelectedOrganization'\n import { useSelectedProjectQuery } from 'hooks/misc/useSelectedProject'\n import { IS_PLATFORM } from 'lib/constants'\n+import { useTrack } from 'lib/telemetry/track'\n import { AdvisorSeverity, AdvisorTab, useAdvisorStateSnapshot } from 'state/advisor-state'\n import { useSidebarManagerSnapshot } from 'state/sidebar-manager-state'\n import { AdvisorDetail } from './AdvisorDetail'\n@@ -49,6 +50,7 @@ const notificationPriorityToSeverity = (priority: string | null | undefined): Ad\n }\n \n export const AdvisorPanel = () => {\n+  const track = useTrack()\n   const {\n     activeTab,\n     severityFilters,\n@@ -250,12 +252,28 @@ export const AdvisorPanel = () => {\n \n   const handleItemClick = (item: AdvisorItem) => {\n     setSelectedItem(item.id, item.source)\n+\n     if (item.source === 'notification') {\n       const notification = item.original as Notification\n       if (notification.status === 'new' && !markedRead.current.includes(notification.id)) {\n         markedRead.current.push(notification.id)\n       }\n     }\n+\n+    const advisorCategory =\n+      item.source === 'lint' && 'categories' in item.original\n+        ? item.original.categories[0]\n+        : undefined\n+    const advisorLevel =\n+      item.source === 'lint' && 'level' in item.original ? item.original.level : undefined\n+\n+    track('advisor_detail_opened', {\n+      origin: 'advisor_panel',\n+      advisorCategory,\n+      advisorSource: item.source,\n+      advisorType: item.original.name,\n+      advisorLevel,\n+    })\n   }\n \n   const handleUpdateNotificationStatus = (id: string, status: 'archived' | 'seen') => {\ndiff --git a/packages/common/telemetry-constants.ts b/packages/common/telemetry-constants.ts\nindex 767ce07df87bd..c364c5230f952 100644\n--- a/packages/common/telemetry-constants.ts\n+++ b/packages/common/telemetry-constants.ts\n@@ -1616,24 +1616,6 @@ export interface HomeActivityStatClickedEvent {\n   groups: TelemetryGroups\n }\n \n-/**\n- * User clicked the main Ask Assistant button in the Advisor section of HomeV2.\n- *\n- * @group Events\n- * @source studio\n- * @page /project/{ref}\n- */\n-export interface HomeAdvisorAskAssistantClickedEvent {\n-  action: 'home_advisor_ask_assistant_clicked'\n-  properties: {\n-    /**\n-     * Number of issues found by the advisor\n-     */\n-    issues_count: number\n-  }\n-  groups: TelemetryGroups\n-}\n-\n /**\n  * User was exposed to the realtime experiment (shown or not shown the Enable Realtime button).\n  *\n@@ -1660,51 +1642,6 @@ export interface RealtimeExperimentExposedEvent {\n   groups: TelemetryGroups\n }\n \n-/**\n- * User clicked on an issue card in the Advisor section of HomeV2.\n- *\n- * @group Events\n- * @source studio\n- * @page /project/{ref}\n- */\n-export interface HomeAdvisorIssueCardClickedEvent {\n-  action: 'home_advisor_issue_card_clicked'\n-  properties: {\n-    /**\n-     * Category of the issue (SECURITY or PERFORMANCE)\n-     */\n-    issue_category: string\n-    /**\n-     * Name/key of the lint issue\n-     */\n-    issue_name: string\n-    issues_count: number\n-  }\n-  groups: TelemetryGroups\n-}\n-\n-/**\n- * User clicked the Fix Issue button on an advisor card in HomeV2.\n- *\n- * @group Events\n- * @source studio\n- * @page /project/{ref}\n- */\n-export interface HomeAdvisorFixIssueClickedEvent {\n-  action: 'home_advisor_fix_issue_clicked'\n-  properties: {\n-    /**\n-     * Category of the issue (SECURITY or PERFORMANCE)\n-     */\n-    issue_category: string\n-    /**\n-     * Name/key of the lint issue\n-     */\n-    issue_name: string\n-  }\n-  groups: TelemetryGroups\n-}\n-\n /**\n  * User clicked on a service title in Project Usage section of HomeV2.\n  *\n@@ -2349,6 +2286,79 @@ export interface LogDrainConfirmButtonSubmittedEvent {\n   groups: TelemetryGroups\n }\n \n+type AdvisorCategory = 'PERFORMANCE' | 'SECURITY'\n+type AdvisorLevel = 'ERROR' | 'WARN' | 'INFO'\n+\n+/**\n+ * User opened an advisor detail page to view a specific advisor (lint or notification).\n+ * This tracks when users engage with advisor recommendations.\n+ *\n+ * @group Events\n+ * @source studio\n+ * @page /dashboard/project/{ref}/advisors/security or home page or advisor panel sidebar\n+ */\n+export interface AdvisorDetailOpenedEvent {\n+  action: 'advisor_detail_opened'\n+  properties: {\n+    /**\n+     * Where the advisor was viewed from\n+     */\n+    origin: 'homepage' | 'advisor_panel' | 'advisors_page'\n+    /**\n+     * Source of the advisor\n+     */\n+    advisorSource: 'lint' | 'notification'\n+    /**\n+     * Category of the advisor (SECURITY or PERFORMANCE)\n+     */\n+    advisorCategory?: AdvisorCategory\n+    /**\n+     * Specific advisor type/name, e.g. missing_index, no_rls_policy\n+     */\n+    advisorType?: string\n+    /**\n+     * Severity level of the advisor (only for lints)\n+     */\n+    advisorLevel?: AdvisorLevel\n+  }\n+  groups: TelemetryGroups\n+}\n+\n+/**\n+ * User clicked the Assistant button to get AI help with an advisor issue.\n+ * This opens the AI Assistant sidebar with a pre-filled prompt about the issue.\n+ *\n+ * @group Events\n+ * @source studio\n+ * @page /dashboard/project/{ref} (homepage), /dashboard/project/{ref}/advisors/security or /dashboard/project/{ref}/advisors/performance (lint detail panel)\n+ */\n+export interface AdvisorAssistantButtonClickedEvent {\n+  action: 'advisor_assistant_button_clicked'\n+  properties: {\n+    /**\n+     * Where the button was clicked\n+     */\n+    origin: 'homepage' | 'lint_detail'\n+    /**\n+     * Category of the advisor (SECURITY or PERFORMANCE)\n+     */\n+    advisorCategory?: AdvisorCategory\n+    /**\n+     * Specific advisor type/name\n+     */\n+    advisorType?: string\n+    /**\n+     * Severity level of the advisor (only for lints)\n+     */\n+    advisorLevel?: AdvisorLevel\n+    /**\n+     * Number of issues found (only included when origin is 'homepage')\n+     */\n+    issuesCount?: number\n+  }\n+  groups: TelemetryGroups\n+}\n+\n /**\n  * @hidden\n  */\n@@ -2451,9 +2461,6 @@ export type TelemetryEvent =\n   | HomeGettingStartedClosedEvent\n   | HomeSectionRowsMovedEvent\n   | HomeActivityStatClickedEvent\n-  | HomeAdvisorAskAssistantClickedEvent\n-  | HomeAdvisorIssueCardClickedEvent\n-  | HomeAdvisorFixIssueClickedEvent\n   | RealtimeExperimentExposedEvent\n   | HomeProjectUsageServiceClickedEvent\n   | HomeProjectUsageChartClickedEvent\n@@ -2480,3 +2487,5 @@ export type TelemetryEvent =\n   | SidebarOpenedEvent\n   | LogDrainSaveButtonClickedEvent\n   | LogDrainConfirmButtonSubmittedEvent\n+  | AdvisorDetailOpenedEvent\n+  | AdvisorAssistantButtonClickedEvent\n",
			"diffSize": 15469,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "cc1442d23a5ada210fd9f5cba77e8d2d552bc5a0",
			"message": "Fix: update to have email for support for maintenance page (#40685)\n\nupdate to have email for support",
			"user": "awaseem",
			"timestamp": "2025-11-21T15:41:10Z",
			"author": {
				"name": "Ali Waseem",
				"email": "waseema393@gmail.com",
				"username": "awaseem"
			},
			"files": {
				"added": [],
				"modified": ["apps/studio/pages/maintenance.tsx"],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/pages/maintenance.tsx b/apps/studio/pages/maintenance.tsx\nindex 44b956478694e..74ac6c1fff82d 100644\n--- a/apps/studio/pages/maintenance.tsx\n+++ b/apps/studio/pages/maintenance.tsx\n@@ -32,6 +32,15 @@ const MaintenancePage: NextPageWithLayout = () => {\n             We are currently improving our services. The dashboard will be back online shortly.\n           </p>\n         </div>\n+        <p className=\"text-sm text-foreground-lighter max-w-xs mx-auto\">\n+          If you need support while the dashboard is inaccessible, you can email us at{' '}\n+          <a\n+            href=\"mailto:support+maintenance@supabase.io\"\n+            className=\"text-foreground-light underline hover:text-foreground\"\n+          >\n+            support+maintenance@supabase.io\n+          </a>\n+        </p>\n         <div className=\"flex flex-col items-center gap-2 mt-4\">\n           <p className=\"text-sm text-foreground-lighter\">\n             Reload the page to check if the maintenance window has ended\n",
			"diffSize": 1010,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "be4a6fe6c130bd522b43c958a016e9f66f7e805c",
			"message": "Update: Banner for maintenance window (#40668)\n\n* updated to use notice banner\n\n* added link to maintenance\n\n* updated banner\n\n* updated message from support",
			"user": "awaseem",
			"timestamp": "2025-11-21T15:38:57Z",
			"author": {
				"name": "Ali Waseem",
				"email": "waseema393@gmail.com",
				"username": "awaseem"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/App/AppBannerWrapperContext.tsx",
					"apps/studio/components/layouts/AppLayout/NoticeBanner.tsx",
					"packages/common/constants/local-storage.ts"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/App/AppBannerWrapperContext.tsx b/apps/studio/components/interfaces/App/AppBannerWrapperContext.tsx\nindex 07ac280ea3f53..30f005b9ac9de 100644\n--- a/apps/studio/components/interfaces/App/AppBannerWrapperContext.tsx\n+++ b/apps/studio/components/interfaces/App/AppBannerWrapperContext.tsx\n@@ -2,41 +2,41 @@ import { LOCAL_STORAGE_KEYS } from 'common'\n import { noop } from 'lodash'\n import { PropsWithChildren, createContext, useContext, useEffect, useState } from 'react'\n \n-const MIDDLEWARE_OUTAGE_BANNER_KEY = LOCAL_STORAGE_KEYS.MIDDLEWARE_OUTAGE_BANNER\n+const MAINTENANCE_WINDOW_BANNER_KEY = LOCAL_STORAGE_KEYS.MAINTENANCE_WINDOW_BANNER\n \n // [Joshen] This file is meant to be dynamic - update this as and when we need to use the NoticeBanner\n \n type AppBannerContextType = {\n-  middlewareOutageBannerAcknowledged: boolean\n-  onUpdateAcknowledged: (key: typeof MIDDLEWARE_OUTAGE_BANNER_KEY) => void\n+  maintenanceWindowBannerAcknowledged: boolean\n+  onUpdateAcknowledged: (key: typeof MAINTENANCE_WINDOW_BANNER_KEY) => void\n }\n \n const AppBannerContext = createContext<AppBannerContextType>({\n-  middlewareOutageBannerAcknowledged: false,\n+  maintenanceWindowBannerAcknowledged: false,\n   onUpdateAcknowledged: noop,\n })\n \n export const useAppBannerContext = () => useContext(AppBannerContext)\n \n export const AppBannerContextProvider = ({ children }: PropsWithChildren<{}>) => {\n-  const [middlewareOutageBannerAcknowledged, setmiddlewareOutageBannerAcknowledged] =\n+  const [maintenanceWindowBannerAcknowledged, setMaintenanceWindowBannerAcknowledged] =\n     useState<boolean>(false)\n \n   useEffect(() => {\n     if (typeof window !== 'undefined') {\n-      const acknowledged = localStorage.getItem(MIDDLEWARE_OUTAGE_BANNER_KEY) === 'true'\n-      setmiddlewareOutageBannerAcknowledged(acknowledged)\n+      const maintenanceAcknowledged = localStorage.getItem(MAINTENANCE_WINDOW_BANNER_KEY) === 'true'\n+      setMaintenanceWindowBannerAcknowledged(maintenanceAcknowledged)\n     }\n   }, [])\n \n   const value = {\n-    middlewareOutageBannerAcknowledged,\n-    onUpdateAcknowledged: (key: typeof MIDDLEWARE_OUTAGE_BANNER_KEY) => {\n-      if (key === MIDDLEWARE_OUTAGE_BANNER_KEY) {\n+    maintenanceWindowBannerAcknowledged,\n+    onUpdateAcknowledged: (key: typeof MAINTENANCE_WINDOW_BANNER_KEY) => {\n+      if (key === MAINTENANCE_WINDOW_BANNER_KEY) {\n         if (typeof window !== 'undefined') {\n-          window.localStorage.setItem(MIDDLEWARE_OUTAGE_BANNER_KEY, 'true')\n+          window.localStorage.setItem(MAINTENANCE_WINDOW_BANNER_KEY, 'true')\n         }\n-        setmiddlewareOutageBannerAcknowledged(true)\n+        setMaintenanceWindowBannerAcknowledged(true)\n       }\n     },\n   }\n@@ -45,6 +45,6 @@ export const AppBannerContextProvider = ({ children }: PropsWithChildren<{}>) =>\n }\n \n export const useIsNoticeBannerShown = () => {\n-  const { middlewareOutageBannerAcknowledged } = useAppBannerContext()\n-  return middlewareOutageBannerAcknowledged\n+  const { maintenanceWindowBannerAcknowledged } = useAppBannerContext()\n+  return maintenanceWindowBannerAcknowledged\n }\ndiff --git a/apps/studio/components/layouts/AppLayout/NoticeBanner.tsx b/apps/studio/components/layouts/AppLayout/NoticeBanner.tsx\nindex 9b1b95a1e70c2..e15a5e0ca2d51 100644\n--- a/apps/studio/components/layouts/AppLayout/NoticeBanner.tsx\n+++ b/apps/studio/components/layouts/AppLayout/NoticeBanner.tsx\n@@ -1,45 +1,65 @@\n-import { ExternalLink } from 'lucide-react'\n+import Link from 'next/link'\n import { useRouter } from 'next/router'\n \n import { useAppBannerContext } from 'components/interfaces/App/AppBannerWrapperContext'\n-import { Button, WarningIcon } from 'ui'\n+import { Button, WarningIcon, cn } from 'ui'\n \n // This file, like AppBannerWrapperContext.tsx, is meant to be dynamic - update this as and when we need to use the NoticeBanner\n-// We can disable this banner after 16th May 2025 as the middleware outage is complete\n+// We can disable this banner after 23rd November 2025 as the maintenance window is complete\n \n export const NoticeBanner = () => {\n   const router = useRouter()\n \n   const appBannerContext = useAppBannerContext()\n-  const { middlewareOutageBannerAcknowledged, onUpdateAcknowledged } = appBannerContext\n+  const { maintenanceWindowBannerAcknowledged, onUpdateAcknowledged } = appBannerContext\n \n-  const acknowledged = middlewareOutageBannerAcknowledged\n+  const acknowledged = maintenanceWindowBannerAcknowledged\n \n   if (router.pathname.includes('sign-in') || acknowledged) {\n     return null\n   }\n \n   return (\n-    <div className=\"flex items-center justify-center gap-x-4 bg py-0.5 border transition text-foreground border-default\">\n-      <WarningIcon className=\"w-4 h-4\" />\n-      <p className=\"text-sm\">\n-        Brief Dashboard outage: May 16, 2025, 22:00–23:00 UTC (no impact to your apps)\n-      </p>\n-      <div className=\"flex items-center gap-x-1\">\n-        <Button asChild type=\"link\" iconRight={<ExternalLink size={14} />}>\n-          <a\n+    <div\n+      className={cn(\n+        'relative bg-warning-300 dark:bg-warning-200 border-b border-muted py-1 flex items-center justify-center flex-shrink-0 px-0'\n+      )}\n+    >\n+      <div className=\"absolute inset-y-0 left-0 right-0 overflow-hidden z-0\">\n+        <div\n+          className=\"absolute inset-0 opacity-[0.8%]\"\n+          style={{\n+            background: `repeating-linear-gradient(\n+                  45deg,\n+                  currentColor,\n+                  currentColor 10px,\n+                  transparent 10px,\n+                  transparent 20px\n+                )`,\n+            maskImage: 'linear-gradient(to top, black, transparent)',\n+            WebkitMaskImage: 'linear-gradient(to top, black, transparent)',\n+          }}\n+        />\n+      </div>\n+      <div className=\"items-center flex flex-row gap-3 z-[1]\">\n+        <WarningIcon className=\"z-[1] flex-shrink-0\" />\n+        <div className=\"flex-1 text-xs sm:text-sm z-[1] text-warning\">\n+          Urgent Dashboard and Management API maintenance currently in progress. For full details,{' '}\n+          <Link\n+            href=\"https://status.supabase.com/incidents/z0l2157y33xk\"\n             target=\"_blank\"\n             rel=\"noreferrer\"\n-            href=\"https://status.supabase.com/incidents/8k0ysqkhscfj\"\n+            className=\"opacity-75 hover:opacity-100 underline\"\n           >\n-            Learn more\n-          </a>\n-        </Button>\n+            check here\n+          </Link>\n+          .\n+        </div>\n         <Button\n           type=\"text\"\n-          className=\"opacity-75\"\n+          className=\"opacity-75 z-[1] flex-shrink-0\"\n           onClick={() => {\n-            onUpdateAcknowledged('middleware-outage-banner-2025-05-16')\n+            onUpdateAcknowledged('maintenance-window-banner-2025-11-21')\n           }}\n         >\n           Dismiss\ndiff --git a/packages/common/constants/local-storage.ts b/packages/common/constants/local-storage.ts\nindex 2656fc7160317..3737437347bf7 100644\n--- a/packages/common/constants/local-storage.ts\n+++ b/packages/common/constants/local-storage.ts\n@@ -67,7 +67,7 @@ export const LOCAL_STORAGE_KEYS = {\n   // Notice banner keys\n   FLY_POSTGRES_DEPRECATION_WARNING: 'fly-postgres-deprecation-warning-dismissed',\n   API_KEYS_FEEDBACK_DISMISSED: (ref: string) => `supabase-api-keys-feedback-dismissed-${ref}`,\n-  MIDDLEWARE_OUTAGE_BANNER: 'middleware-outage-banner-2025-05-16',\n+  MAINTENANCE_WINDOW_BANNER: 'maintenance-window-banner-2025-11-21',\n   REPORT_DATERANGE: 'supabase-report-daterange',\n \n   // api keys view switcher for new and legacy api keys\n",
			"diffSize": 7615,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "93aaae09927150232cd8118a4c97f301f326ed6c",
			"message": "chore: nits on events page (#40620)\n\n* nits on events page\n\n* nit\n\n* mobile spacing\n\n* line",
			"user": "stylessh",
			"timestamp": "2025-11-21T14:40:39Z",
			"author": {
				"name": "Alan Daniel",
				"email": "stylesshjs@gmail.com",
				"username": "stylessh"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/www/components/Events/new/EventBanner.tsx",
					"apps/www/components/Events/new/EventClientRenderer.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/www/components/Events/new/EventBanner.tsx b/apps/www/components/Events/new/EventBanner.tsx\nindex 439e72306e71d..66aae718c2f55 100644\n--- a/apps/www/components/Events/new/EventBanner.tsx\n+++ b/apps/www/components/Events/new/EventBanner.tsx\n@@ -1,6 +1,6 @@\n 'use client'\n \n-import { CalendarIcon, MapPinIcon, UsersIcon } from 'lucide-react'\n+import { CalendarIcon, MapPinIcon } from 'lucide-react'\n import Image from 'next/image'\n import Link from 'next/link'\n import { cn, Button } from 'ui'\n@@ -8,7 +8,7 @@ import { useEvents } from '~/app/events/context'\n import { formatHosts } from '~/lib/eventsUtils'\n \n export function EventBanner() {\n-  const { isLoading, allEvents, featuredEvent } = useEvents()\n+  const { isLoading, featuredEvent } = useEvents()\n \n   if (isLoading) {\n     return <EventBannerSkeleton />\n@@ -17,13 +17,13 @@ export function EventBanner() {\n   if (!featuredEvent) return null\n \n   return (\n-    <section className={cn('grid md:grid-cols-[minmax(320px,35%),1fr] gap-12')}>\n+    <section className={cn('grid md:grid-cols-[minmax(320px,35%),1fr] gap-6 lg:gap-12')}>\n       <CoverImage url={featuredEvent.cover_url} />\n \n-      <article className=\"flex flex-col gap-6 py-2\">\n-        <div className=\"flex justify-between items-start\">\n+      <article className=\"flex flex-col md:justify-center gap-6 lg:py-2\">\n+        <div className=\"flex justify-between items-start gap-4\">\n           <div className=\"flex flex-col gap-1.5\">\n-            <h2 className=\"text-2xl font-medium\">{featuredEvent.title}</h2>\n+            <h2 className=\"text-2xl font-medium lg:line-clamp-2\">{featuredEvent.title}</h2>\n             <p\n               className=\"text-lg font-medium text-foreground-light\"\n               title={`Hosted by ${formatHosts(featuredEvent.hosts).fullList}`}\n@@ -50,9 +50,11 @@ export function EventBanner() {\n           <LocationWidget location={featuredEvent.location} />\n         </div>\n \n-        <p className=\"whitespace-pre-line text-foreground-light mt-4\">\n-          {featuredEvent.description}\n-        </p>\n+        <div className=\"relative flex\">\n+          <p className=\"text-foreground-light line-clamp-3 lg:line-clamp-4\">\n+            {featuredEvent.description}\n+          </p>\n+        </div>\n \n         {featuredEvent.link && (\n           <Button className=\"block md:hidden mt-1\" size=\"medium\" asChild>\n@@ -75,7 +77,7 @@ const DateWidget = ({ date, endDate }: { date: string; endDate?: string }) => {\n \n   const formattedDate = eventDate.toLocaleDateString('en-US', {\n     weekday: 'long',\n-    month: 'long',\n+    month: 'short',\n     day: 'numeric',\n   })\n \n@@ -105,8 +107,8 @@ const DateWidget = ({ date, endDate }: { date: string; endDate?: string }) => {\n \n   return (\n     <div className=\"flex items-center gap-4\">\n-      <div className=\"bg-surface-100 p-1.5 border rounded-md\">\n-        <CalendarIcon className=\"size-7\" />\n+      <div className=\"bg-surface-100 w-10 h-10 flex items-center justify-center border rounded-md\">\n+        <CalendarIcon className=\"size-5\" strokeWidth={1.5} />\n       </div>\n \n       <div className=\"flex flex-col gap-0\">\n@@ -123,8 +125,8 @@ const LocationWidget = ({ location }: { location?: string }) => {\n \n   return (\n     <div className=\"flex items-center gap-4\">\n-      <div className=\"bg-surface-100 p-1.5 border rounded-md\">\n-        <MapPinIcon className=\"size-7\" />\n+      <div className=\"bg-surface-100 w-10 h-10 flex items-center justify-center border rounded-md\">\n+        <MapPinIcon className=\"size-5\" strokeWidth={1.5} />\n       </div>\n \n       <div className=\"flex flex-col gap-0\">\n@@ -138,14 +140,14 @@ const LocationWidget = ({ location }: { location?: string }) => {\n const CoverImage = ({ url }: { url?: string }) => {\n   if (!url)\n     return (\n-      <div className=\"w-full bg-surface-100 aspect-square border rounded-lg grid place-items-center\">\n+      <div className=\"w-full bg-surface-100 aspect-square border rounded-lg hidden md:grid place-items-center\">\n         <Logo />\n       </div>\n     )\n \n   return (\n-    <div className=\"w-full bg-surface-100 aspect-square border rounded-lg overflow-hidden relative\">\n-      <img src={url} alt=\"Event Cover\" className=\"object-cover w-full\" />\n+    <div className=\"w-full bg-surface-100 hidden md:block aspect-square border rounded-lg overflow-hidden relative\">\n+      <img src={url} alt=\"Event Cover\" className=\"object-cover object-center w-full\" />\n     </div>\n   )\n }\ndiff --git a/apps/www/components/Events/new/EventClientRenderer.tsx b/apps/www/components/Events/new/EventClientRenderer.tsx\nindex 96399b77328e1..21568b7fdd458 100644\n--- a/apps/www/components/Events/new/EventClientRenderer.tsx\n+++ b/apps/www/components/Events/new/EventClientRenderer.tsx\n@@ -11,18 +11,18 @@ export function EventClientRenderer({ staticEvents }: { staticEvents: SupabaseEv\n   return (\n     <EventsProvider staticEvents={staticEvents}>\n       <DefaultLayout className=\"flex flex-col\">\n-        <SectionContainer className=\"border-x border-b lg:!py-12\">\n-          <h1 className=\"h1\">\n+        <SectionContainer className=\"border-x border-b !py-8\">\n+          <h1 className=\"h3 !p-0 !m-0\">\n             <span className=\"sr-only\">Supabase</span> Events\n           </h1>\n           <p className=\"text-foreground-light\">Join us at the following upcoming events</p>\n         </SectionContainer>\n \n-        <SectionContainer className=\"border-x flex-1 lg:!pt-12\">\n+        <SectionContainer className=\"border-x border-b flex-1 !py-8\">\n           <EventBanner />\n         </SectionContainer>\n \n-        <SectionContainer className=\"border-x flex-1 !pt-0\">\n+        <SectionContainer className=\"border-x flex-1 !pt-8\">\n           <EventGallery />\n         </SectionContainer>\n       </DefaultLayout>\n",
			"diffSize": 5739,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "8ce41157a32101d761c10d8827594630a520c8bd",
			"message": "fix: Generate temp API keys when doing mutations for Analytics buckets (#40680)\n\n* Refactor the iceberg queries and mutations to use getOrRefreshTemporaryApiKey.\n\n* Fix the uses of the mutations.\n\n* Hardcode the temp api keys queries at 60 seconds.",
			"user": "ivasilov",
			"timestamp": "2025-11-21T13:47:29Z",
			"author": {
				"name": "Ivan Vasilov",
				"email": "vasilov.ivan@gmail.com",
				"username": "ivasilov"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/Database/ETL/DestinationPanel/DestinationPanel.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/index.tsx",
					"apps/studio/data/api-keys/temp-api-keys-query.ts",
					"apps/studio/data/storage/iceberg-namespace-create-mutation.ts",
					"apps/studio/data/storage/iceberg-namespace-delete-mutation.ts",
					"apps/studio/data/storage/iceberg-namespace-table-delete-mutation.ts",
					"apps/studio/data/storage/iceberg-namespace-tables-query.ts",
					"apps/studio/data/storage/iceberg-namespaces-query.ts",
					"apps/studio/hooks/use-supabase-client-query.ts"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Database/ETL/DestinationPanel/DestinationPanel.tsx b/apps/studio/components/interfaces/Database/ETL/DestinationPanel/DestinationPanel.tsx\nindex ac7291671b07a..700d5ae77ea25 100644\n--- a/apps/studio/components/interfaces/Database/ETL/DestinationPanel/DestinationPanel.tsx\n+++ b/apps/studio/components/interfaces/Database/ETL/DestinationPanel/DestinationPanel.tsx\n@@ -113,7 +113,7 @@ export const DestinationPanel = ({\n     useS3AccessKeyCreateMutation()\n \n   const { mutateAsync: createNamespace, isPending: isCreatingNamespace } =\n-    useIcebergNamespaceCreateMutation({ projectRef })\n+    useIcebergNamespaceCreateMutation()\n \n   const {\n     data: publications = [],\n@@ -232,6 +232,7 @@ export const DestinationPanel = ({\n       const catalogUri = getCatalogURI(project?.ref ?? '', protocol, endpoint)\n \n       await createNamespace({\n+        projectRef,\n         catalogUri,\n         warehouse: data.warehouseName!,\n         namespace: data.newNamespaceName,\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx\nindex ffd58a652cf32..7bda0f9e4b228 100644\n--- a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx\n@@ -79,7 +79,7 @@ export const TableRowComponent = ({ table, schema, namespace }: TableRowComponen\n   const { mutateAsync: updateFDW } = useFDWUpdateMutation()\n   const { mutateAsync: dropForeignTable } = useFDWDropForeignTableMutation()\n   const { mutateAsync: deleteNamespaceTable, isLoading: isDeletingNamespaceTable } =\n-    useIcebergNamespaceTableDeleteMutation({ projectRef, onError: () => {} })\n+    useIcebergNamespaceTableDeleteMutation({ onError: () => {} })\n   const { mutateAsync: updatePublication } = useUpdatePublicationMutation()\n   const { mutateAsync: startPipeline } = useStartPipelineMutation()\n \n@@ -226,6 +226,7 @@ export const TableRowComponent = ({ table, schema, namespace }: TableRowComponen\n \n       const wrapperValues = convertKVStringArrayToJson(wrapperInstance?.server_options ?? [])\n       await deleteNamespaceTable({\n+        projectRef,\n         catalogUri: wrapperValues.catalog_uri,\n         warehouse: wrapperValues.warehouse,\n         namespace: namespace,\n@@ -255,6 +256,7 @@ export const TableRowComponent = ({ table, schema, namespace }: TableRowComponen\n       setIsRemovingTable(true)\n       const wrapperValues = convertKVStringArrayToJson(wrapperInstance?.server_options ?? [])\n       await deleteNamespaceTable({\n+        projectRef,\n         catalogUri: wrapperValues.catalog_uri,\n         warehouse: wrapperValues.warehouse,\n         namespace: namespace,\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/index.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/index.tsx\nindex 9672e9b7bf15a..12c9c4ee83d96 100644\n--- a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/index.tsx\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/index.tsx\n@@ -123,11 +123,9 @@ export const NamespaceWithTables = ({\n \n   const { mutateAsync: importForeignSchema, isPending: isImportingForeignSchema } =\n     useFDWImportForeignSchemaMutation()\n-  const { mutateAsync: deleteNamespace } = useIcebergNamespaceDeleteMutation({ projectRef })\n+  const { mutateAsync: deleteNamespace } = useIcebergNamespaceDeleteMutation()\n   const { mutateAsync: dropForeignTable } = useFDWDropForeignTableMutation()\n-  const { mutateAsync: deleteNamespaceTable } = useIcebergNamespaceTableDeleteMutation({\n-    projectRef,\n-  })\n+  const { mutateAsync: deleteNamespaceTable } = useIcebergNamespaceTableDeleteMutation()\n \n   const rescanNamespace = async () => {\n     if (!icebergWrapper) return console.error('Iceberg wrapper cannot be found')\n@@ -194,6 +192,7 @@ export const NamespaceWithTables = ({\n       await Promise.all(\n         allTables.map((table) =>\n           deleteNamespaceTable({\n+            projectRef,\n             catalogUri,\n             warehouse: bucketId,\n             namespace,\n@@ -214,7 +213,7 @@ export const NamespaceWithTables = ({\n         )\n       )\n \n-      await deleteNamespace({ catalogUri, warehouse: bucketId, namespace })\n+      await deleteNamespace({ projectRef, catalogUri, warehouse: bucketId, namespace })\n \n       toast.success(`Successfully deleted namespace \"${namespace}\"`)\n       setShowConfirmDeleteNamespace(false)\ndiff --git a/apps/studio/data/api-keys/temp-api-keys-query.ts b/apps/studio/data/api-keys/temp-api-keys-query.ts\nindex eed65a90814bb..44e821a62e6c3 100644\n--- a/apps/studio/data/api-keys/temp-api-keys-query.ts\n+++ b/apps/studio/data/api-keys/temp-api-keys-query.ts\n@@ -35,12 +35,14 @@ export async function getTemporaryAPIKey(\n export type TemporaryAPIKeyData = Awaited<ReturnType<typeof getTemporaryAPIKey>>\n \n export const useTemporaryAPIKeyQuery = <TData = TemporaryAPIKeyData>(\n-  { projectRef, expiry = 300 }: getTemporaryAPIKeyVariables,\n+  { projectRef }: { projectRef?: string },\n   {\n     enabled = true,\n     ...options\n   }: UseCustomQueryOptions<TemporaryAPIKeyData, ResponseError, TData> = {}\n ) => {\n+  // The expiry time is set to 60 seconds in the API.\n+  const expiry = 60\n   return useQuery<TemporaryAPIKeyData, ResponseError, TData>({\n     queryKey: apiKeysKeys.temporary(projectRef),\n     queryFn: ({ signal }) => getTemporaryAPIKey({ projectRef, expiry }, signal),\ndiff --git a/apps/studio/data/storage/iceberg-namespace-create-mutation.ts b/apps/studio/data/storage/iceberg-namespace-create-mutation.ts\nindex 7a86983df7c92..fc638a387ff3c 100644\n--- a/apps/studio/data/storage/iceberg-namespace-create-mutation.ts\n+++ b/apps/studio/data/storage/iceberg-namespace-create-mutation.ts\n@@ -1,12 +1,13 @@\n import { useMutation, useQueryClient } from '@tanstack/react-query'\n import { toast } from 'sonner'\n \n-import { useTemporaryAPIKeyQuery } from 'data/api-keys/temp-api-keys-query'\n+import { getOrRefreshTemporaryApiKey } from 'data/api-keys/temp-api-keys-utils'\n import { constructHeaders, fetchHandler, handleError } from 'data/fetchers'\n import type { ResponseError, UseCustomMutationOptions } from 'types'\n import { storageKeys } from './keys'\n \n type CreateIcebergNamespaceVariables = {\n+  projectRef?: string\n   catalogUri: string\n   warehouse: string\n   namespace: string\n@@ -15,13 +16,16 @@ type CreateIcebergNamespaceVariables = {\n const errorPrefix = 'Failed to create Iceberg namespace'\n \n async function createIcebergNamespace({\n+  projectRef,\n   catalogUri,\n   warehouse,\n   namespace,\n-  tempApiKey,\n-}: CreateIcebergNamespaceVariables & { tempApiKey?: string }) {\n+}: CreateIcebergNamespaceVariables) {\n   try {\n-    if (!tempApiKey) throw new Error(`${errorPrefix}: API Key missing`)\n+    if (!projectRef) throw new Error(`${errorPrefix}: projectRef is required`)\n+\n+    const tempApiKeyObj = await getOrRefreshTemporaryApiKey(projectRef)\n+    const tempApiKey = tempApiKeyObj.apiKey\n \n     let headers = new Headers()\n     headers = await constructHeaders({\n@@ -52,11 +56,10 @@ async function createIcebergNamespace({\n type IcebergNamespaceCreateData = Awaited<ReturnType<typeof createIcebergNamespace>>\n \n export const useIcebergNamespaceCreateMutation = ({\n-  projectRef,\n   onSuccess,\n   onError,\n   ...options\n-}: { projectRef?: string } & Omit<\n+}: Omit<\n   UseCustomMutationOptions<\n     IcebergNamespaceCreateData,\n     ResponseError,\n@@ -65,15 +68,13 @@ export const useIcebergNamespaceCreateMutation = ({\n   'mutationFn'\n > = {}) => {\n   const queryClient = useQueryClient()\n-  const { data } = useTemporaryAPIKeyQuery({ projectRef })\n-  const tempApiKey = data?.api_key\n \n   return useMutation<IcebergNamespaceCreateData, ResponseError, CreateIcebergNamespaceVariables>({\n-    mutationFn: (vars) => createIcebergNamespace({ ...vars, tempApiKey }),\n+    mutationFn: (vars) => createIcebergNamespace({ ...vars }),\n     async onSuccess(data, variables, context) {\n       await queryClient.invalidateQueries({\n         queryKey: storageKeys.icebergNamespace({\n-          projectRef,\n+          projectRef: variables.projectRef,\n           catalog: variables.catalogUri,\n           warehouse: variables.warehouse,\n           namespace: variables.namespace,\n@@ -81,7 +82,7 @@ export const useIcebergNamespaceCreateMutation = ({\n       })\n       await queryClient.invalidateQueries({\n         queryKey: storageKeys.icebergNamespaces({\n-          projectRef,\n+          projectRef: variables.projectRef,\n           catalog: variables.catalogUri,\n           warehouse: variables.warehouse,\n         }),\ndiff --git a/apps/studio/data/storage/iceberg-namespace-delete-mutation.ts b/apps/studio/data/storage/iceberg-namespace-delete-mutation.ts\nindex b22c82c628617..86bbc58faf2ba 100644\n--- a/apps/studio/data/storage/iceberg-namespace-delete-mutation.ts\n+++ b/apps/studio/data/storage/iceberg-namespace-delete-mutation.ts\n@@ -1,12 +1,13 @@\n import { useMutation, useQueryClient } from '@tanstack/react-query'\n import { toast } from 'sonner'\n \n-import { useTemporaryAPIKeyQuery } from 'data/api-keys/temp-api-keys-query'\n+import { getOrRefreshTemporaryApiKey } from 'data/api-keys/temp-api-keys-utils'\n import { constructHeaders, fetchHandler, handleError } from 'data/fetchers'\n import type { ResponseError, UseCustomMutationOptions } from 'types'\n import { storageKeys } from './keys'\n \n type DeleteIcebergNamespaceVariables = {\n+  projectRef?: string\n   catalogUri: string\n   warehouse: string\n   namespace: string\n@@ -15,13 +16,16 @@ type DeleteIcebergNamespaceVariables = {\n const errorPrefix = 'Failed to delete Iceberg namespace'\n \n async function deleteIcebergNamespace({\n+  projectRef,\n   catalogUri,\n   warehouse,\n   namespace,\n-  tempApiKey,\n-}: DeleteIcebergNamespaceVariables & { tempApiKey?: string }) {\n+}: DeleteIcebergNamespaceVariables) {\n   try {\n-    if (!tempApiKey) throw new Error(`${errorPrefix}: API Key missing`)\n+    if (!projectRef) throw new Error(`${errorPrefix}: projectRef is required`)\n+\n+    const tempApiKeyObj = await getOrRefreshTemporaryApiKey(projectRef)\n+    const tempApiKey = tempApiKeyObj.apiKey\n \n     let headers = new Headers()\n     headers = await constructHeaders({\n@@ -48,11 +52,10 @@ async function deleteIcebergNamespace({\n type IcebergNamespaceDeleteData = Awaited<ReturnType<typeof deleteIcebergNamespace>>\n \n export const useIcebergNamespaceDeleteMutation = ({\n-  projectRef,\n   onSuccess,\n   onError,\n   ...options\n-}: { projectRef?: string } & Omit<\n+}: Omit<\n   UseCustomMutationOptions<\n     IcebergNamespaceDeleteData,\n     ResponseError,\n@@ -61,15 +64,13 @@ export const useIcebergNamespaceDeleteMutation = ({\n   'mutationFn'\n > = {}) => {\n   const queryClient = useQueryClient()\n-  const { data } = useTemporaryAPIKeyQuery({ projectRef })\n-  const tempApiKey = data?.api_key\n \n   return useMutation<IcebergNamespaceDeleteData, ResponseError, DeleteIcebergNamespaceVariables>({\n-    mutationFn: (vars) => deleteIcebergNamespace({ ...vars, tempApiKey }),\n+    mutationFn: (vars) => deleteIcebergNamespace({ ...vars }),\n     async onSuccess(data, variables, context) {\n       await queryClient.invalidateQueries({\n         queryKey: storageKeys.icebergNamespaces({\n-          projectRef,\n+          projectRef: variables.projectRef,\n           catalog: variables.catalogUri,\n           warehouse: variables.warehouse,\n         }),\ndiff --git a/apps/studio/data/storage/iceberg-namespace-table-delete-mutation.ts b/apps/studio/data/storage/iceberg-namespace-table-delete-mutation.ts\nindex c89bc814074bf..23ebca378629c 100644\n--- a/apps/studio/data/storage/iceberg-namespace-table-delete-mutation.ts\n+++ b/apps/studio/data/storage/iceberg-namespace-table-delete-mutation.ts\n@@ -1,7 +1,7 @@\n import { useMutation, useQueryClient } from '@tanstack/react-query'\n import { toast } from 'sonner'\n \n-import { useTemporaryAPIKeyQuery } from 'data/api-keys/temp-api-keys-query'\n+import { getOrRefreshTemporaryApiKey } from 'data/api-keys/temp-api-keys-utils'\n import { constructHeaders, fetchHandler, handleError } from 'data/fetchers'\n import type { ResponseError, UseCustomMutationOptions } from 'types'\n import { storageKeys } from './keys'\n@@ -17,14 +17,17 @@ type DeleteIcebergNamespaceTableVariables = {\n const errorPrefix = 'Failed to delete Iceberg namespace table'\n \n async function deleteIcebergNamespaceTable({\n+  projectRef,\n   catalogUri,\n   warehouse,\n   namespace,\n   table,\n-  tempApiKey,\n-}: DeleteIcebergNamespaceTableVariables & { tempApiKey?: string }) {\n+}: DeleteIcebergNamespaceTableVariables) {\n   try {\n-    if (!tempApiKey) throw new Error(`${errorPrefix}: API Key missing`)\n+    if (!projectRef) throw new Error(`${errorPrefix}: projectRef is required`)\n+\n+    const tempApiKeyObj = await getOrRefreshTemporaryApiKey(projectRef)\n+    const tempApiKey = tempApiKeyObj.apiKey\n \n     let headers = new Headers()\n     headers = await constructHeaders({\n@@ -49,11 +52,10 @@ async function deleteIcebergNamespaceTable({\n type IcebergNamespaceTableDeleteData = Awaited<ReturnType<typeof deleteIcebergNamespaceTable>>\n \n export const useIcebergNamespaceTableDeleteMutation = ({\n-  projectRef,\n   onSuccess,\n   onError,\n   ...options\n-}: { projectRef?: string } & Omit<\n+}: Omit<\n   UseCustomMutationOptions<\n     IcebergNamespaceTableDeleteData,\n     ResponseError,\n@@ -62,19 +64,17 @@ export const useIcebergNamespaceTableDeleteMutation = ({\n   'mutationFn'\n > = {}) => {\n   const queryClient = useQueryClient()\n-  const { data } = useTemporaryAPIKeyQuery({ projectRef })\n-  const tempApiKey = data?.api_key\n \n   return useMutation<\n     IcebergNamespaceTableDeleteData,\n     ResponseError,\n     DeleteIcebergNamespaceTableVariables\n   >({\n-    mutationFn: (vars) => deleteIcebergNamespaceTable({ ...vars, tempApiKey }),\n+    mutationFn: (vars) => deleteIcebergNamespaceTable({ ...vars }),\n     async onSuccess(data, variables, context) {\n       await queryClient.invalidateQueries({\n         queryKey: storageKeys.icebergNamespace({\n-          projectRef,\n+          projectRef: variables.projectRef,\n           catalog: variables.catalogUri,\n           warehouse: variables.warehouse,\n           namespace: variables.namespace,\ndiff --git a/apps/studio/data/storage/iceberg-namespace-tables-query.ts b/apps/studio/data/storage/iceberg-namespace-tables-query.ts\nindex 1f05938d9ae77..e5edcf0bdcaa9 100644\n--- a/apps/studio/data/storage/iceberg-namespace-tables-query.ts\n+++ b/apps/studio/data/storage/iceberg-namespace-tables-query.ts\n@@ -1,6 +1,6 @@\n import { useQuery } from '@tanstack/react-query'\n \n-import { useTemporaryAPIKeyQuery } from 'data/api-keys/temp-api-keys-query'\n+import { getOrRefreshTemporaryApiKey } from 'data/api-keys/temp-api-keys-utils'\n import { constructHeaders, fetchHandler, handleError } from 'data/fetchers'\n import type { ResponseError, UseCustomQueryOptions } from 'types'\n import { storageKeys } from './keys'\n@@ -15,13 +15,16 @@ type GetNamespaceTablesVariables = {\n const errorPrefix = 'Failed to retrieve Iceberg namespace tables'\n \n async function getNamespaceTables({\n+  projectRef,\n   catalogUri,\n   warehouse,\n   namespace,\n-  tempApiKey,\n-}: GetNamespaceTablesVariables & { tempApiKey?: string }) {\n+}: GetNamespaceTablesVariables) {\n   try {\n-    if (!tempApiKey) throw new Error(`${errorPrefix}: API Key missing`)\n+    if (!projectRef) throw new Error(`${errorPrefix}: projectRef is required`)\n+\n+    const tempApiKeyObj = await getOrRefreshTemporaryApiKey(projectRef)\n+    const tempApiKey = tempApiKeyObj.apiKey\n \n     let headers = new Headers()\n     headers = await constructHeaders({\n@@ -61,8 +64,6 @@ export const useIcebergNamespaceTablesQuery = <TData = IcebergNamespaceTablesDat\n   }: UseCustomQueryOptions<IcebergNamespaceTablesData, IcebergNamespaceTablesError, TData> = {}\n ) => {\n   const { projectRef, catalogUri, warehouse, namespace } = params\n-  const { data } = useTemporaryAPIKeyQuery({ projectRef })\n-  const tempApiKey = data?.api_key\n \n   return useQuery<IcebergNamespaceTablesData, IcebergNamespaceTablesError, TData>({\n     queryKey: storageKeys.icebergNamespaceTables({\n@@ -71,11 +72,10 @@ export const useIcebergNamespaceTablesQuery = <TData = IcebergNamespaceTablesDat\n       namespace,\n       catalog: catalogUri,\n     }),\n-    queryFn: () => getNamespaceTables({ ...params, tempApiKey }),\n+    queryFn: () => getNamespaceTables({ ...params }),\n     enabled:\n       enabled &&\n       typeof projectRef !== 'undefined' &&\n-      typeof tempApiKey !== 'undefined' &&\n       typeof warehouse !== 'undefined' &&\n       typeof namespace !== 'undefined' &&\n       typeof catalogUri !== 'undefined',\ndiff --git a/apps/studio/data/storage/iceberg-namespaces-query.ts b/apps/studio/data/storage/iceberg-namespaces-query.ts\nindex 6f311e685264d..be5e4057388ac 100644\n--- a/apps/studio/data/storage/iceberg-namespaces-query.ts\n+++ b/apps/studio/data/storage/iceberg-namespaces-query.ts\n@@ -1,6 +1,6 @@\n import { useQuery } from '@tanstack/react-query'\n \n-import { useTemporaryAPIKeyQuery } from 'data/api-keys/temp-api-keys-query'\n+import { getOrRefreshTemporaryApiKey } from 'data/api-keys/temp-api-keys-utils'\n import { constructHeaders, fetchHandler, handleError } from 'data/fetchers'\n import type { ResponseError, UseCustomQueryOptions } from 'types'\n import { storageKeys } from './keys'\n@@ -13,13 +13,12 @@ type GetNamespacesVariables = {\n \n const errorPrefix = 'Failed to retrieve Iceberg namespaces'\n \n-async function getNamespaces({\n-  catalogUri,\n-  warehouse,\n-  tempApiKey,\n-}: GetNamespacesVariables & { tempApiKey?: string }) {\n+async function getNamespaces({ projectRef, catalogUri, warehouse }: GetNamespacesVariables) {\n   try {\n-    if (!tempApiKey) throw new Error(`${errorPrefix}: API Key missing`)\n+    if (!projectRef) throw new Error(`${errorPrefix}: projectRef is required`)\n+\n+    const tempApiKeyObj = await getOrRefreshTemporaryApiKey(projectRef)\n+    const tempApiKey = tempApiKeyObj.apiKey\n \n     let headers = new Headers()\n     headers = await constructHeaders({\n@@ -56,8 +55,6 @@ export const useIcebergNamespacesQuery = <TData = IcebergNamespacesData>(\n   }: UseCustomQueryOptions<IcebergNamespacesData, IcebergNamespacesError, TData> = {}\n ) => {\n   const { projectRef, catalogUri, warehouse } = params\n-  const { data } = useTemporaryAPIKeyQuery({ projectRef })\n-  const tempApiKey = data?.api_key\n \n   return useQuery<IcebergNamespacesData, IcebergNamespacesError, TData>({\n     queryKey: storageKeys.icebergNamespaces({\n@@ -65,11 +62,10 @@ export const useIcebergNamespacesQuery = <TData = IcebergNamespacesData>(\n       warehouse,\n       catalog: catalogUri,\n     }),\n-    queryFn: () => getNamespaces({ ...params, tempApiKey }),\n+    queryFn: () => getNamespaces({ ...params }),\n     enabled:\n       options &&\n       typeof projectRef !== 'undefined' &&\n-      typeof tempApiKey !== 'undefined' &&\n       typeof catalogUri !== 'undefined' &&\n       catalogUri.length > 0 &&\n       typeof warehouse !== 'undefined' &&\ndiff --git a/apps/studio/hooks/use-supabase-client-query.ts b/apps/studio/hooks/use-supabase-client-query.ts\nindex acada318d47b1..032214560bc24 100644\n--- a/apps/studio/hooks/use-supabase-client-query.ts\n+++ b/apps/studio/hooks/use-supabase-client-query.ts\n@@ -38,7 +38,7 @@ export const useSupabaseClientQuery = (\n   { enabled = true, ...options } = {}\n ) => {\n   const { data: settings } = useProjectSettingsV2Query({ projectRef })\n-  const { data: temporaryApiKeyData } = useTemporaryAPIKeyQuery({ projectRef, expiry: 3600 })\n+  const { data: temporaryApiKeyData } = useTemporaryAPIKeyQuery({ projectRef })\n \n   const endpoint = settings\n     ? `${settings?.app_config?.protocol ?? 'https'}://${settings?.app_config?.endpoint}`\n",
			"diffSize": 20138,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "da4712532d54b80e0373932899a312cdadfea1a1",
			"message": "chore(studio): use custom github local dev app (#40384)\n\n* chore(studio): use custom github local dev app\n\n* chore: remove debug log",
			"user": "avallete",
			"timestamp": "2025-11-21T13:24:44Z",
			"author": {
				"name": "Andrew Valleteau",
				"email": "avallete@users.noreply.github.com",
				"username": "avallete"
			},
			"files": {
				"added": [],
				"modified": ["apps/studio/lib/github.ts"],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/lib/github.ts b/apps/studio/lib/github.ts\nindex e961960cf0ea4..e0d6ebd559413 100644\n--- a/apps/studio/lib/github.ts\n+++ b/apps/studio/lib/github.ts\n@@ -2,22 +2,24 @@ import { LOCAL_STORAGE_KEYS } from 'common'\n import { makeRandomString } from './helpers'\n \n const GITHUB_INTEGRATION_APP_NAME =\n-  process.env.NEXT_PUBLIC_IS_NIMBUS !== undefined\n+  process.env.NEXT_PUBLIC_GITHUB_INTEGRATION_APP_NAME ||\n+  (process.env.NEXT_PUBLIC_IS_NIMBUS !== undefined\n     ? 'supabase-snap'\n     : process.env.NEXT_PUBLIC_ENVIRONMENT === 'prod'\n       ? `supabase`\n       : process.env.NEXT_PUBLIC_ENVIRONMENT === 'staging'\n         ? `supabase-staging`\n-        : `supabase-local-testing`\n+        : `supabase-local-testing`)\n \n const GITHUB_INTEGRATION_CLIENT_ID =\n-  process.env.NEXT_PUBLIC_IS_NIMBUS !== undefined\n+  process.env.NEXT_PUBLIC_GITHUB_INTEGRATION_CLIENT_ID ||\n+  (process.env.NEXT_PUBLIC_IS_NIMBUS !== undefined\n     ? 'Iv23li2pAiqDGgaSrP8q'\n     : process.env.NEXT_PUBLIC_ENVIRONMENT === 'prod'\n       ? `Iv1.b91a6d8eaa272168`\n       : process.env.NEXT_PUBLIC_ENVIRONMENT === 'staging'\n         ? `Iv1.2681ab9a0360d8ad`\n-        : `Iv1.5022a3b44d150fbf`\n+        : `Iv1.5022a3b44d150fbf`)\n \n const GITHUB_INTEGRATION_AUTHORIZATION_URL = `https://github.com/login/oauth/authorize?client_id=${GITHUB_INTEGRATION_CLIENT_ID}`\n export const GITHUB_INTEGRATION_INSTALLATION_URL = `https://github.com/apps/${GITHUB_INTEGRATION_APP_NAME}/installations/new`\n",
			"diffSize": 1480,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "bfef63e87417ea45de2d6e3eb7a2178c06ae4cb4",
			"message": "feat(mgmt-api): update reports API to use multiple attributes (#40473)\n\n* feat(mgmt-api): update reports API\n\nRelated to https://github.com/supabase/infrastructure/pull/27519 and https://linear.app/supabase/issue/API-551/extend-infra-monitoring-with-multi-attribute-response\n\n* tests: infra-monitoring-queries\n\n---------\n\nCo-authored-by: Ali Waseem <waseema393@gmail.com>",
			"user": "raulb",
			"timestamp": "2025-11-21T12:56:04Z",
			"author": {
				"name": "Raúl Barroso",
				"email": "code@raulb.dev",
				"username": "raulb"
			},
			"files": {
				"added": [
					"apps/studio/data/analytics/infra-monitoring-queries.test.ts"
				],
				"modified": [
					"apps/studio/data/analytics/infra-monitoring-queries.ts",
					"apps/studio/data/analytics/infra-monitoring-query.ts",
					"apps/studio/data/analytics/keys.ts"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/data/analytics/infra-monitoring-queries.test.ts b/apps/studio/data/analytics/infra-monitoring-queries.test.ts\nnew file mode 100644\nindex 0000000000000..5f32410872442\n--- /dev/null\n+++ b/apps/studio/data/analytics/infra-monitoring-queries.test.ts\n@@ -0,0 +1,72 @@\n+import { describe, expect, it } from 'vitest'\n+\n+import type { InfraMonitoringMultiData } from './infra-monitoring-query'\n+import { mapMultiResponseToAnalyticsData } from './infra-monitoring-queries'\n+\n+const mockResponse: InfraMonitoringMultiData = {\n+  data: [\n+    {\n+      period_start: '2024-01-02 03:04:00',\n+      values: {\n+        max_cpu_usage: '1.5',\n+        ram_usage: undefined,\n+      },\n+    },\n+    {\n+      period_start: '2024-01-02 04:04:00',\n+      values: {\n+        max_cpu_usage: undefined,\n+        ram_usage: '3',\n+      },\n+    },\n+  ],\n+  series: {\n+    max_cpu_usage: { format: 'percent', total: 2.5, totalAverage: 1.25, yAxisLimit: 100 },\n+    ram_usage: { format: 'bytes', total: 3, totalAverage: 1.5, yAxisLimit: 200 },\n+  },\n+}\n+\n+describe('mapMultiResponseToAnalyticsData', () => {\n+  it('maps attribute series and coerces values to numbers', () => {\n+    const result = mapMultiResponseToAnalyticsData(mockResponse, ['max_cpu_usage', 'ram_usage'])\n+\n+    expect(result.max_cpu_usage?.data).toStrictEqual([\n+      {\n+        period_start: '2024-01-02 03:04:00',\n+        periodStartFormatted: '03:04 02 Jan',\n+        max_cpu_usage: 1.5,\n+      },\n+      {\n+        period_start: '2024-01-02 04:04:00',\n+        periodStartFormatted: '04:04 02 Jan',\n+        max_cpu_usage: 0,\n+      },\n+    ])\n+\n+    expect(result.ram_usage?.data[0].ram_usage).toBe(0)\n+    expect(result.ram_usage?.data[1].ram_usage).toBe(3)\n+    expect(result.max_cpu_usage).toMatchObject({\n+      format: 'percent',\n+      total: 2.5,\n+      yAxisLimit: 100,\n+    })\n+  })\n+\n+  it('omits attributes that are missing series metadata', () => {\n+    const result = mapMultiResponseToAnalyticsData(mockResponse, [\n+      'max_cpu_usage',\n+      'ram_usage',\n+      'pg_stat_database_num_backends',\n+    ])\n+\n+    expect(result.max_cpu_usage).toBeDefined()\n+    expect(result.ram_usage).toBeDefined()\n+    expect(result.pg_stat_database_num_backends).toBeUndefined()\n+  })\n+\n+  it('uses a custom date format when provided', () => {\n+    const result = mapMultiResponseToAnalyticsData(mockResponse, ['max_cpu_usage'], 'YYYY/MM/DD')\n+\n+    expect(result.max_cpu_usage?.data[0].periodStartFormatted).toBe('2024/01/02')\n+  })\n+})\ndiff --git a/apps/studio/data/analytics/infra-monitoring-queries.ts b/apps/studio/data/analytics/infra-monitoring-queries.ts\nindex 7cc001a93900d..4ea93a774d996 100644\n--- a/apps/studio/data/analytics/infra-monitoring-queries.ts\n+++ b/apps/studio/data/analytics/infra-monitoring-queries.ts\n@@ -1,6 +1,24 @@\n-import { AnalyticsInterval } from './constants'\n+import { useMemo } from 'react'\n+import type { UseQueryResult } from '@tanstack/react-query'\n+\n+import dayjs from 'dayjs'\n+\n+import type { AnalyticsData, AnalyticsInterval } from './constants'\n import type { InfraMonitoringAttribute } from './infra-monitoring-query'\n-import { useInfraMonitoringQuery } from './infra-monitoring-query'\n+import {\n+  InfraMonitoringMultiData,\n+  InfraMonitoringError,\n+  useInfraMonitoringAttributesQuery,\n+  useInfraMonitoringQuery,\n+} from './infra-monitoring-query'\n+\n+const DEFAULT_DATE_FORMAT = 'HH:mm DD MMM'\n+const DEFAULT_ATTRIBUTE: InfraMonitoringAttribute = 'max_cpu_usage'\n+\n+type InfraQueryResult = Pick<\n+  UseQueryResult<AnalyticsData, InfraMonitoringError>,\n+  'data' | 'error' | 'isError' | 'isFetching' | 'isLoading' | 'status'\n+>\n \n export function useInfraMonitoringQueries(\n   attributes: InfraMonitoringAttribute[],\n@@ -12,18 +30,83 @@ export function useInfraMonitoringQueries(\n   data: any,\n   isVisible: boolean\n ) {\n-  return attributes.map((attribute) =>\n-    // eslint-disable-next-line react-hooks/rules-of-hooks\n-    useInfraMonitoringQuery(\n-      {\n-        projectRef: ref as string,\n-        attribute,\n-        startDate,\n-        endDate,\n-        interval,\n-        databaseIdentifier,\n-      },\n-      { enabled: data === undefined && isVisible }\n-    )\n+  const shouldFetch = data === undefined && isVisible\n+  const hasAttributes = attributes.length > 0\n+  const isSingleAttribute = attributes.length === 1\n+  const primaryAttribute = attributes[0] ?? DEFAULT_ATTRIBUTE\n+\n+  const singleAttributeQuery = useInfraMonitoringQuery(\n+    {\n+      projectRef: ref as string,\n+      attribute: primaryAttribute,\n+      startDate,\n+      endDate,\n+      interval,\n+      databaseIdentifier,\n+    },\n+    { enabled: shouldFetch && isSingleAttribute && hasAttributes }\n   )\n+\n+  const multiQuery = useInfraMonitoringAttributesQuery(\n+    {\n+      projectRef: ref as string,\n+      attributes,\n+      startDate,\n+      endDate,\n+      interval,\n+      databaseIdentifier,\n+    },\n+    { enabled: shouldFetch && attributes.length > 1 }\n+  )\n+\n+  const seriesByAttribute = useMemo(() => {\n+    if (!multiQuery.data) return undefined\n+    return mapMultiResponseToAnalyticsData(multiQuery.data, attributes)\n+  }, [multiQuery.data, attributes])\n+\n+  if (!hasAttributes) {\n+    return []\n+  }\n+\n+  if (isSingleAttribute) {\n+    return [singleAttributeQuery]\n+  }\n+\n+  return attributes.map<InfraQueryResult>((attribute) => ({\n+    data: seriesByAttribute?.[attribute],\n+    error: multiQuery.error,\n+    isError: multiQuery.isError,\n+    isFetching: multiQuery.isFetching,\n+    isLoading: multiQuery.isLoading,\n+    status: multiQuery.status,\n+  }))\n+}\n+\n+export function mapMultiResponseToAnalyticsData(\n+  response: InfraMonitoringMultiData,\n+  attributes: InfraMonitoringAttribute[],\n+  dateFormat: string = DEFAULT_DATE_FORMAT\n+) {\n+  return attributes.reduce<Record<string, AnalyticsData>>((acc, attribute) => {\n+    const metadata = response.series?.[attribute]\n+    if (!metadata) return acc\n+\n+    const dataPoints = response.data.map((point) => {\n+      const value = point.values?.[attribute]\n+      return {\n+        period_start: point.period_start,\n+        periodStartFormatted: dayjs(point.period_start).format(dateFormat),\n+        [attribute]: value === undefined ? 0 : Number(value),\n+      }\n+    })\n+\n+    acc[attribute] = {\n+      data: dataPoints,\n+      format: metadata.format,\n+      total: metadata.total,\n+      yAxisLimit: metadata.yAxisLimit,\n+    }\n+\n+    return acc\n+  }, {})\n }\ndiff --git a/apps/studio/data/analytics/infra-monitoring-query.ts b/apps/studio/data/analytics/infra-monitoring-query.ts\nindex b7604bbeefd4e..60dfd4b33815e 100644\n--- a/apps/studio/data/analytics/infra-monitoring-query.ts\n+++ b/apps/studio/data/analytics/infra-monitoring-query.ts\n@@ -35,6 +35,28 @@ export type InfraMonitoringVariables = {\n   modifier?: (x: number) => number\n }\n \n+export type InfraMonitoringSeriesMetadata = {\n+  yAxisLimit: number\n+  format: string\n+  total: number\n+  totalAverage: number\n+}\n+\n+export type InfraMonitoringMultiResponse = {\n+  data: {\n+    period_start: string\n+    values: Record<string, string | undefined>\n+  }[]\n+  series: Record<string, InfraMonitoringSeriesMetadata>\n+}\n+\n+export type InfraMonitoringMultiVariables = Omit<\n+  InfraMonitoringVariables,\n+  'attribute' | 'modifier'\n+> & {\n+  attributes: InfraMonitoringAttribute[]\n+}\n+\n export async function getInfraMonitoring(\n   {\n     projectRef,\n@@ -69,8 +91,44 @@ export async function getInfraMonitoring(\n   return data as unknown as AnalyticsData\n }\n \n+export async function getInfraMonitoringAttributes(\n+  {\n+    projectRef,\n+    attributes,\n+    startDate,\n+    endDate,\n+    interval = '1h',\n+    databaseIdentifier,\n+  }: InfraMonitoringMultiVariables,\n+  signal?: AbortSignal\n+) {\n+  if (!projectRef) throw new Error('Project ref is required')\n+  if (!attributes?.length) throw new Error('At least one attribute is required')\n+  if (!startDate) throw new Error('Start date is required')\n+  if (!endDate) throw new Error('End date is required')\n+\n+  const { data, error } = await get('/platform/projects/{ref}/infra-monitoring', {\n+    params: {\n+      path: { ref: projectRef },\n+      // Attributes support is not yet reflected in the generated client types.\n+      query: {\n+        attributes,\n+        startDate,\n+        endDate,\n+        interval,\n+        databaseIdentifier,\n+      } as any,\n+    },\n+    signal,\n+  })\n+\n+  if (error) handleError(error)\n+  return data as unknown as InfraMonitoringMultiResponse\n+}\n+\n export type InfraMonitoringData = Awaited<ReturnType<typeof getInfraMonitoring>>\n export type InfraMonitoringError = unknown\n+export type InfraMonitoringMultiData = Awaited<ReturnType<typeof getInfraMonitoringAttributes>>\n \n export const useInfraMonitoringQuery = <TData = InfraMonitoringData>(\n   {\n@@ -123,3 +181,40 @@ export const useInfraMonitoringQuery = <TData = InfraMonitoringData>(\n     staleTime: 1000 * 60,\n     ...options,\n   })\n+\n+export const useInfraMonitoringAttributesQuery = <TData = InfraMonitoringMultiData>(\n+  {\n+    projectRef,\n+    attributes,\n+    startDate,\n+    endDate,\n+    interval = '1h',\n+    databaseIdentifier,\n+  }: InfraMonitoringMultiVariables,\n+  {\n+    enabled = true,\n+    ...options\n+  }: UseCustomQueryOptions<InfraMonitoringMultiData, InfraMonitoringError, TData> = {}\n+) =>\n+  useQuery<InfraMonitoringMultiData, InfraMonitoringError, TData>({\n+    queryKey: analyticsKeys.infraMonitoringGroup(projectRef, {\n+      attributes,\n+      startDate,\n+      endDate,\n+      interval,\n+      databaseIdentifier,\n+    }),\n+    queryFn: ({ signal }) =>\n+      getInfraMonitoringAttributes(\n+        { projectRef, attributes, startDate, endDate, interval, databaseIdentifier },\n+        signal\n+      ),\n+    enabled:\n+      enabled &&\n+      typeof projectRef !== 'undefined' &&\n+      !!attributes?.length &&\n+      typeof startDate !== 'undefined' &&\n+      typeof endDate !== 'undefined',\n+    staleTime: 1000 * 60,\n+    ...options,\n+  })\ndiff --git a/apps/studio/data/analytics/keys.ts b/apps/studio/data/analytics/keys.ts\nindex 26aca0b0f365d..82ed6a133220e 100644\n--- a/apps/studio/data/analytics/keys.ts\n+++ b/apps/studio/data/analytics/keys.ts\n@@ -121,6 +121,35 @@ export const analyticsKeys = {\n       'infra-monitoring',\n       { attribute, startDate, endDate, interval, databaseIdentifier },\n     ] as const,\n+  infraMonitoringGroup: (\n+    projectRef: string | undefined,\n+    {\n+      attributes,\n+      startDate,\n+      endDate,\n+      interval,\n+      databaseIdentifier,\n+    }: {\n+      attributes?: string[]\n+      startDate?: string\n+      endDate?: string\n+      interval?: string\n+      databaseIdentifier?: string\n+    }\n+  ) =>\n+    [\n+      'projects',\n+      projectRef,\n+      'infra-monitoring',\n+      'group',\n+      {\n+        attributes: attributes ? [...attributes].sort() : undefined,\n+        startDate,\n+        endDate,\n+        interval,\n+        databaseIdentifier,\n+      },\n+    ] as const,\n   projectMetrics: (projectRef: string | undefined, { interval }: { interval?: string }) =>\n     ['projects', projectRef, 'project.metrics', { interval }] as const,\n   usageApiCounts: (projectRef: string | undefined, interval: string | undefined) =>\n",
			"diffSize": 11181,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "9fdc3dd8dee33b74ecac43a614c3268e12d31e4d",
			"message": "ref(etl): Improve updates, rollbacks and errors UI (#40644)",
			"user": "iambriccardo",
			"timestamp": "2025-11-21T10:30:39Z",
			"author": {
				"name": "Riccardo Busetti",
				"email": "riccardo.busetti@supabase.io",
				"username": "iambriccardo"
			},
			"files": {
				"added": [
					"apps/studio/components/interfaces/Database/ETL/ErrorDetailsButton.tsx",
					"apps/studio/components/interfaces/Database/ETL/ResetTableButton.tsx",
					"apps/studio/data/etl/restart-pipeline-helper.ts",
					"apps/studio/data/etl/use-table-reset.ts"
				],
				"modified": [
					"apps/studio/components/interfaces/Database/ETL/DestinationPanel/DestinationPanel.tsx",
					"apps/studio/components/interfaces/Database/ETL/DestinationPanel/PublicationSelection.tsx",
					"apps/studio/components/interfaces/Database/ETL/DestinationRow.tsx",
					"apps/studio/components/interfaces/Database/ETL/Destinations.tsx",
					"apps/studio/components/interfaces/Database/ETL/ErroredTableDetails.tsx",
					"apps/studio/components/interfaces/Database/ETL/ReplicationPipelineStatus/ReplicationPipelineStatus.tsx",
					"apps/studio/components/interfaces/Database/ETL/RetryOptionsDropdown.tsx",
					"apps/studio/components/interfaces/Database/ETL/RowMenu.tsx",
					"apps/studio/components/interfaces/Database/ETL/UpdateVersionModal.tsx",
					"apps/studio/components/interfaces/Sidebar.tsx",
					"packages/ui-patterns/src/Dialogs/ConfirmationModal.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Database/ETL/DestinationPanel/DestinationPanel.tsx b/apps/studio/components/interfaces/Database/ETL/DestinationPanel/DestinationPanel.tsx\nindex 7ac88336bc7f5..ac7291671b07a 100644\n--- a/apps/studio/components/interfaces/Database/ETL/DestinationPanel/DestinationPanel.tsx\n+++ b/apps/studio/components/interfaces/Database/ETL/DestinationPanel/DestinationPanel.tsx\n@@ -15,6 +15,7 @@ import { useCreateDestinationPipelineMutation } from 'data/etl/create-destinatio\n import { useReplicationDestinationByIdQuery } from 'data/etl/destination-by-id-query'\n import { useReplicationPipelineByIdQuery } from 'data/etl/pipeline-by-id-query'\n import { useReplicationPublicationsQuery } from 'data/etl/publications-query'\n+import { useRestartPipelineHelper } from 'data/etl/restart-pipeline-helper'\n import { useStartPipelineMutation } from 'data/etl/start-pipeline-mutation'\n import { useUpdateDestinationPipelineMutation } from 'data/etl/update-destination-pipeline-mutation'\n import { useIcebergNamespaceCreateMutation } from 'data/storage/iceberg-namespace-create-mutation'\n@@ -36,6 +37,7 @@ import {\n   SheetSection,\n   SheetTitle,\n } from 'ui'\n+import { NewPublicationPanel } from '../NewPublicationPanel'\n import { ReplicationDisclaimerDialog } from '../ReplicationDisclaimerDialog'\n import { AdvancedSettings } from './AdvancedSettings'\n import { DestinationNameInput } from './DestinationNameInput'\n@@ -88,6 +90,7 @@ export const DestinationPanel = ({\n \n   const editMode = !!existingDestination\n   const [showDisclaimerDialog, setShowDisclaimerDialog] = useState(false)\n+  const [publicationPanelVisible, setPublicationPanelVisible] = useState(false)\n   const [pendingFormValues, setPendingFormValues] = useState<z.infer<typeof FormSchema> | null>(\n     null\n   )\n@@ -104,12 +107,13 @@ export const DestinationPanel = ({\n     })\n \n   const { mutateAsync: startPipeline, isPending: startingPipeline } = useStartPipelineMutation()\n+  const { restartPipeline } = useRestartPipelineHelper()\n \n   const { mutateAsync: createS3AccessKey, isPending: isCreatingS3AccessKey } =\n     useS3AccessKeyCreateMutation()\n \n   const { mutateAsync: createNamespace, isPending: isCreatingNamespace } =\n-    useIcebergNamespaceCreateMutation()\n+    useIcebergNamespaceCreateMutation({ projectRef })\n \n   const {\n     data: publications = [],\n@@ -317,6 +321,7 @@ export const DestinationPanel = ({\n             snapshot\n           )\n           toast.success('Settings applied. Restarting the pipeline...')\n+          restartPipeline({ projectRef, pipelineId: existingDestination.pipelineId })\n         } else {\n           setRequestStatus(\n             existingDestination.pipelineId,\n@@ -324,8 +329,8 @@ export const DestinationPanel = ({\n             snapshot\n           )\n           toast.success('Settings applied. Starting the pipeline...')\n+          startPipeline({ projectRef, pipelineId: existingDestination.pipelineId })\n         }\n-        startPipeline({ projectRef, pipelineId: existingDestination.pipelineId })\n         onClose()\n       } else {\n         let destinationConfig: any = {}\n@@ -440,7 +445,11 @@ export const DestinationPanel = ({\n   return (\n     <>\n       <Sheet open={visible} onOpenChange={onClose}>\n-        <SheetContent showClose={false} size=\"default\">\n+        <SheetContent\n+          showClose={false}\n+          size=\"default\"\n+          className={publicationPanelVisible ? 'right-32' : 'right-0'}\n+        >\n           <div className=\"flex flex-col h-full\" tabIndex={-1}>\n             <SheetHeader>\n               <SheetTitle>{editMode ? 'Edit destination' : 'Create a new destination'}</SheetTitle>\n@@ -467,7 +476,12 @@ export const DestinationPanel = ({\n \n                       <div className=\"space-y-4\">\n                         <DestinationNameInput form={form} />\n-                        <PublicationSelection form={form} sourceId={sourceId} visible={visible} />\n+                        <PublicationSelection\n+                          form={form}\n+                          sourceId={sourceId}\n+                          visible={visible}\n+                          onSelectNewPublication={() => setPublicationPanelVisible(true)}\n+                        />\n                       </div>\n                     </div>\n                     <DialogSectionSeparator />\n@@ -514,6 +528,12 @@ export const DestinationPanel = ({\n         </SheetContent>\n       </Sheet>\n \n+      <NewPublicationPanel\n+        sourceId={sourceId}\n+        visible={publicationPanelVisible}\n+        onClose={() => setPublicationPanelVisible(false)}\n+      />\n+\n       <ReplicationDisclaimerDialog\n         open={showDisclaimerDialog}\n         onOpenChange={handleDisclaimerDialogChange}\ndiff --git a/apps/studio/components/interfaces/Database/ETL/DestinationPanel/PublicationSelection.tsx b/apps/studio/components/interfaces/Database/ETL/DestinationPanel/PublicationSelection.tsx\nindex 7c23c1ded6427..b713eabc1af79 100644\n--- a/apps/studio/components/interfaces/Database/ETL/DestinationPanel/PublicationSelection.tsx\n+++ b/apps/studio/components/interfaces/Database/ETL/DestinationPanel/PublicationSelection.tsx\n@@ -1,4 +1,4 @@\n-import { useMemo, useState } from 'react'\n+import { useMemo } from 'react'\n import type { UseFormReturn } from 'react-hook-form'\n \n import { useParams } from 'common'\n@@ -9,7 +9,6 @@ import { useSelectedProjectQuery } from 'hooks/misc/useSelectedProject'\n import { FormControl_Shadcn_, FormField_Shadcn_ } from 'ui'\n import { Admonition } from 'ui-patterns'\n import { FormItemLayout } from 'ui-patterns/form/FormItemLayout/FormItemLayout'\n-import { NewPublicationPanel } from '../NewPublicationPanel'\n import { PublicationsComboBox } from '../PublicationsComboBox'\n import type { DestinationPanelSchemaType } from './DestinationPanel.schema'\n \n@@ -17,15 +16,19 @@ type PublicationSelectionProps = {\n   form: UseFormReturn<DestinationPanelSchemaType>\n   sourceId?: number\n   visible: boolean\n+  onSelectNewPublication: () => void\n }\n \n-export const PublicationSelection = ({ form, sourceId, visible }: PublicationSelectionProps) => {\n+export const PublicationSelection = ({\n+  form,\n+  sourceId,\n+  visible,\n+  onSelectNewPublication,\n+}: PublicationSelectionProps) => {\n   const { ref: projectRef } = useParams()\n   const { data: project } = useSelectedProjectQuery()\n   const { publicationName } = form.watch()\n \n-  const [publicationPanelVisible, setPublicationPanelVisible] = useState(false)\n-\n   const {\n     data: publications = [],\n     isLoading: isLoadingPublications,\n@@ -64,7 +67,7 @@ export const PublicationSelection = ({ form, sourceId, visible }: PublicationSel\n                 isLoadingPublications={isLoadingPublications}\n                 isLoadingCheck={!!selectedPublication && isLoadingCheck}\n                 field={field}\n-                onNewPublicationClick={() => setPublicationPanelVisible(true)}\n+                onNewPublicationClick={() => onSelectNewPublication()}\n               />\n             </FormControl_Shadcn_>\n             {isSelectedPublicationMissing ? (\n@@ -98,12 +101,6 @@ export const PublicationSelection = ({ form, sourceId, visible }: PublicationSel\n           </FormItemLayout>\n         )}\n       />\n-\n-      <NewPublicationPanel\n-        sourceId={sourceId}\n-        visible={publicationPanelVisible}\n-        onClose={() => setPublicationPanelVisible(false)}\n-      />\n     </>\n   )\n }\ndiff --git a/apps/studio/components/interfaces/Database/ETL/DestinationRow.tsx b/apps/studio/components/interfaces/Database/ETL/DestinationRow.tsx\nindex 4fa6d64f7fddd..4c96439ce81eb 100644\n--- a/apps/studio/components/interfaces/Database/ETL/DestinationRow.tsx\n+++ b/apps/studio/components/interfaces/Database/ETL/DestinationRow.tsx\n@@ -88,7 +88,10 @@ export const DestinationRow = ({\n   )\n   const tableStatuses = replicationStatusData?.table_statuses ?? []\n   const errorCount = tableStatuses.filter((t) => t.state?.name === 'error').length\n-  const hasTableErrors = errorCount > 0\n+  // Only show errors when pipeline is running (not when stopped or restarting)\n+  const isPipelineStopped = statusName === PipelineStatusName.STOPPED\n+  const isRestarting = requestStatus === PipelineStatusRequestStatus.RestartRequested\n+  const hasTableErrors = errorCount > 0 && !isPipelineStopped && !isRestarting\n \n   // Check if a newer pipeline version is available (one-time check cached for session)\n   const { data: versionData } = useReplicationPipelineVersionQuery({\ndiff --git a/apps/studio/components/interfaces/Database/ETL/Destinations.tsx b/apps/studio/components/interfaces/Database/ETL/Destinations.tsx\nindex 4a392ad5326bc..9fb917d22dac8 100644\n--- a/apps/studio/components/interfaces/Database/ETL/Destinations.tsx\n+++ b/apps/studio/components/interfaces/Database/ETL/Destinations.tsx\n@@ -113,11 +113,18 @@ export const Destinations = () => {\n               />\n             </div>\n           </div>\n-          {!!sourceId && (\n-            <Button type=\"default\" icon={<Plus />} onClick={() => setShowNewDestinationPanel(true)}>\n-              Add destination\n-            </Button>\n-          )}\n+          <div className=\"flex items-center gap-x-2\">\n+            {!!sourceId && (\n+              <Button\n+                type=\"default\"\n+                icon={<Plus />}\n+                onClick={() => setShowNewDestinationPanel(true)}\n+              >\n+                Add destination\n+              </Button>\n+            )}\n+            <DocsButton href=\"https://supabase.com/docs/guides/database/replication\" />\n+          </div>\n         </div>\n       </div>\n \ndiff --git a/apps/studio/components/interfaces/Database/ETL/ErrorDetailsButton.tsx b/apps/studio/components/interfaces/Database/ETL/ErrorDetailsButton.tsx\nnew file mode 100644\nindex 0000000000000..d1213bbffd3de\n--- /dev/null\n+++ b/apps/studio/components/interfaces/Database/ETL/ErrorDetailsButton.tsx\n@@ -0,0 +1,109 @@\n+import { AlertCircle } from 'lucide-react'\n+import {\n+  Button,\n+  cn,\n+  CodeBlock,\n+  Dialog,\n+  DialogClose,\n+  DialogContent,\n+  DialogFooter,\n+  DialogHeader,\n+  DialogSection,\n+  DialogSectionSeparator,\n+  DialogTitle,\n+  DialogTrigger,\n+  Tooltip,\n+  TooltipContent,\n+  TooltipTrigger,\n+} from 'ui'\n+\n+interface ErrorDetailsButtonProps {\n+  tableName: string\n+  reason: string\n+  solution?: string\n+}\n+\n+export const ErrorDetailsButton = ({ tableName, reason, solution }: ErrorDetailsButtonProps) => {\n+  return (\n+    <Dialog>\n+      <DialogTrigger asChild>\n+        <Button size=\"tiny\" type=\"default\" className=\"w-min\" aria-label=\"Show error details\">\n+          Show error\n+        </Button>\n+      </DialogTrigger>\n+      <DialogContent size=\"xlarge\" aria-describedby={undefined}>\n+        <DialogHeader>\n+          <DialogTitle>Replication error on \"{tableName}\"</DialogTitle>\n+        </DialogHeader>\n+        <DialogSectionSeparator />\n+        <DialogSection className=\"!p-0\">\n+          <div className=\"px-4 py-3\">\n+            <p className=\"text-sm text-foreground-light\">\n+              The following error occured during replication:\n+            </p>\n+          </div>\n+          <CodeBlock\n+            hideLineNumbers\n+            wrapLines={false}\n+            wrapperClassName={cn(\n+              '[&_pre]:px-4 [&_pre]:py-3 [&>pre]:border-x-0 [&>pre]:rounded-none'\n+            )}\n+            language=\"bash\"\n+            value={reason}\n+            className=\"[&_code]:text-xs [&_code]:text-foreground [&_span]:!text-foreground\"\n+          />\n+          {/* Solution if available */}\n+          {solution && (\n+            <div className=\"px-4 py-3\">\n+              <p className=\"text-sm\">{solution}</p>\n+            </div>\n+          )}\n+        </DialogSection>\n+        <DialogFooter>\n+          <DialogClose>\n+            <Button type=\"default\">Close</Button>\n+          </DialogClose>\n+        </DialogFooter>\n+      </DialogContent>\n+    </Dialog>\n+  )\n+\n+  return (\n+    <Tooltip delayDuration={0}>\n+      <TooltipTrigger asChild>\n+        <Button\n+          size=\"tiny\"\n+          type=\"default\"\n+          className=\"w-min\"\n+          icon={<AlertCircle size={14} />}\n+          aria-label=\"Show error details\"\n+        >\n+          Show Error\n+        </Button>\n+      </TooltipTrigger>\n+      <TooltipContent\n+        side=\"bottom\"\n+        align=\"start\"\n+        className=\"w-[500px] max-w-[90vw] max-h-[400px] p-0 overflow-hidden\"\n+      >\n+        <div className=\"flex flex-col gap-y-3 p-4 max-h-[400px] overflow-y-auto\">\n+          {/* Error message */}\n+          <div>\n+            <div className=\"text-xs font-medium mb-2\">Error</div>\n+            <div className=\"bg-surface-100 rounded p-2 max-h-[250px] overflow-y-auto\">\n+              <pre className=\"text-xs font-mono whitespace-pre-wrap break-words\">{reason}</pre>\n+            </div>\n+          </div>\n+\n+          {/* Solution if available */}\n+          {solution && (\n+            <div>\n+              <div className=\"text-xs font-medium mb-2\">Solution</div>\n+              <p className=\"text-xs\">{solution}</p>\n+            </div>\n+          )}\n+        </div>\n+      </TooltipContent>\n+    </Tooltip>\n+  )\n+}\ndiff --git a/apps/studio/components/interfaces/Database/ETL/ErroredTableDetails.tsx b/apps/studio/components/interfaces/Database/ETL/ErroredTableDetails.tsx\nindex ba0bdad5e4deb..666766af7f2d8 100644\n--- a/apps/studio/components/interfaces/Database/ETL/ErroredTableDetails.tsx\n+++ b/apps/studio/components/interfaces/Database/ETL/ErroredTableDetails.tsx\n@@ -1,9 +1,10 @@\n import { useParams } from 'common'\n import { InlineLink } from 'components/ui/InlineLink'\n+import { ErrorDetailsButton } from './ErrorDetailsButton'\n import { TableState } from './ReplicationPipelineStatus/ReplicationPipelineStatus.types'\n import { isValidRetryPolicy } from './ReplicationPipelineStatus/ReplicationPipelineStatus.utils'\n+import { ResetTableButton } from './ResetTableButton'\n import { RetryCountdown } from './RetryCountdown'\n-import { RetryOptionsDropdown } from './RetryOptionsDropdown'\n \n interface ErroredTableDetailsProps {\n   state: Extract<TableState['state'], { name: 'error' }>\n@@ -31,27 +32,52 @@ export const ErroredTableDetails = ({ state, tableName, tableId }: ErroredTableD\n   return (\n     <div role=\"region\" aria-label={`Error details for table ${tableName}`}>\n       {retryPolicy === 'no_retry' ? (\n-        <p className=\"text-xs text-foreground-lighter\">\n-          This error requires manual intervention from our{' '}\n-          <InlineLink\n-            className=\"text-foreground-lighter hover:text-foreground\"\n-            href={`/support?projectRef=${projectRef}&category=dashboard_bug&subject=Database%20replication%20error&error=${state.reason}`}\n-          >\n-            support\n-          </InlineLink>\n-          . Alternatively, you may also recreate the pipeline.\n-        </p>\n+        <div className=\"flex flex-col gap-y-3\">\n+          <p className=\"text-xs text-foreground-lighter\">\n+            This error requires manual intervention from our{' '}\n+            <InlineLink\n+              className=\"text-foreground-lighter hover:text-foreground\"\n+              href={`/support?projectRef=${projectRef}&category=dashboard_bug&subject=Database%20replication%20error&error=${state.reason}`}\n+            >\n+              support\n+            </InlineLink>\n+            . Alternatively, you may also recreate the pipeline.\n+          </p>\n+          <ErrorDetailsButton\n+            tableName={tableName}\n+            reason={state.reason}\n+            solution={state.solution}\n+          />\n+        </div>\n       ) : retryPolicy === 'manual_retry' ? (\n-        <div className=\"flex flex-col gap-y-2 text-foreground-lighter\">\n-          <p className=\"text-xs\">{state.solution}. You may thereafter rollback the pipeline.</p>\n-          <RetryOptionsDropdown tableId={tableId} tableName={tableName} />\n+        <div className=\"flex flex-col gap-y-3 text-foreground-lighter\">\n+          <div>\n+            <p className=\"text-xs\">\n+              {state.solution}\n+              {state.solution && !/[.!?]$/.test(state.solution.trim()) && '.'}\n+            </p>\n+            <p className=\"text-xs\">You can reset the table to start replication from scratch.</p>\n+          </div>\n+          <div className=\"flex items-center gap-x-2\">\n+            <ResetTableButton tableId={tableId} tableName={tableName} />\n+            <ErrorDetailsButton\n+              tableName={tableName}\n+              reason={state.reason}\n+              solution={state.solution}\n+            />\n+          </div>\n         </div>\n       ) : retryPolicy === 'timed_retry' ? (\n-        <div className=\"flex flex-col text-foreground-lighter\">\n+        <div className=\"flex flex-col text-foreground-lighter gap-y-3\">\n           <p className=\"text-xs\">\n             A retry will be triggered automatically by restarting the pipeline on this table.\n           </p>\n           <RetryCountdown nextRetryTime={state.retry_policy.next_retry} />\n+          <ErrorDetailsButton\n+            tableName={tableName}\n+            reason={state.reason}\n+            solution={state.solution}\n+          />\n         </div>\n       ) : null}\n     </div>\ndiff --git a/apps/studio/components/interfaces/Database/ETL/ReplicationPipelineStatus/ReplicationPipelineStatus.tsx b/apps/studio/components/interfaces/Database/ETL/ReplicationPipelineStatus/ReplicationPipelineStatus.tsx\nindex 51e34cc0e707d..f05aece3ceab3 100644\n--- a/apps/studio/components/interfaces/Database/ETL/ReplicationPipelineStatus/ReplicationPipelineStatus.tsx\n+++ b/apps/studio/components/interfaces/Database/ETL/ReplicationPipelineStatus/ReplicationPipelineStatus.tsx\n@@ -25,6 +25,7 @@ import { useReplicationPipelineByIdQuery } from 'data/etl/pipeline-by-id-query'\n import { useReplicationPipelineReplicationStatusQuery } from 'data/etl/pipeline-replication-status-query'\n import { useReplicationPipelineStatusQuery } from 'data/etl/pipeline-status-query'\n import { useReplicationPipelineVersionQuery } from 'data/etl/pipeline-version-query'\n+import { useRestartPipelineHelper } from 'data/etl/restart-pipeline-helper'\n import { useStartPipelineMutation } from 'data/etl/start-pipeline-mutation'\n import { useStopPipelineMutation } from 'data/etl/stop-pipeline-mutation'\n import {\n@@ -105,6 +106,7 @@ export const ReplicationPipelineStatus = () => {\n \n   const { mutateAsync: startPipeline, isPending: isStartingPipeline } = useStartPipelineMutation()\n   const { mutateAsync: stopPipeline, isPending: isStoppingPipeline } = useStopPipelineMutation()\n+  const { restartPipeline } = useRestartPipelineHelper()\n \n   const destinationName = pipeline?.destination_name\n   const statusName = getStatusName(pipelineStatusData?.status)\n@@ -169,7 +171,7 @@ export const ReplicationPipelineStatus = () => {\n         await stopPipeline({ projectRef, pipelineId: pipeline.id })\n       } else if (statusName === 'failed') {\n         setRequestStatus(pipeline.id, PipelineStatusRequestStatus.RestartRequested, statusName)\n-        await startPipeline({ projectRef, pipelineId: pipeline.id })\n+        await restartPipeline({ projectRef, pipelineId: pipeline.id })\n       }\n     } catch (error) {\n       toast.error(PIPELINE_ERROR_MESSAGES.ENABLE_DESTINATION)\n@@ -411,7 +413,7 @@ export const ReplicationPipelineStatus = () => {\n                                 Status unavailable while pipeline is {config.badge.toLowerCase()}\n                               </p>\n                             ) : (\n-                              <div className=\"space-y-3\">\n+                              <div className=\"flex flex-col gap-y-2\">\n                                 <div className=\"text-sm text-foreground\">\n                                   {statusConfig.description}\n                                 </div>\n@@ -459,6 +461,7 @@ export const ReplicationPipelineStatus = () => {\n           </div>\n         )}\n       </div>\n+\n       <UpdateVersionModal\n         visible={showUpdateVersionModal}\n         pipeline={pipeline}\ndiff --git a/apps/studio/components/interfaces/Database/ETL/ResetTableButton.tsx b/apps/studio/components/interfaces/Database/ETL/ResetTableButton.tsx\nnew file mode 100644\nindex 0000000000000..7b5491651d0ad\n--- /dev/null\n+++ b/apps/studio/components/interfaces/Database/ETL/ResetTableButton.tsx\n@@ -0,0 +1,97 @@\n+import { RotateCcw } from 'lucide-react'\n+import { useState } from 'react'\n+import { toast } from 'sonner'\n+\n+import { useParams } from 'common'\n+import { useTableReset } from 'data/etl/use-table-reset'\n+import {\n+  AlertDialog,\n+  AlertDialogAction,\n+  AlertDialogCancel,\n+  AlertDialogContent,\n+  AlertDialogDescription,\n+  AlertDialogFooter,\n+  AlertDialogHeader,\n+  AlertDialogTitle,\n+  Button,\n+} from 'ui'\n+\n+interface ResetTableButtonProps {\n+  tableId: number\n+  tableName: string\n+}\n+\n+export const ResetTableButton = ({ tableId, tableName }: ResetTableButtonProps) => {\n+  const { ref: projectRef, pipelineId: _pipelineId } = useParams()\n+  const [isOpen, setIsOpen] = useState(false)\n+\n+  const { resetTable, isRollingBack, isRestartingPipeline, isResetting } = useTableReset({\n+    tableName,\n+    onSuccess: () => setIsOpen(false),\n+    onError: () => setIsOpen(false),\n+  })\n+\n+  const handleReset = () => {\n+    if (!projectRef) return toast.error('Project ref is required')\n+    if (!_pipelineId) return toast.error('Pipeline ID is required')\n+\n+    const pipelineId = Number(_pipelineId)\n+\n+    resetTable({\n+      projectRef,\n+      pipelineId,\n+      tableId,\n+      rollbackType: 'full',\n+    })\n+  }\n+\n+  return (\n+    <AlertDialog open={isOpen} onOpenChange={setIsOpen}>\n+      <Button\n+        size=\"tiny\"\n+        type=\"default\"\n+        loading={isResetting}\n+        disabled={isResetting}\n+        className=\"w-min\"\n+        icon={<RotateCcw />}\n+        aria-label={`Reset and restart table ${tableName}`}\n+        onClick={() => setIsOpen(true)}\n+      >\n+        Reset table and restart\n+      </Button>\n+      <AlertDialogContent>\n+        <AlertDialogHeader>\n+          <AlertDialogTitle>Reset and restart table \"{tableName}\"?</AlertDialogTitle>\n+          <AlertDialogDescription className=\"flex flex-col gap-y-3 py-4 !mt-0\">\n+            <p>\n+              This will reset and restart replication for this table only. The table will start\n+              copying from scratch, and any existing data for this table downstream will be deleted.\n+            </p>\n+            <p className=\"text-foreground-light\">\n+              Other tables in the pipeline will not be affected. Only this table will be restarted\n+              and go through the full replication process again, starting with the initial copy\n+              phase.\n+            </p>\n+            <p className=\"text-foreground-light\">\n+              The pipeline will be restarted to apply the table reset.\n+            </p>\n+          </AlertDialogDescription>\n+        </AlertDialogHeader>\n+        <AlertDialogFooter>\n+          <AlertDialogCancel disabled={isResetting}>Cancel</AlertDialogCancel>\n+          <AlertDialogAction\n+            disabled={isResetting}\n+            onClick={handleReset}\n+            className=\"bg-destructive hover:bg-destructive/90\"\n+          >\n+            {isRollingBack\n+              ? 'Resetting table...'\n+              : isRestartingPipeline\n+                ? 'Restarting pipeline...'\n+                : 'Confirm reset and restart'}\n+          </AlertDialogAction>\n+        </AlertDialogFooter>\n+      </AlertDialogContent>\n+    </AlertDialog>\n+  )\n+}\ndiff --git a/apps/studio/components/interfaces/Database/ETL/RetryOptionsDropdown.tsx b/apps/studio/components/interfaces/Database/ETL/RetryOptionsDropdown.tsx\nindex 862511fdfa679..90fb4cadf5e86 100644\n--- a/apps/studio/components/interfaces/Database/ETL/RetryOptionsDropdown.tsx\n+++ b/apps/studio/components/interfaces/Database/ETL/RetryOptionsDropdown.tsx\n@@ -3,8 +3,8 @@ import { useState } from 'react'\n import { toast } from 'sonner'\n \n import { useParams } from 'common'\n+import { useRestartPipelineHelper } from 'data/etl/restart-pipeline-helper'\n import { RollbackType, useRollbackTableMutation } from 'data/etl/rollback-table-mutation'\n-import { useStartPipelineMutation } from 'data/etl/start-pipeline-mutation'\n import {\n   Button,\n   DropdownMenu,\n@@ -36,12 +36,27 @@ interface RetryOptionsDropdownProps {\n export const RetryOptionsDropdown = ({ tableId, tableName }: RetryOptionsDropdownProps) => {\n   const { ref: projectRef, pipelineId: _pipelineId } = useParams()\n   const [isOpen, setIsOpen] = useState(false)\n+  const [isRestartingPipeline, setIsRestartingPipeline] = useState(false)\n+\n+  const { restartPipeline } = useRestartPipelineHelper()\n \n   const { mutate: rollbackTable, isPending: isRollingBack } = useRollbackTableMutation({\n-    onSuccess: (_, vars) => {\n-      const { projectRef, pipelineId } = vars\n-      toast.success(`Table \"${tableName}\" rolled back successfully and pipeline is being restarted`)\n-      startPipeline({ projectRef, pipelineId })\n+    onSuccess: async (_, vars) => {\n+      const { projectRef, pipelineId, rollbackType } = vars\n+      toast.success(\n+        `Table \"${tableName}\" ${rollbackType === 'full' ? 'reset' : 'rolled back'} successfully and pipeline is being restarted`\n+      )\n+\n+      setIsRestartingPipeline(true)\n+      try {\n+        await restartPipeline({ projectRef, pipelineId })\n+        toast.success('Pipeline restarted successfully')\n+      } catch (error: any) {\n+        toast.error(`Failed to restart pipeline: ${error.message}`)\n+      } finally {\n+        setIsRestartingPipeline(false)\n+        setIsOpen(false)\n+      }\n     },\n     onError: (error, vars) => {\n       const { rollbackType } = vars\n@@ -50,16 +65,6 @@ export const RetryOptionsDropdown = ({ tableId, tableName }: RetryOptionsDropdow\n       )\n     },\n   })\n-  const { mutate: startPipeline, isPending: isRestartingPipeline } = useStartPipelineMutation({\n-    onSuccess: () => {\n-      toast.success('Pipeline restarted successfully')\n-      setIsOpen(false)\n-    },\n-    onError: (error) => {\n-      toast.error(`Failed to restart pipeline: ${error.message}`)\n-      setIsOpen(false)\n-    },\n-  })\n \n   const isLoading = isRollingBack || isRestartingPipeline\n \ndiff --git a/apps/studio/components/interfaces/Database/ETL/RowMenu.tsx b/apps/studio/components/interfaces/Database/ETL/RowMenu.tsx\nindex 9a02bb49c425d..8456c1dcaf4f8 100644\n--- a/apps/studio/components/interfaces/Database/ETL/RowMenu.tsx\n+++ b/apps/studio/components/interfaces/Database/ETL/RowMenu.tsx\n@@ -5,6 +5,7 @@ import { useParams } from 'common'\n import AlertError from 'components/ui/AlertError'\n import { ReplicationPipelineStatusData } from 'data/etl/pipeline-status-query'\n import { Pipeline } from 'data/etl/pipelines-query'\n+import { useRestartPipelineHelper } from 'data/etl/restart-pipeline-helper'\n import { useStartPipelineMutation } from 'data/etl/start-pipeline-mutation'\n import { useStopPipelineMutation } from 'data/etl/stop-pipeline-mutation'\n import {\n@@ -58,6 +59,7 @@ export const RowMenu = ({\n \n   const { mutateAsync: startPipeline } = useStartPipelineMutation()\n   const { mutateAsync: stopPipeline } = useStopPipelineMutation()\n+  const { restartPipeline } = useRestartPipelineHelper()\n   const { getRequestStatus, setRequestStatus: setGlobalRequestStatus } = usePipelineRequestStatus()\n   const requestStatus = pipeline?.id\n     ? getRequestStatus(pipeline.id)\n@@ -117,7 +119,7 @@ export const RowMenu = ({\n \n     try {\n       setGlobalRequestStatus(pipeline.id, PipelineStatusRequestStatus.RestartRequested, statusName)\n-      await startPipeline({ projectRef, pipelineId: pipeline.id })\n+      await restartPipeline({ projectRef, pipelineId: pipeline.id })\n     } catch (error) {\n       setGlobalRequestStatus(pipeline.id, PipelineStatusRequestStatus.None)\n       toast.error(PIPELINE_ERROR_MESSAGES.ENABLE_DESTINATION)\ndiff --git a/apps/studio/components/interfaces/Database/ETL/UpdateVersionModal.tsx b/apps/studio/components/interfaces/Database/ETL/UpdateVersionModal.tsx\nindex 585241a7adbf7..78439c97b4b51 100644\n--- a/apps/studio/components/interfaces/Database/ETL/UpdateVersionModal.tsx\n+++ b/apps/studio/components/interfaces/Database/ETL/UpdateVersionModal.tsx\n@@ -4,12 +4,19 @@ import { useParams } from 'common'\n import { useReplicationPipelineStatusQuery } from 'data/etl/pipeline-status-query'\n import { useReplicationPipelineVersionQuery } from 'data/etl/pipeline-version-query'\n import { Pipeline } from 'data/etl/pipelines-query'\n-import { useStartPipelineMutation } from 'data/etl/start-pipeline-mutation'\n+import { useRestartPipelineHelper } from 'data/etl/restart-pipeline-helper'\n import { useUpdatePipelineVersionMutation } from 'data/etl/update-pipeline-version-mutation'\n+import { ChevronDown } from 'lucide-react'\n import {\n   PipelineStatusRequestStatus,\n   usePipelineRequestStatus,\n } from 'state/replication-pipeline-request-status'\n+import {\n+  Collapsible_Shadcn_,\n+  CollapsibleContent_Shadcn_,\n+  CollapsibleTrigger_Shadcn_,\n+  DialogSectionSeparator,\n+} from 'ui'\n import ConfirmationModal from 'ui-patterns/Dialogs/ConfirmationModal'\n import { getStatusName } from './Pipeline.utils'\n import { PipelineStatusName, STATUS_REFRESH_FREQUENCY_MS } from './Replication.constants'\n@@ -25,7 +32,7 @@ interface UpdateVersionModalProps {\n export const UpdateVersionModal = ({\n   visible,\n   pipeline,\n-  confirmLabel = 'Update and restart',\n+  confirmLabel,\n   confirmLabelLoading = 'Updating',\n   onClose,\n }: UpdateVersionModalProps) => {\n@@ -38,6 +45,7 @@ export const UpdateVersionModal = ({\n   )\n   const pipelineStatus = pipelineStatusData?.status\n   const statusName = getStatusName(pipelineStatus)\n+  const isStopped = statusName === PipelineStatusName.STOPPED\n \n   const { data: versionData } = useReplicationPipelineVersionQuery({\n     projectRef,\n@@ -47,7 +55,7 @@ export const UpdateVersionModal = ({\n   const newVersionName = versionData?.new_version?.name\n \n   const { mutateAsync: updatePipelineVersion } = useUpdatePipelineVersionMutation()\n-  const { mutateAsync: startPipeline } = useStartPipelineMutation()\n+  const { restartPipeline } = useRestartPipelineHelper()\n \n   const onConfirmUpdate = async () => {\n     if (!projectRef || !pipeline?.id) return\n@@ -64,16 +72,13 @@ export const UpdateVersionModal = ({\n       return\n     }\n \n-    // Step 2: Reflect optimistic restart (only if currently active) and close any panels\n-    const isActive =\n-      statusName === PipelineStatusName.STARTED || statusName === PipelineStatusName.FAILED\n-\n-    if (isActive) {\n+    // Step 2: Reflect optimistic restart (only if not stopped) and close any panels\n+    if (!isStopped) {\n       setRequestStatus(pipeline.id, PipelineStatusRequestStatus.RestartRequested, statusName)\n \n-      // Step 3: Restart the pipeline\n+      // Step 3: Restart the pipeline (stop + start)\n       try {\n-        await startPipeline({ projectRef, pipelineId: pipeline.id })\n+        await restartPipeline({ projectRef, pipelineId: pipeline.id })\n         toast.success('Pipeline successfully updated and is currently restarting')\n       } catch (e: any) {\n         // Clear optimistic state and surface a single concise error\n@@ -89,34 +94,46 @@ export const UpdateVersionModal = ({\n \n   return (\n     <ConfirmationModal\n-      size=\"medium\"\n+      size=\"small\"\n       visible={visible}\n-      title=\"Update pipeline version\"\n-      confirmLabel={confirmLabel}\n+      title=\"Update pipeline image\"\n+      className=\"!p-0\"\n+      confirmLabel={confirmLabel ?? (isStopped ? 'Update image' : 'Update and restart')}\n       confirmLabelLoading={confirmLabelLoading}\n       onCancel={onClose}\n       onConfirm={onConfirmUpdate}\n-      alert={{\n-        base: { variant: 'warning' },\n-        title: 'Pipeline will be restarted briefly to complete the change',\n-        description: (\n-          <div className=\"flex flex-col gap-y-1\">\n-            <p className=\"!leading-normal\">\n-              During the update process, the replication pauses and resumes.\n-            </p>\n-            <p className=\"!leading-normal\">\n-              If a long‑running transaction is in progress, some records may be reprocessed due to\n-              PostgreSQL logical replication limitations.\n-            </p>\n-          </div>\n-        ),\n-      }}\n     >\n-      <p className=\"text-sm text-foreground prose max-w-full mb-1\">\n-        Pipeline will be updated from <code>{currentVersionName ?? 'Current version'}</code> to{' '}\n-        <code>{newVersionName ?? 'New version'}</code>.\n-      </p>\n-      <p className=\"text-sm\">Confirm to update pipeline? This action cannot be undone.</p>\n+      <div className=\"flex flex-col gap-y-3 py-4 px-5\">\n+        <p className=\"text-sm text-foreground\">\n+          A new pipeline image is available with improvements and bug fixes. Proceed to update?\n+        </p>\n+        {!isStopped && (\n+          <p className=\"text-sm text-foreground-light\">\n+            The pipeline will automatically restart when updating. Replication will continue from\n+            where it left off.\n+          </p>\n+        )}\n+      </div>\n+      <DialogSectionSeparator />\n+\n+      <Collapsible_Shadcn_ className=\"px-5 py-3 group\">\n+        <CollapsibleTrigger_Shadcn_ className=\"w-full flex items-center justify-between text-sm text-foreground-light\">\n+          <p>View version update details</p>\n+          <ChevronDown size={14} className=\"group-data-[state=open]:-rotate-180 transition\" />\n+        </CollapsibleTrigger_Shadcn_>\n+        <CollapsibleContent_Shadcn_>\n+          <div className=\"flex flex-col gap-y-2 mt-2 pb-2\">\n+            <div className=\"text-sm text-foreground prose max-w-full\">\n+              <p className=\"text-foreground-light mb-1\">Current version:</p>{' '}\n+              <code className=\"text-xs\">{currentVersionName ?? 'Unknown'}</code>\n+            </div>\n+            <div className=\"text-sm text-foreground prose max-w-full\">\n+              <p className=\"text-foreground-light mb-1\">New version:</p>{' '}\n+              <code className=\"text-xs\">{newVersionName ?? 'Unknown'}</code>\n+            </div>\n+          </div>\n+        </CollapsibleContent_Shadcn_>\n+      </Collapsible_Shadcn_>\n     </ConfirmationModal>\n   )\n }\ndiff --git a/apps/studio/components/interfaces/Sidebar.tsx b/apps/studio/components/interfaces/Sidebar.tsx\nindex 31ce6352910f0..757995ea24379 100644\n--- a/apps/studio/components/interfaces/Sidebar.tsx\n+++ b/apps/studio/components/interfaces/Sidebar.tsx\n@@ -430,6 +430,8 @@ const OrganizationLinks = () => {\n     },\n   ]\n \n+  if (!organizationSlug) return null\n+\n   return (\n     <SidebarMenu className=\"flex flex-col gap-1 items-start\">\n       <SidebarGroup className=\"gap-0.5\">\ndiff --git a/apps/studio/data/etl/restart-pipeline-helper.ts b/apps/studio/data/etl/restart-pipeline-helper.ts\nnew file mode 100644\nindex 0000000000000..75c5b022f293d\n--- /dev/null\n+++ b/apps/studio/data/etl/restart-pipeline-helper.ts\n@@ -0,0 +1,40 @@\n+import { useStopPipelineMutation } from './stop-pipeline-mutation'\n+import { useStartPipelineMutation } from './start-pipeline-mutation'\n+\n+export interface RestartPipelineParams {\n+  projectRef: string\n+  pipelineId: number\n+}\n+\n+/**\n+ * Helper hook that provides a restart function which properly stops and then starts a pipeline.\n+ *\n+ * ## Why Stop + Start?\n+ *\n+ * This explicit two-step restart process is necessary to work around edge cases where Kubernetes\n+ * doesn't properly recreate pods when using the start endpoint alone on a running pipeline. This happens\n+ * because crash looping pods are not restarted if the resource is patched. We will try to find a better\n+ * solution for this in the future.\n+ */\n+export const useRestartPipelineHelper = () => {\n+  const { mutateAsync: stopPipeline } = useStopPipelineMutation()\n+  const { mutateAsync: startPipeline } = useStartPipelineMutation()\n+\n+  const restartPipeline = async ({ projectRef, pipelineId }: RestartPipelineParams) => {\n+    // Step 1: Stop the pipeline to ensure pods are fully terminated\n+    try {\n+      await stopPipeline({ projectRef, pipelineId })\n+    } catch (error: any) {\n+      throw new Error(`Failed to stop pipeline: ${error.message}`)\n+    }\n+\n+    // Step 2: Start the pipeline to create fresh pods with clean state\n+    try {\n+      await startPipeline({ projectRef, pipelineId })\n+    } catch (error: any) {\n+      throw new Error(`Failed to start pipeline: ${error.message}`)\n+    }\n+  }\n+\n+  return { restartPipeline }\n+}\ndiff --git a/apps/studio/data/etl/use-table-reset.ts b/apps/studio/data/etl/use-table-reset.ts\nnew file mode 100644\nindex 0000000000000..86136afdfdad3\n--- /dev/null\n+++ b/apps/studio/data/etl/use-table-reset.ts\n@@ -0,0 +1,70 @@\n+import { useState } from 'react'\n+import { toast } from 'sonner'\n+import { RollbackType, useRollbackTableMutation } from './rollback-table-mutation'\n+import { useRestartPipelineHelper } from './restart-pipeline-helper'\n+\n+interface UseTableResetParams {\n+  tableName: string\n+  onSuccess?: () => void\n+  onError?: (error: Error) => void\n+}\n+\n+/**\n+ * Custom hook that encapsulates the logic for resetting a table and restarting the pipeline.\n+ * Provides unified error handling and loading states for table reset operations.\n+ */\n+export const useTableReset = ({ tableName, onSuccess, onError }: UseTableResetParams) => {\n+  const [isRestartingPipeline, setIsRestartingPipeline] = useState(false)\n+  const { restartPipeline } = useRestartPipelineHelper()\n+\n+  const { mutate: rollbackTable, isLoading: isRollingBack } = useRollbackTableMutation({\n+    onSuccess: async (_, vars) => {\n+      const { projectRef, pipelineId } = vars\n+      toast.success(`Table \"${tableName}\" reset successfully and pipeline is being restarted`)\n+\n+      setIsRestartingPipeline(true)\n+      try {\n+        await restartPipeline({ projectRef, pipelineId })\n+        toast.success('Pipeline restarted successfully')\n+        onSuccess?.()\n+      } catch (error: any) {\n+        const errorMessage = `Failed to restart pipeline: ${error.message}`\n+        toast.error(errorMessage)\n+        onError?.(new Error(errorMessage))\n+      } finally {\n+        setIsRestartingPipeline(false)\n+      }\n+    },\n+    onError: (error) => {\n+      const errorMessage = `Failed to reset table: ${error.message}`\n+      toast.error(errorMessage)\n+      onError?.(new Error(errorMessage))\n+    },\n+  })\n+\n+  const resetTable = ({\n+    projectRef,\n+    pipelineId,\n+    tableId,\n+    rollbackType = 'full' as RollbackType,\n+  }: {\n+    projectRef: string\n+    pipelineId: number\n+    tableId: number\n+    rollbackType?: RollbackType\n+  }) => {\n+    rollbackTable({\n+      projectRef,\n+      pipelineId,\n+      tableId,\n+      rollbackType,\n+    })\n+  }\n+\n+  return {\n+    resetTable,\n+    isRollingBack,\n+    isRestartingPipeline,\n+    isResetting: isRollingBack || isRestartingPipeline,\n+  }\n+}\ndiff --git a/packages/ui-patterns/src/Dialogs/ConfirmationModal.tsx b/packages/ui-patterns/src/Dialogs/ConfirmationModal.tsx\nindex 7db9f803e4fd7..bea5d1633a593 100644\n--- a/packages/ui-patterns/src/Dialogs/ConfirmationModal.tsx\n+++ b/packages/ui-patterns/src/Dialogs/ConfirmationModal.tsx\n@@ -32,6 +32,7 @@ export interface ConfirmationModalProps {\n     title?: string\n     description?: string | React.ReactNode\n   }\n+  className?: string\n }\n \n export const ConfirmationModal = forwardRef<\n@@ -54,6 +55,7 @@ export const ConfirmationModal = forwardRef<\n       children,\n       variant = 'default',\n       disabled,\n+      className,\n       ...props\n     },\n     ref\n@@ -105,7 +107,9 @@ export const ConfirmationModal = forwardRef<\n           )}\n           {children && (\n             <>\n-              <DialogSection padding={'small'}>{children}</DialogSection>\n+              <DialogSection padding=\"small\" className={className}>\n+                {children}\n+              </DialogSection>\n               <DialogSectionSeparator />\n             </>\n           )}\n",
			"diffSize": 39892,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "169e3d9c9045789a3bfa698d86e70851e183aa84",
			"message": "docs(replication): Add docs for ETL (#35649)",
			"user": "charislam",
			"timestamp": "2025-11-21T08:52:32Z",
			"author": {
				"name": "Charis",
				"email": "26616127+charislam@users.noreply.github.com",
				"username": "charislam"
			},
			"files": {
				"added": [
					"apps/docs/content/guides/database/replication/etl-bigquery.mdx",
					"apps/docs/content/guides/database/replication/etl-destinations.mdx",
					"apps/docs/content/guides/database/replication/etl-iceberg.mdx",
					"apps/docs/content/guides/database/replication/etl-replication-faq.mdx",
					"apps/docs/content/guides/database/replication/etl-replication-monitoring.mdx",
					"apps/docs/content/guides/database/replication/etl-replication-setup.mdx",
					"apps/docs/public/img/database/replication/etl-add-destination.png",
					"apps/docs/public/img/database/replication/etl-bigquery-details.png",
					"apps/docs/public/img/database/replication/etl-destinations-list.png",
					"apps/docs/public/img/database/replication/etl-enable-replication.png",
					"apps/docs/public/img/database/replication/etl-iceberg-bucket-details.png",
					"apps/docs/public/img/database/replication/etl-iceberg-details.png",
					"apps/docs/public/img/database/replication/etl-iceberg-new-bucket.png",
					"apps/docs/public/img/database/replication/etl-pipeline-actions.png",
					"apps/docs/public/img/database/replication/etl-pipeline-error.png",
					"apps/docs/public/img/database/replication/etl-pipeline-table-error.png",
					"apps/docs/public/img/database/replication/etl-replication-logs.png",
					"apps/docs/public/img/database/replication/etl-view-status.png"
				],
				"modified": [
					"apps/docs/components/Navigation/NavigationMenu/NavigationMenu.constants.ts",
					"apps/docs/content/guides/database/replication.mdx",
					"apps/docs/content/guides/getting-started/features.mdx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/docs/components/Navigation/NavigationMenu/NavigationMenu.constants.ts b/apps/docs/components/Navigation/NavigationMenu/NavigationMenu.constants.ts\nindex b1a43aa1cbd2c..5c358d9fd3270 100644\n--- a/apps/docs/components/Navigation/NavigationMenu/NavigationMenu.constants.ts\n+++ b/apps/docs/components/Navigation/NavigationMenu/NavigationMenu.constants.ts\n@@ -1147,14 +1147,39 @@ export const database: NavMenuConstant = {\n       items: [\n         { name: 'Overview', url: '/guides/database/replication' },\n         {\n-          name: 'Setting up replication',\n-          url: '/guides/database/replication/setting-up-replication' as `/${string}`,\n+          name: 'ETL Replication',\n+          url: '/guides/database/replication/etl-replication-setup' as `/${string}`,\n+          items: [\n+            {\n+              name: 'Setting up',\n+              url: '/guides/database/replication/etl-replication-setup' as `/${string}`,\n+            },\n+            {\n+              name: 'Destinations',\n+              url: '/guides/database/replication/etl-destinations' as `/${string}`,\n+            },\n+            {\n+              name: 'Monitoring',\n+              url: '/guides/database/replication/etl-replication-monitoring' as `/${string}`,\n+            },\n+            { name: 'FAQ', url: '/guides/database/replication/etl-replication-faq' },\n+          ],\n         },\n         {\n-          name: 'Monitoring replication',\n-          url: '/guides/database/replication/monitoring-replication' as `/${string}`,\n+          name: 'Manual Replication',\n+          url: '/guides/database/replication/manual-replication-setup' as `/${string}`,\n+          items: [\n+            {\n+              name: 'Setting up',\n+              url: '/guides/database/replication/manual-replication-setup' as `/${string}`,\n+            },\n+            {\n+              name: 'Monitoring',\n+              url: '/guides/database/replication/manual-replication-monitoring' as `/${string}`,\n+            },\n+            { name: 'FAQ', url: '/guides/database/replication/manual-replication-faq' },\n+          ],\n         },\n-        { name: 'FAQ', url: '/guides/database/replication/faq' },\n       ],\n     },\n     {\ndiff --git a/apps/docs/content/guides/database/replication.mdx b/apps/docs/content/guides/database/replication.mdx\nindex 10793ab2abb02..d2375d88e731c 100644\n--- a/apps/docs/content/guides/database/replication.mdx\n+++ b/apps/docs/content/guides/database/replication.mdx\n@@ -1,39 +1,55 @@\n ---\n-title: 'Replication and change data capture'\n-description: 'An introduction to logical replication and change data capture'\n+id: 'replication'\n+title: 'Database Replication'\n+description: 'Replicate your database to external destinations using ETL or manual replication.'\n+subtitle: 'An introduction to database replication and change data capture.'\n+sidebar_label: 'Overview'\n ---\n \n Replication is the process of copying changes from your database to another location. It's also referred to as change data capture (CDC): capturing all the changes that occur to your data.\n \n ## Use cases\n \n-You might use replication for:\n+You might use database replication for:\n \n - **Analytics and Data Warehousing**: Replicate your operational database to analytics platforms for complex analysis without impacting your application's performance.\n - **Data Integration**: Keep your data synchronized across different systems and services in your tech stack.\n - **Backup and Disaster Recovery**: Maintain up-to-date copies of your data in different locations.\n-- **Read Scaling**: Distribute read operations across multiple database instances to improve performance.\n \n-## Replication in Postgres\n+## Replication methods\n \n-Postgres comes with built-in support for replication via publications and replication slots. Refer to the [Concepts and terms](#concepts-and-terms) section to learn how replication works.\n+Supabase supports two methods for replicating your database to external destinations:\n \n-## Setting up and monitoring replication in Supabase\n+### ETL replication\n \n-- [Setting up replication](/docs/guides/database/replication/setting-up-replication)\n-- [Monitoring replication](/docs/guides/database/replication/monitoring-replication)\n+<Admonition type=\"caution\" label=\"Private Alpha\">\n \n-<Admonition type=\"tip\">\n-\n-If you want to set up a read replica, see [Read Replicas](/docs/guides/platform/read-replicas) instead. If you want to sync your data in real time to a client such as a browser or mobile app, see [Realtime](/docs/guides/realtime) instead. For configuring replication to an ETL destination, use the [Dashboard](/dashboard/project/_/database/replication).\n+ETL Replication is currently in private alpha. Access is limited and features may change.\n \n </Admonition>\n \n+Use Supabase ETL to automatically replicate data to supported systems.\n+\n+- [Set up ETL Replication](/docs/guides/database/replication/etl-replication-setup)\n+\n+### Manual replication\n+\n+Configure your own replication using external tools and Postgres's native logical replication. This gives you full control over the replication process and allows you to use any tool that supports Postgres logical replication.\n+\n+- [Set up Manual Replication](/docs/guides/database/replication/manual-replication-setup)\n+\n+## Related features\n+\n+Choose the data syncing method based on your use case:\n+\n+- For realtime features and syncing data to clients (browsers, mobile apps), see [Realtime](/docs/guides/realtime)\n+- For deploying read-only databases across multiple regions, see [Read Replicas](/docs/guides/platform/read-replicas)\n+\n ## Concepts and terms\n \n ### Write-Ahead Log (WAL)\n \n-Postgres uses a system called the Write-Ahead Log (WAL) to manage changes to the database. As you make changes, they are appended to the WAL (which is a series of files (also called \"segments\"), where the file size can be specified). Once one segment is full, Postgres will start appending to a new segment. After a period of time, a checkpoint occurs and Postgres synchronizes the WAL with your database. Once the checkpoint is complete, then the WAL files can be removed from disk and free up space.\n+Postgres uses a system called the Write-Ahead Log (WAL) to manage changes to the database. As you make changes, they are appended to the WAL, which is a series of files (also called \"segments\") where the file size can be specified. Once one segment is full, Postgres will start appending to a new segment. After a period of time, a checkpoint occurs and Postgres synchronizes the WAL with your database. Once the checkpoint is complete, then the WAL files can be removed from disk and free up space.\n \n ### Logical replication and WAL\n \ndiff --git a/apps/docs/content/guides/database/replication/etl-bigquery.mdx b/apps/docs/content/guides/database/replication/etl-bigquery.mdx\nnew file mode 100644\nindex 0000000000000..1547272f1e9e5\n--- /dev/null\n+++ b/apps/docs/content/guides/database/replication/etl-bigquery.mdx\n@@ -0,0 +1,126 @@\n+---\n+id: 'etl-bigquery'\n+title: 'ETL to BigQuery'\n+description: 'Replicate your Supabase database to Google BigQuery using ETL Replication.'\n+subtitle: 'Stream data changes to BigQuery in real-time.'\n+sidebar_label: 'BigQuery'\n+---\n+\n+<Admonition type=\"caution\" label=\"Private Alpha\">\n+\n+ETL Replication is currently in private alpha. Access is limited and features may change.\n+\n+</Admonition>\n+\n+BigQuery is Google's fully managed data warehouse. ETL Replication allows you to automatically sync your Supabase database tables to BigQuery for analytics and reporting.\n+\n+<Admonition type=\"tip\">\n+\n+This page covers BigQuery-specific configuration. For complete setup instructions including publications, general settings, and pipeline management, see the [ETL Replication Setup guide](/docs/guides/database/replication/etl-replication-setup).\n+\n+</Admonition>\n+\n+### Setup\n+\n+Setting up BigQuery replication requires preparing your GCP resources, then configuring BigQuery as an ETL destination.\n+\n+#### Step 1: Prepare GCP resources\n+\n+Before configuring BigQuery as a destination, set up the following in Google Cloud Platform:\n+\n+1. **Google Cloud Platform (GCP) account**: [Sign up for GCP](https://cloud.google.com/gcp) if you don't have one\n+2. **BigQuery dataset**: Create a [BigQuery dataset](https://cloud.google.com/bigquery/docs/datasets-intro) in your GCP project\n+3. **GCP service account key**: Create a [service account](https://cloud.google.com/iam/docs/keys-create-delete) with the **BigQuery Data Editor** role and download the JSON key file\n+\n+#### Step 2: Add BigQuery as an ETL destination\n+\n+After preparing your GCP resources, configure BigQuery as an ETL destination:\n+\n+1. Navigate to [Database](/dashboard/project/_/database/etl) → **ETL Replication** in your Supabase Dashboard\n+2. Click **Add destination**\n+3. Configure the destination:\n+\n+   <Image\n+     alt=\"BigQuery Configuration Settings\"\n+     src=\"/docs/img/database/replication/etl-bigquery-details.png\"\n+     zoomable\n+   />\n+\n+   - **Destination type**: Select **BigQuery**\n+   - **Project ID**: Your BigQuery project identifier (found in the GCP Console)\n+   - **Dataset ID**: The name of your BigQuery dataset (without the project ID)\n+\n+     <Admonition type=\"note\">\n+\n+     In the GCP Console, the dataset is shown as `project-id.dataset-id`. Enter only the part after the dot. For example, if you see `my-project.my_dataset`, enter `my_dataset`.\n+\n+     </Admonition>\n+\n+   - **Service Account Key**: Your GCP service account key in JSON format. The service account must have the following permissions:\n+     - `bigquery.datasets.get`\n+     - `bigquery.tables.create`\n+     - `bigquery.tables.get`\n+     - `bigquery.tables.getData`\n+     - `bigquery.tables.update`\n+     - `bigquery.tables.updateData`\n+\n+4. Complete the remaining configuration following the [ETL Replication Setup guide](/docs/guides/database/replication/etl-replication-setup)\n+\n+### How it works\n+\n+Once configured, ETL Replication to BigQuery:\n+\n+1. Captures changes from your Postgres database (INSERT, UPDATE, DELETE operations)\n+2. Batches changes for optimal performance\n+3. Creates BigQuery tables automatically to match your Postgres schema\n+4. Streams data to BigQuery with CDC metadata\n+\n+<Admonition type=\"note\">\n+\n+Due to ingestion latency in BigQuery's streaming API, there may be a delay (typically seconds to minutes) in data appearing. This is normal and expected for BigQuery's architecture.\n+\n+</Admonition>\n+\n+#### BigQuery CDC format\n+\n+BigQuery tables include additional columns for change tracking:\n+\n+- `_change_type`: The type of change (`INSERT`, `UPDATE`, `DELETE`)\n+- `_commit_timestamp`: When the change was committed in Postgres\n+- `_stream_id`: Internal identifier for the replication stream\n+\n+### Querying replicated data\n+\n+Once replication is running, you can query your data in BigQuery:\n+\n+```sql\n+-- Query the replicated table\n+SELECT * FROM `your-project.your_dataset.users`\n+WHERE created_at > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL 7 DAY);\n+\n+-- View CDC changes\n+SELECT\n+  _change_type,\n+  _commit_timestamp,\n+  id,\n+  name,\n+  email\n+FROM `your-project.your_dataset.users`\n+ORDER BY _commit_timestamp DESC\n+LIMIT 100;\n+```\n+\n+### Limitations\n+\n+BigQuery-specific limitations:\n+\n+- **Ingestion latency**: BigQuery's streaming API has inherent latency (typically seconds to minutes)\n+- **Row size**: Limited to 10 MB per row due to BigQuery Storage Write API constraints\n+\n+For general ETL Replication limitations that apply to all destinations, see the [ETL Replication Setup guide](/docs/guides/database/replication/etl-replication-setup#limitations).\n+\n+### Next steps\n+\n+- [Set up ETL Replication](/docs/guides/database/replication/etl-replication-setup)\n+- [Monitor ETL Replication](/docs/guides/database/replication/etl-replication-monitoring)\n+- [View ETL Replication FAQ](/docs/guides/database/replication/etl-replication-faq)\ndiff --git a/apps/docs/content/guides/database/replication/etl-destinations.mdx b/apps/docs/content/guides/database/replication/etl-destinations.mdx\nnew file mode 100644\nindex 0000000000000..e958d51d4f748\n--- /dev/null\n+++ b/apps/docs/content/guides/database/replication/etl-destinations.mdx\n@@ -0,0 +1,32 @@\n+---\n+id: 'etl-destinations'\n+title: 'ETL Destinations'\n+description: 'Choose where to replicate your database with ETL Replication.'\n+subtitle: 'Available destinations for ETL Replication.'\n+sidebar_label: 'Destinations'\n+---\n+\n+<Admonition type=\"caution\" label=\"Private Alpha\">\n+\n+ETL Replication is currently in private alpha. Access is limited and features may change.\n+\n+</Admonition>\n+\n+ETL Replication supports multiple destination types for syncing your database. Choose the destination that best fits your analytics and integration needs.\n+\n+<Admonition type=\"note\">\n+\n+Some destinations may not be available for all users. Additional destinations are planned for the future, but we don't have public timelines to share at this time.\n+\n+</Admonition>\n+\n+### Available destinations\n+\n+| Destination                     | Description                                    | Configuration                                                        |\n+| ------------------------------- | ---------------------------------------------- | -------------------------------------------------------------------- |\n+| **Iceberg (Analytics Buckets)** | Apache Iceberg tables in S3-compatible storage | [Configure Iceberg →](/docs/guides/database/replication/etl-iceberg) |\n+\n+### Next steps\n+\n+- [Set up ETL Replication](/docs/guides/database/replication/etl-replication-setup)\n+- [Monitor ETL Replication](/docs/guides/database/replication/etl-replication-monitoring)\ndiff --git a/apps/docs/content/guides/database/replication/etl-iceberg.mdx b/apps/docs/content/guides/database/replication/etl-iceberg.mdx\nnew file mode 100644\nindex 0000000000000..5db6f621b66de\n--- /dev/null\n+++ b/apps/docs/content/guides/database/replication/etl-iceberg.mdx\n@@ -0,0 +1,88 @@\n+---\n+id: 'etl-iceberg'\n+title: 'ETL to Iceberg (Analytics Buckets)'\n+description: 'Replicate your Supabase database to Iceberg format using Analytics Buckets.'\n+subtitle: 'Stream data to Analytics Buckets.'\n+sidebar_label: 'Iceberg'\n+---\n+\n+<Admonition type=\"caution\" label=\"Private Alpha\">\n+\n+ETL Replication is currently in private alpha. Access is limited and features may change.\n+\n+</Admonition>\n+\n+<Admonition type=\"caution\" label=\"Current Limitation\">\n+\n+Iceberg replication is currently incomplete. It provides an append-only log listing all your data changes with an additional column explaining the type of operation (INSERT, UPDATE, DELETE).\n+\n+</Admonition>\n+\n+Apache Iceberg is an open table format for analytic datasets. ETL Replication to Iceberg uses Supabase [Analytics Buckets](/docs/guides/storage/analytics) to store your replicated data.\n+\n+<Admonition type=\"tip\">\n+\n+This page covers Iceberg-specific configuration. For complete setup instructions including publications, general settings, and pipeline management, see the [ETL Replication Setup guide](/docs/guides/database/replication/etl-replication-setup).\n+\n+</Admonition>\n+\n+### Setup\n+\n+Setting up Iceberg replication requires two steps: creating an Analytics Bucket, then configuring it as an ETL destination.\n+\n+#### Step 1: Create an Analytics bucket\n+\n+First, create an Analytics Bucket to store your replicated data:\n+\n+1. Navigate to [Storage](/dashboard/project/_/storage/buckets) → **Analytics** in your Supabase Dashboard\n+2. Click **New bucket**\n+\n+   <Image\n+     alt=\"Create New Analytics Bucket\"\n+     src=\"/docs/img/database/replication/etl-iceberg-new-bucket.png\"\n+     zoomable\n+   />\n+\n+#### Step 2: Add Iceberg as an ETL destination\n+\n+After clicking **New bucket**, fill in the bucket details and copy the credentials:\n+\n+1. Fill in the bucket details:\n+\n+   <Image\n+     alt=\"Analytics Bucket Details\"\n+     src=\"/docs/img/database/replication/etl-iceberg-details.png\"\n+     zoomable\n+   />\n+\n+   - **Name**: A unique name for your bucket\n+   - **Region**: Select the region where your data will be stored\n+\n+2. Click **Create bucket**\n+3. **Copy the credentials** displayed after bucket creation (Catalog Token, S3 Access Key ID, S3 Secret Access Key). You'll need these in the next steps.\n+4. Navigate to [Database](/dashboard/project/_/database/etl) → **ETL Replication** in your Supabase Dashboard\n+5. Click **Add destination**\n+6. Configure the destination:\n+   - **Destination type**: Select **Iceberg (Analytics Bucket)**\n+   - **Bucket**: The name of your Analytics Bucket from Step 1\n+   - **Namespace**: The schema name where your tables will be replicated (e.g., `public`)\n+   - **Catalog Token**: Authentication token for accessing the Iceberg catalog (copied in Step 3)\n+   - **S3 Access Key ID**: Access key for S3-compatible storage (copied in Step 3)\n+   - **S3 Secret Access Key**: Secret key for S3-compatible storage (copied in Step 3)\n+7. Complete the remaining configuration following the [ETL Replication Setup guide](/docs/guides/database/replication/etl-replication-setup)\n+\n+For more information about Analytics Buckets, see the [Analytics Buckets documentation](/docs/guides/storage/analytics).\n+\n+### Limitations\n+\n+Iceberg-specific limitations:\n+\n+- **Append-only log**: Currently provides an append-only log format rather than a full table representation\n+\n+For general ETL Replication limitations that apply to all destinations, see the [ETL Replication Setup guide](/docs/guides/database/replication/etl-replication-setup#limitations).\n+\n+### Next steps\n+\n+- [Set up ETL Replication](/docs/guides/database/replication/etl-replication-setup)\n+- [Monitor ETL Replication](/docs/guides/database/replication/etl-replication-monitoring)\n+- [View ETL Replication FAQ](/docs/guides/database/replication/etl-replication-faq)\ndiff --git a/apps/docs/content/guides/database/replication/etl-replication-faq.mdx b/apps/docs/content/guides/database/replication/etl-replication-faq.mdx\nnew file mode 100644\nindex 0000000000000..e76c1377c5c5a\n--- /dev/null\n+++ b/apps/docs/content/guides/database/replication/etl-replication-faq.mdx\n@@ -0,0 +1,100 @@\n+---\n+id: 'etl-replication-faq'\n+title: 'ETL Replication FAQ'\n+description: 'Frequently asked questions about ETL replication.'\n+subtitle: 'Common questions and answers about ETL replication.'\n+sidebar_label: 'FAQ'\n+---\n+\n+<Admonition type=\"caution\" label=\"Private Alpha\">\n+\n+ETL Replication is currently in private alpha. Access is limited and features may change.\n+\n+</Admonition>\n+\n+## What destinations are supported?\n+\n+ETL Replication currently supports Iceberg (Analytics Buckets). See the [ETL Destinations guide](/docs/guides/database/replication/etl-destinations) for details.\n+\n+## Why is a table not being replicated?\n+\n+Common reasons:\n+\n+- **Missing primary key**: Tables must have a primary key to be replicated\n+- **Not in publication**: Ensure the table is included in your publication\n+- **Unsupported data types**: Tables with custom data types are not supported\n+- **Partitioned tables**: Not currently supported\n+\n+Check your publication settings and verify your table meets the requirements.\n+\n+## Why aren't publication changes reflected after adding or removing tables?\n+\n+After modifying your publication, you must restart the ETL pipeline for changes to take effect. See [Adding or removing tables](/docs/guides/database/replication/etl-replication-setup#adding-or-removing-tables) for instructions.\n+\n+## Why is a pipeline in failed state?\n+\n+Pipeline failures occur during the streaming phase when an error happens while replicating live data. This prevents data loss. To recover:\n+\n+1. Check the error message by hovering over the **Failed** status\n+2. Click **View status** for detailed information\n+3. Fix the underlying issue (e.g., schema mismatches, destination connectivity)\n+4. Restart the pipeline\n+\n+See [Handling errors](/docs/guides/database/replication/etl-replication-monitoring#handling-errors) for more details.\n+\n+## Why is a table in error state?\n+\n+Table errors occur during the copy phase. To recover, click **View status**, find the affected table, and reset the table state. This will restart the table copy from the beginning.\n+\n+## How to verify replication is working\n+\n+Check the [Database](/dashboard/project/_/database/etl) → **ETL Replication** page:\n+\n+1. Verify your pipeline shows **Running** status\n+2. Click **View status** to check table states\n+3. Ensure all tables show **Live** state (actively replicating)\n+4. Monitor replication lag metrics\n+\n+See the [ETL Replication Monitoring guide](/docs/guides/database/replication/etl-replication-monitoring) for comprehensive monitoring instructions.\n+\n+## What are the main limitations?\n+\n+Key limitations to be aware of:\n+\n+- **Primary keys**: Required on all tables\n+- **Custom data types**: Not supported\n+- **Schema changes**: Not automatically handled\n+\n+Destination-specific limitations may also apply. See the [Iceberg](/docs/guides/database/replication/etl-iceberg#limitations) destination page for details.\n+\n+## How to stop or pause replication\n+\n+You can manage your pipeline using the actions menu in the destinations list. See [Managing your pipeline](/docs/guides/database/replication/etl-replication-setup#managing-your-pipeline) for details on available actions.\n+\n+Note: Stopping replication will cause changes to queue up in the WAL.\n+\n+## Can data duplicates occur during pipeline operations?\n+\n+Yes, data duplicates can occur in certain scenarios when stopping a pipeline.\n+\n+When you stop a pipeline (for restarts or updates), ETL Replication tries to finish processing any transactions that are currently being sent to your destination. It waits up to a few minutes to allow these in-progress transactions to complete cleanly before stopping.\n+\n+However, if a transaction in your database takes longer than this waiting period to complete, the pipeline will stop before that entire transaction has been fully processed. When the pipeline starts again, it must restart the incomplete transaction from the beginning to maintain transaction boundaries, which results in some data being sent twice to your destination.\n+\n+**Understanding transaction boundaries**: A transaction is a group of database changes that happen together (for example, all changes within a `BEGIN...COMMIT` block). ETL Replication must process entire transactions - it cannot process part of a transaction, stop, and then continue from the middle. This means if a transaction is interrupted, the whole transaction must be replayed when the pipeline resumes.\n+\n+**Example scenario**: Suppose you have a batch operation that updates 10,000 rows within a single transaction. If this operation takes 10 minutes to complete and you stop the pipeline after 5 minutes (when 5,000 rows have been processed), the pipeline cannot resume from row 5,001. Instead, when it restarts, it must reprocess all 10,000 rows from the beginning, resulting in the first 5,000 rows being sent to your destination twice.\n+\n+**Important**: We are not currently planning to implement automatic deduplication. If your use case requires guaranteed exactly-once delivery, you should implement deduplication logic in your downstream systems based on primary keys or other unique identifiers.\n+\n+## Where to find replication logs\n+\n+Navigate to [Logs](/dashboard/project/_/logs/explorer) → **ETL Replication** to see all pipeline logs. Logs contain diagnostic information. If you're experiencing issues, contact support with your error details.\n+\n+## How to get help\n+\n+If you need assistance:\n+\n+1. Check the [ETL Replication Setup guide](/docs/guides/database/replication/etl-replication-setup) and [ETL Replication Monitoring guide](/docs/guides/database/replication/etl-replication-monitoring)\n+2. Review this FAQ for common issues\n+3. Contact support with your error details and logs\ndiff --git a/apps/docs/content/guides/database/replication/etl-replication-monitoring.mdx b/apps/docs/content/guides/database/replication/etl-replication-monitoring.mdx\nnew file mode 100644\nindex 0000000000000..f524d326db4e7\n--- /dev/null\n+++ b/apps/docs/content/guides/database/replication/etl-replication-monitoring.mdx\n@@ -0,0 +1,180 @@\n+---\n+id: 'etl-replication-monitoring'\n+title: 'ETL Replication Monitoring'\n+description: 'Monitor the status and health of your ETL replication pipelines.'\n+subtitle: 'Track replication status, view logs, and troubleshoot issues.'\n+sidebar_label: 'Monitoring'\n+---\n+\n+<Admonition type=\"caution\" label=\"Private Alpha\">\n+\n+ETL Replication is currently in private alpha. Access is limited and features may change.\n+\n+</Admonition>\n+\n+After setting up ETL replication, you can monitor the status and health of your replication pipelines directly from the Supabase Dashboard. The pipeline is the active process that continuously replicates changes from your database to your destination.\n+\n+### Viewing pipeline status\n+\n+To monitor your ETL replication pipelines:\n+\n+1. Navigate to the [Database](/dashboard/project/_/database/etl) section in your Supabase Dashboard\n+2. Select the **ETL Replication** tab\n+3. You'll see a list of all your destinations with their pipeline status\n+\n+<Image\n+  alt=\"ETL Destinations List\"\n+  src=\"/docs/img/database/replication/etl-destinations-list.png\"\n+  zoomable\n+/>\n+\n+#### Pipeline states\n+\n+Each destination shows its pipeline in one of these states:\n+\n+| State        | Description                                                                     |\n+| ------------ | ------------------------------------------------------------------------------- |\n+| **Stopped**  | Pipeline is not running                                                         |\n+| **Starting** | Pipeline is being started                                                       |\n+| **Running**  | Pipeline is actively replicating data                                           |\n+| **Stopping** | Pipeline is being stopped                                                       |\n+| **Failed**   | Pipeline has encountered an error (hover over the status to view error details) |\n+\n+### Viewing detailed pipeline metrics\n+\n+For detailed information about a specific pipeline, click **View status** on the destination. This opens the pipeline status page where you can monitor replication performance and table states.\n+\n+<Image\n+  alt=\"Pipeline Status View\"\n+  src=\"/docs/img/database/replication/etl-view-status.png\"\n+  zoomable\n+/>\n+\n+#### Replication lag metrics\n+\n+The status page shows replication lag metrics that help you determine how fast your pipeline is replicating data. These metrics are loaded directly from Postgres itself.\n+\n+#### Table states\n+\n+The pipeline status page also shows the state of individual tables being replicated. Each table can be in one of these states:\n+\n+| State       | Description                                                            |\n+| ----------- | ---------------------------------------------------------------------- |\n+| **Queue**   | Table is getting ready to be copied                                    |\n+| **Copying** | Initial snapshot of the table is being copied                          |\n+| **Copied**  | Table snapshot is complete and getting ready for real-time replication |\n+| **Live**    | Table is now replicating data in near real-time                        |\n+| **Error**   | Table has experienced an error during replication                      |\n+\n+### Handling errors\n+\n+Errors can occur at two levels: per table or per pipeline.\n+\n+#### Table errors\n+\n+Table errors occur during the copy phase and affect individual tables. These errors can be retried without stopping the entire pipeline.\n+\n+<Image\n+  alt=\"Table Error Details\"\n+  src=\"/docs/img/database/replication/etl-pipeline-table-error.png\"\n+  zoomable\n+/>\n+\n+**Viewing table error details:**\n+\n+1. Click **View status** on your destination\n+2. Check the table states section to identify tables in **Error** state\n+3. Review the error message for that specific table\n+\n+**Recovering from table errors:**\n+\n+When a table encounters an error during the copy phase, you can reset the table state (for some errors). This will restart the table copy from the beginning.\n+\n+#### Pipeline errors\n+\n+Pipeline errors occur during the streaming phase (Live state) and affect the entire pipeline. When streaming data, if an error occurs, the entire pipeline will stop and enter a **Failed** state. This prevents data loss by ensuring no changes are skipped.\n+\n+<Image\n+  alt=\"Pipeline Error Details\"\n+  src=\"/docs/img/database/replication/etl-pipeline-error.png\"\n+  zoomable\n+/>\n+\n+**Viewing pipeline error details:**\n+\n+1. Hover over the **Failed** status in the destinations list to see a quick error summary\n+2. Click **View status** for comprehensive error information\n+3. Navigate to [Logs](/dashboard/project/_/logs/explorer) → **ETL Replication** for detailed error logs\n+\n+**Recovering from pipeline errors:**\n+\n+To recover from a pipeline error, you'll need to:\n+\n+1. Investigate the root cause using the error details and logs\n+2. Fix the underlying issue (e.g., destination connectivity, schema compatibility)\n+3. Restart the pipeline from the destinations list\n+\n+### Viewing logs\n+\n+To see detailed logs for all your ETL replication pipelines:\n+\n+1. Navigate to [Logs](/dashboard/project/_/logs/explorer) in your Supabase Dashboard\n+2. Select **ETL Replication** from the log source filter\n+3. You'll see all logs from your replication pipelines\n+\n+<Image\n+  alt=\"ETL Replication Logs\"\n+  src=\"/docs/img/database/replication/etl-replication-logs.png\"\n+  zoomable\n+/>\n+\n+<Admonition type=\"note\">\n+\n+Logs contain diagnostic information that may be too technical for most users. If you're experiencing issues with ETL replication, reaching out to support with your error details is recommended.\n+\n+</Admonition>\n+\n+### Common monitoring scenarios\n+\n+#### Checking if replication is healthy\n+\n+1. Navigate to [Database](/dashboard/project/_/database/etl) → **ETL Replication**\n+2. Verify your destination shows **Running** status\n+3. Click **View status** to check replication lag and table states\n+4. Ensure all tables show **Live** state\n+\n+#### Investigating errors\n+\n+If you see a **Failed** status:\n+\n+1. Hover over the status to see the error summary\n+2. Click **View status** to see detailed error information\n+3. Check table states to identify which tables are affected\n+4. Navigate to [Logs](/dashboard/project/_/logs/explorer) → **ETL Replication** for full error details\n+5. For table errors, attempt to reset the affected tables\n+\n+#### Monitoring performance\n+\n+To ensure optimal performance:\n+\n+1. Regularly check replication lag metrics in the pipeline status view\n+2. Monitor table states to ensure tables are staying in **Live** state\n+3. Review logs for warnings or performance issues\n+4. If lag is consistently high, consider adjusting your publication or batch wait time settings\n+\n+### Troubleshooting\n+\n+If you notice issues with your ETL replication:\n+\n+1. **Check pipeline state**: Ensure the pipeline is in **Running** state\n+2. **Review table states**: Identify tables in **Error** state\n+3. **Check logs**: Navigate to Logs → ETL Replication for detailed error information\n+4. **Verify publication**: Ensure your publication is properly configured\n+5. **Monitor replication lag**: High lag may indicate performance issues\n+\n+For more troubleshooting tips, see the [ETL Replication FAQ](/docs/guides/database/replication/etl-replication-faq).\n+\n+### Next steps\n+\n+- [Set up ETL Replication](/docs/guides/database/replication/etl-replication-setup)\n+- [View ETL Replication FAQ](/docs/guides/database/replication/etl-replication-faq)\ndiff --git a/apps/docs/content/guides/database/replication/etl-replication-setup.mdx b/apps/docs/content/guides/database/replication/etl-replication-setup.mdx\nnew file mode 100644\nindex 0000000000000..34b3d1ea4cbf9\n--- /dev/null\n+++ b/apps/docs/content/guides/database/replication/etl-replication-setup.mdx\n@@ -0,0 +1,260 @@\n+---\n+id: 'etl-replication-setup'\n+title: 'ETL Replication Setup'\n+description: 'Set up ETL replication to automatically sync your database to external destinations.'\n+subtitle: 'Configure publications and destinations for ETL replication.'\n+sidebar_label: 'Setting up'\n+---\n+\n+<Admonition type=\"caution\" label=\"Private Alpha\">\n+\n+ETL Replication is currently in private alpha. Access is limited and features may change.\n+\n+</Admonition>\n+\n+ETL Replication requires two main components: a **publication** (source) and a **destination**. Follow these steps to set up your replication pipeline.\n+\n+<Admonition type=\"tip\">\n+\n+If you already have a publication set up, you can skip to [Step 2: Enable ETL Replication](#step-2-enable-etl-replication).\n+\n+</Admonition>\n+\n+### Step 1: Create a publication\n+\n+A publication defines which tables and change types will be replicated. You need to create a publication using SQL.\n+\n+#### Creating a publication\n+\n+The following SQL examples assume you have `users` and `orders` tables in your database.\n+\n+##### Publication for specific tables\n+\n+```sql\n+-- Create publication for both tables\n+create publication pub_users_orders\n+for table users, orders;\n+```\n+\n+This publication will track all changes (INSERT, UPDATE, DELETE) for both the `users` and `orders` tables.\n+\n+##### Publication for all tables in a schema\n+\n+```sql\n+-- Create a publication for all tables in the public schema\n+create publication pub_all_public for tables in schema public;\n+```\n+\n+This will track changes for all existing and future tables in the `public` schema.\n+\n+##### Publication for all tables\n+\n+```sql\n+-- Create a publication for all tables\n+create publication pub_all_tables for all tables;\n+```\n+\n+This will track changes for all tables in your database.\n+\n+#### Advanced publication options\n+\n+##### Selecting specific columns\n+\n+You can replicate only a subset of columns from a table:\n+\n+```sql\n+-- Replicate only specific columns from the users table\n+create publication pub_users_subset\n+for table users (id, email, created_at);\n+```\n+\n+This will only replicate the `id`, `email`, and `created_at` columns from the `users` table.\n+\n+##### Filtering rows with a predicate\n+\n+You can filter which rows to replicate using a WHERE clause:\n+\n+```sql\n+-- Only replicate active users\n+create publication pub_active_users\n+for table users where (status = 'active');\n+\n+-- Only replicate recent orders\n+create publication pub_recent_orders\n+for table orders where (created_at > '2024-01-01');\n+```\n+\n+#### Viewing publications in the Dashboard\n+\n+After creating a publication via SQL, you can view it in the Supabase Dashboard:\n+\n+1. Navigate to **Database** → [Publications](/dashboard/project/_/database/publications) in your Supabase Dashboard\n+2. You'll see all your publications listed with their tables\n+\n+### Step 2: Enable ETL replication\n+\n+Before adding destinations, you need to enable ETL replication for your project:\n+\n+1. Navigate to the [Database](/dashboard/project/_/database/etl) section in your Supabase Dashboard\n+2. Select the **ETL Replication** tab\n+3. Click **Enable replication** to activate ETL replication for your project\n+\n+<Image\n+  alt=\"Enable ETL Replication\"\n+  src=\"/docs/img/database/replication/etl-enable-replication.png\"\n+  zoomable\n+/>\n+\n+### Step 3: Add a destination\n+\n+Once replication is enabled and you have a publication, you can add a destination. The destination is where your replicated data will be stored, while the pipeline is the active process that continuously replicates changes from your database to that destination.\n+\n+#### Available destinations\n+\n+For a complete list of available destinations and how to choose the right one for your needs, see [ETL Destinations](/docs/guides/database/replication/etl-destinations).\n+\n+#### Configuration\n+\n+1. In the ETL Replication tab, click **Add destination**\n+2. Configure the destination settings:\n+\n+   **General Settings:**\n+\n+   - **Destination name**: A name to identify this destination (e.g., \"Analytics Warehouse\")\n+   - **Publication**: The publication to replicate data from (created in Step 1)\n+   - **Destination type**: Choose from available destination types\n+\n+   **Destination-specific settings:**\n+   Each destination type requires different configuration. See the [ETL Destinations guide](/docs/guides/database/replication/etl-destinations) for configuration details specific to your chosen destination.\n+\n+<Image\n+  alt=\"Add ETL Destination\"\n+  src=\"/docs/img/database/replication/etl-add-destination.png\"\n+  zoomable\n+/>\n+\n+3. Configure **Advanced Settings** (optional):\n+\n+   - **Batch wait time (milliseconds)**: How long to wait for more changes before sending a batch. We recommend leaving this at the default value for optimal performance. Setting this too low can result in too much traffic and less efficient batching.\n+\n+4. Click **Create and start** to begin replication\n+\n+### Step 4: Monitor your pipeline\n+\n+After creating a destination, the pipeline will start and appear in the destinations list. You can monitor the pipeline's status and performance from the Dashboard.\n+\n+<Image\n+  alt=\"ETL Destinations List\"\n+  src=\"/docs/img/database/replication/etl-destinations-list.png\"\n+  zoomable\n+/>\n+\n+For comprehensive monitoring instructions including pipeline states, metrics, and logs, see the [ETL Replication Monitoring guide](/docs/guides/database/replication/etl-replication-monitoring).\n+\n+### Managing your pipeline\n+\n+You can manage your pipeline from the destinations list using the actions menu.\n+\n+<Image\n+  alt=\"Pipeline Actions\"\n+  src=\"/docs/img/database/replication/etl-pipeline-actions.png\"\n+  zoomable\n+/>\n+\n+Available actions:\n+\n+- **Start**: Begin replication for a stopped pipeline\n+- **Stop**: Pause replication (changes will queue up in the WAL)\n+- **Restart**: Stop and start the pipeline (required after publication changes)\n+- **Edit destination**: Modify destination settings like credentials or advanced options\n+- **Delete**: Remove the destination and permanently stop replication\n+\n+### Adding or removing tables\n+\n+If you need to modify which tables are replicated after your ETL pipeline is already running, follow these steps:\n+\n+<Admonition type=\"note\">\n+\n+If your publication uses `FOR ALL TABLES` or `FOR TABLES IN SCHEMA`, new tables in that scope are automatically included in the publication. However, you still **must restart the ETL pipeline** for the changes to take effect.\n+\n+</Admonition>\n+\n+#### Adding tables to replication\n+\n+1. Add the table to your publication using SQL:\n+\n+   ```sql\n+   -- Add a single table to an existing publication\n+   alter publication pub_users_orders add table products;\n+\n+   -- Or add multiple tables at once\n+   alter publication pub_users_orders add table products, categories;\n+   ```\n+\n+2. **Restart the ETL pipeline** using the actions menu (see [Managing your pipeline](#managing-your-pipeline)) for the changes to take effect.\n+\n+#### Removing tables from replication\n+\n+1. Remove the table from your publication using SQL:\n+\n+   ```sql\n+   -- Remove a single table from a publication\n+   alter publication pub_users_orders drop table orders;\n+\n+   -- Or remove multiple tables at once\n+   alter publication pub_users_orders drop table orders, products;\n+   ```\n+\n+2. **Restart the ETL pipeline** using the actions menu (see [Managing your pipeline](#managing-your-pipeline)) for the changes to take effect.\n+\n+### How it works\n+\n+Once configured, ETL Replication:\n+\n+1. **Captures** changes from your database using the publication\n+2. **Loads** the data to your destination in near real-time batches\n+\n+Changes are sent in batches to optimize performance and reduce costs. The batch size and timing can be adjusted using the advanced settings.\n+\n+<Admonition type=\"note\">\n+\n+ETL Replication currently performs data extraction and loading only, without transformation. Your data is replicated as-is to the destination.\n+\n+</Admonition>\n+\n+### Troubleshooting\n+\n+If you encounter issues during setup:\n+\n+- **Publication not appearing**: Ensure you created the publication via SQL and refresh the dashboard\n+- **Tables not showing in publication**: Verify your tables have primary keys (required for replication)\n+- **Pipeline failed to start**: Check the error message in the status view for specific details\n+- **No data being replicated**: Verify your publication includes the correct tables and event types\n+\n+For more troubleshooting help, see the [ETL Replication FAQ](/docs/guides/database/replication/etl-replication-faq).\n+\n+### Limitations\n+\n+ETL Replication has the following limitations that apply to all destinations:\n+\n+- **Primary keys required**: Tables must have primary keys\n+- **Custom data types**: Not supported\n+- **Schema changes**: Not automatically handled\n+- **No data transformation**: Data is replicated as-is without transformation\n+- **Data duplicates**: Duplicates can occur when stopping a pipeline if your database has transactions that take longer than a few minutes to complete. See [Can data duplicates occur?](/docs/guides/database/replication/etl-replication-faq#can-data-duplicates-occur-during-pipeline-operations) for details\n+\n+Destination-specific limitations may also apply. See the [Iceberg](/docs/guides/database/replication/etl-iceberg#limitations) destination page for details.\n+\n+### Future work\n+\n+ETL Replication is actively being developed. Planned improvements include:\n+\n+- **DDL support**: Automatic handling of schema changes (ALTER TABLE, ADD COLUMN, etc.)\n+- **Additional destinations**: Support for more data warehouses and analytics platforms\n+\n+We don't have public timelines for these features, but they represent our roadmap for making ETL Replication more robust and flexible.\n+\n+### Next steps\n+\n+- [Monitor ETL Replication](/docs/guides/database/replication/etl-replication-monitoring)\n+- [View ETL Replication FAQ](/docs/guides/database/replication/etl-replication-faq)\ndiff --git a/apps/docs/content/guides/database/replication/faq.mdx b/apps/docs/content/guides/database/replication/manual-replication-faq.mdx\nsimilarity index 73%\nrename from apps/docs/content/guides/database/replication/faq.mdx\nrename to apps/docs/content/guides/database/replication/manual-replication-faq.mdx\nindex 93427562d689c..d909e2b629468 100644\n--- a/apps/docs/content/guides/database/replication/faq.mdx\n+++ b/apps/docs/content/guides/database/replication/manual-replication-faq.mdx\n@@ -1,21 +1,22 @@\n ---\n id: 'replication-faq'\n-title: 'FAQs'\n-description: 'Considerations and FAQs when setting up replication'\n-sidebar_label: 'FAQs'\n+title: 'Replication FAQ'\n+description: 'Frequently asked questions about manual database replication.'\n+subtitle: 'Common questions and considerations when setting up manual replication.'\n+sidebar_label: 'FAQ'\n ---\n \n-# Which connection string should be used?\n+## Which connection string should be used?\n \n Always use the direct connection string for logical replication.\n \n Connections through a pooler, such as Supavisor, will not work.\n \n-# The tool in use does not support IPv6\n+## The tool in use does not support IPv6\n \n You can enable the [IPv4 add-on](/docs/guides/platform/ipv4-address) for your project.\n \n-# What is XMIN and should it be used?\n+## What is XMIN and should it be used?\n \n Xmin is a different form of replication from logical replication and should only be used if logical replication is not available for your database (i.e. older versions of Postgres).\n \n@@ -23,15 +24,15 @@ Xmin performs replication by checking the [xmin system column](https://www.postg\n \n It does not capture deletion of data and is **not recommended**, particularly for larger databases.\n \n-# Can replication be configured in the Dashboard?\n+## Can replication be configured in the Dashboard?\n \n You can view [publications](/dashboard/project/default/database/publications) in the Dashboard but all steps to configure replication must be done using the [SQL Editor](/dashboard/project/default/sql/new) or a CLI tool of your choice.\n \n-# How to configure database settings for replication?\n+## How to configure database settings for replication?\n \n Yes. Using the Supabase CLI, you can [configure database settings](/docs/guides/database/custom-postgres-config#cli-configurable-settings) to optimize them for your replication needs. These values can vary depending on the activity of your database size and activity.\n \n-# What are some important configuration options?\n+## What are some important configuration options?\n \n Some of the more important options to be aware of are:\n \ndiff --git a/apps/docs/content/guides/database/replication/monitoring-replication.mdx b/apps/docs/content/guides/database/replication/manual-replication-monitoring.mdx\nsimilarity index 88%\nrename from apps/docs/content/guides/database/replication/monitoring-replication.mdx\nrename to apps/docs/content/guides/database/replication/manual-replication-monitoring.mdx\nindex 300ca96689822..0047bc80136e4 100644\n--- a/apps/docs/content/guides/database/replication/monitoring-replication.mdx\n+++ b/apps/docs/content/guides/database/replication/manual-replication-monitoring.mdx\n@@ -1,5 +1,9 @@\n ---\n-title: 'Monitoring replication'\n+id: 'monitoring-replication'\n+title: 'Monitoring Replication'\n+description: 'Monitor replication lag and status for manual replication setups.'\n+subtitle: 'Track replication health and performance.'\n+sidebar_label: 'Monitoring'\n ---\n \n Monitoring replication lag is important and there are 3 ways to do this:\n@@ -14,9 +18,9 @@ Monitoring replication lag is important and there are 3 ways to do this:\n    - pg_stat_replication_replay_lag - lag to replay WAL files from the source DB on the target DB (throttled by disk or high activity)\n    - pg_stat_replication_send_lag - lag in sending WAL files from the source DB (a high lag means that the publisher is not being asked to send new WAL files OR a network issues)\n \n-## Primary\n+### Primary\n \n-### Replication status and lag\n+#### Replication status and lag\n \n The `pg_stat_replication` table shows the status of any replicas connected to the primary database.\n \n@@ -25,7 +29,7 @@ select pid, application_name, state, sent_lsn, write_lsn, flush_lsn, replay_lsn,\n from pg_stat_replication;\n ```\n \n-### Replication slot status\n+#### Replication slot status\n \n A replication slot can be in one of three states:\n \n@@ -39,7 +43,7 @@ The state can be checked using the `pg_replication_slots` table:\n select slot_name, active, state from pg_replication_slots;\n ```\n \n-### WAL size\n+#### WAL size\n \n The WAL size can be checked using the `pg_ls_waldir()` function:\n \n@@ -47,15 +51,15 @@ The WAL size can be checked using the `pg_ls_waldir()` function:\n select * from pg_ls_waldir();\n ```\n \n-### Check LSN\n+#### Check LSN\n \n ```sql\n select pg_current_wal_lsn();\n ```\n \n-## Subscriber\n+### Subscriber\n \n-### Subscription status\n+#### Subscription status\n \n The `pg_subscription` table shows the status of any subscriptions on a replica and the `pg_subscription_rel` table shows the status of each table within a subscription.\n \n@@ -87,7 +91,7 @@ ORDER BY\n     table_name;\n ```\n \n-### Check LSN\n+#### Check LSN\n \n ```sql\n select pg_last_wal_replay_lsn();\ndiff --git a/apps/docs/content/guides/database/replication/setting-up-replication.mdx b/apps/docs/content/guides/database/replication/manual-replication-setup.mdx\nsimilarity index 80%\nrename from apps/docs/content/guides/database/replication/setting-up-replication.mdx\nrename to apps/docs/content/guides/database/replication/manual-replication-setup.mdx\nindex 5258bc2d18eed..eeccf0a383579 100644\n--- a/apps/docs/content/guides/database/replication/setting-up-replication.mdx\n+++ b/apps/docs/content/guides/database/replication/manual-replication-setup.mdx\n@@ -1,11 +1,20 @@\n ---\n-id: 'setting-up-replication'\n-title: 'Setting up replication and CDC with Supabase'\n-description: 'Performing Extract Transform Load (ETL) with Supabase'\n-sidebar_label: 'Setting up replication and CDC'\n+id: 'manual-replication-setup'\n+title: 'Manual Replication Setup'\n+description: 'Configure your own replication using external tools and Postgres logical replication.'\n+subtitle: 'Set up replication with Airbyte, Estuary, Fivetran, and other tools.'\n+sidebar_label: 'Setting up'\n ---\n \n-## Prerequisites\n+This guide covers setting up **manual replication** using external tools. If you prefer a simpler, managed solution, see [ETL Replication](/docs/guides/database/replication/etl-replication-setup) instead.\n+\n+<Admonition type=\"note\">\n+\n+This guide is for replicating data to external systems using your own tools. For deploying read-only databases across multiple regions, see [Read Replicas](/docs/guides/platform/read-replicas) instead.\n+\n+</Admonition>\n+\n+### Prerequisites\n \n To set up replication, the following is recommended:\n \n@@ -39,7 +48,7 @@ You can follow those steps with the following modifications:\n 1. Use the `postgres` user\n 2. Select `logical replication` as the replication method (`xmin` is possible, but not recommended)\n \n-## Troubleshooting\n+### Troubleshooting\n \n Airbyte has a known [issue](https://discuss.airbyte.io/t/postgres-source-replication-slot-safe-wal-size-only-reset-when-a-change-occurs/3263/7) where it does not clear WAL files on each successful sync. The recommended workaround is to have a `heartbeat` table that you write changes to once an hour.>\n \ndiff --git a/apps/docs/content/guides/getting-started/features.mdx b/apps/docs/content/guides/getting-started/features.mdx\nindex 33cf6c0345bbc..a5d10213bff00 100644\n--- a/apps/docs/content/guides/getting-started/features.mdx\n+++ b/apps/docs/content/guides/getting-started/features.mdx\n@@ -32,6 +32,10 @@ Send database changes to any external service using Webhooks. [Docs](/docs/guide\n \n Encrypt sensitive data and store secrets using our Postgres extension, Supabase Vault. [Docs](/docs/guides/database/vault).\n \n+### ETL replication\n+\n+Automatically replicate your database to external destinations like data warehouses and analytics platforms. [Docs](/docs/guides/database/replication/etl-replication).\n+\n ## Platform\n \n ### Database backups\n@@ -195,59 +199,60 @@ Features in Beta are tested by an external penetration tester for security issue\n \n In addition to the Beta requirements, features in GA are covered by the [uptime SLA](/sla).\n \n-| Product        | Feature                    | Stage          | Available on self-hosted                    |\n-| -------------- | -------------------------- | -------------- | ------------------------------------------- |\n-| Database       | Postgres                   | `GA`           | ✅                                          |\n-| Database       | Vector Database            | `GA`           | ✅                                          |\n-| Database       | Auto-generated Rest API    | `GA`           | ✅                                          |\n-| Database       | Auto-generated GraphQL API | `GA`           | ✅                                          |\n-| Database       | Webhooks                   | `beta`         | ✅                                          |\n-| Database       | Vault                      | `public alpha` | ✅                                          |\n-| Platform       |                            | `GA`           | ✅                                          |\n-| Platform       | Point-in-Time Recovery     | `GA`           | 🚧 [wal-g](https://github.com/wal-g/wal-g)  |\n-| Platform       | Custom Domains             | `GA`           | N/A                                         |\n-| Platform       | Network Restrictions       | `GA`           | N/A                                         |\n-| Platform       | SSL enforcement            | `GA`           | N/A                                         |\n-| Platform       | Branching                  | `beta`         | N/A                                         |\n-| Platform       | Terraform Provider         | `public alpha` | N/A                                         |\n-| Platform       | Read Replicas              | `GA`           | N/A                                         |\n-| Platform       | Log Drains                 | `public alpha` | ✅                                          |\n-| Platform       | MCP                        | `public alpha` | ✅                                          |\n-| Studio         |                            | `GA`           | ✅                                          |\n-| Studio         | SSO                        | `GA`           | ✅                                          |\n-| Studio         | Column Privileges          | `public alpha` | ✅                                          |\n-| Realtime       | Postgres Changes           | `GA`           | ✅                                          |\n-| Realtime       | Broadcast                  | `GA`           | ✅                                          |\n-| Realtime       | Presence                   | `GA`           | ✅                                          |\n-| Realtime       | Broadcast Authorization    | `public beta`  | ✅                                          |\n-| Realtime       | Presence Authorization     | `public beta`  | ✅                                          |\n-| Realtime       | Broadcast from Database    | `public beta`  | ✅                                          |\n-| Storage        |                            | `GA`           | ✅                                          |\n-| Storage        | CDN                        | `GA`           | 🚧 [Cloudflare](https://www.cloudflare.com) |\n-| Storage        | Smart CDN                  | `GA`           | 🚧 [Cloudflare](https://www.cloudflare.com) |\n-| Storage        | Image Transformations      | `GA`           | ✅                                          |\n-| Storage        | Resumable Uploads          | `GA`           | ✅                                          |\n-| Storage        | S3 compatibility           | `GA`           | ✅                                          |\n-| Edge Functions |                            | `GA`           | ✅                                          |\n-| Edge Functions | Regional Invocations       | `GA`           | ✅                                          |\n-| Edge Functions | NPM compatibility          | `GA`           | ✅                                          |\n-| Auth           |                            | `GA`           | ✅                                          |\n-| Auth           | Email login                | `GA`           | ✅                                          |\n-| Auth           | Social login               | `GA`           | ✅                                          |\n-| Auth           | Phone login                | `GA`           | ✅                                          |\n-| Auth           | Passwordless login         | `GA`           | ✅                                          |\n-| Auth           | SSO with SAML              | `GA`           | ✅                                          |\n-| Auth           | Authorization via RLS      | `GA`           | ✅                                          |\n-| Auth           | CAPTCHA protection         | `GA`           | ✅                                          |\n-| Auth           | Server-side Auth           | `beta`         | ✅                                          |\n-| Auth           | Third-Party Auth           | `GA`           | ✅                                          |\n-| Auth           | Hooks                      | `beta`         | ✅                                          |\n-| CLI            |                            | `GA`           | ✅ Works with self-hosted                   |\n-| Management API |                            | `GA`           | N/A                                         |\n-| Client Library | JavaScript                 | `GA`           | N/A                                         |\n-| Client Library | Flutter                    | `GA`           | N/A                                         |\n-| Client Library | Swift                      | `GA`           | N/A                                         |\n-| Client Library | Python                     | `beta`         | N/A                                         |\n+| Product        | Feature                    | Stage           | Available on self-hosted                    |\n+| -------------- | -------------------------- | --------------- | ------------------------------------------- |\n+| Database       | Postgres                   | `GA`            | ✅                                          |\n+| Database       | Vector Database            | `GA`            | ✅                                          |\n+| Database       | Auto-generated Rest API    | `GA`            | ✅                                          |\n+| Database       | Auto-generated GraphQL API | `GA`            | ✅                                          |\n+| Database       | Webhooks                   | `beta`          | ✅                                          |\n+| Database       | Vault                      | `public alpha`  | ✅                                          |\n+| Database       | ETL Replication            | `private alpha` | N/A                                         |\n+| Platform       |                            | `GA`            | ✅                                          |\n+| Platform       | Point-in-Time Recovery     | `GA`            | 🚧 [wal-g](https://github.com/wal-g/wal-g)  |\n+| Platform       | Custom Domains             | `GA`            | N/A                                         |\n+| Platform       | Network Restrictions       | `GA`            | N/A                                         |\n+| Platform       | SSL enforcement            | `GA`            | N/A                                         |\n+| Platform       | Branching                  | `beta`          | N/A                                         |\n+| Platform       | Terraform Provider         | `public alpha`  | N/A                                         |\n+| Platform       | Read Replicas              | `GA`            | N/A                                         |\n+| Platform       | Log Drains                 | `public alpha`  | ✅                                          |\n+| Platform       | MCP                        | `public alpha`  | ✅                                          |\n+| Studio         |                            | `GA`            | ✅                                          |\n+| Studio         | SSO                        | `GA`            | ✅                                          |\n+| Studio         | Column Privileges          | `public alpha`  | ✅                                          |\n+| Realtime       | Postgres Changes           | `GA`            | ✅                                          |\n+| Realtime       | Broadcast                  | `GA`            | ✅                                          |\n+| Realtime       | Presence                   | `GA`            | ✅                                          |\n+| Realtime       | Broadcast Authorization    | `public beta`   | ✅                                          |\n+| Realtime       | Presence Authorization     | `public beta`   | ✅                                          |\n+| Realtime       | Broadcast from Database    | `public beta`   | ✅                                          |\n+| Storage        |                            | `GA`            | ✅                                          |\n+| Storage        | CDN                        | `GA`            | 🚧 [Cloudflare](https://www.cloudflare.com) |\n+| Storage        | Smart CDN                  | `GA`            | 🚧 [Cloudflare](https://www.cloudflare.com) |\n+| Storage        | Image Transformations      | `GA`            | ✅                                          |\n+| Storage        | Resumable Uploads          | `GA`            | ✅                                          |\n+| Storage        | S3 compatibility           | `GA`            | ✅                                          |\n+| Edge Functions |                            | `GA`            | ✅                                          |\n+| Edge Functions | Regional Invocations       | `GA`            | ✅                                          |\n+| Edge Functions | NPM compatibility          | `GA`            | ✅                                          |\n+| Auth           |                            | `GA`            | ✅                                          |\n+| Auth           | Email login                | `GA`            | ✅                                          |\n+| Auth           | Social login               | `GA`            | ✅                                          |\n+| Auth           | Phone login                | `GA`            | ✅                                          |\n+| Auth           | Passwordless login         | `GA`            | ✅                                          |\n+| Auth           | SSO with SAML              | `GA`            | ✅                                          |\n+| Auth           | Authorization via RLS      | `GA`            | ✅                                          |\n+| Auth           | CAPTCHA protection         | `GA`            | ✅                                          |\n+| Auth           | Server-side Auth           | `beta`          | ✅                                          |\n+| Auth           | Third-Party Auth           | `GA`            | ✅                                          |\n+| Auth           | Hooks                      | `beta`          | ✅                                          |\n+| CLI            |                            | `GA`            | ✅ Works with self-hosted                   |\n+| Management API |                            | `GA`            | N/A                                         |\n+| Client Library | JavaScript                 | `GA`            | N/A                                         |\n+| Client Library | Flutter                    | `GA`            | N/A                                         |\n+| Client Library | Swift                      | `GA`            | N/A                                         |\n+| Client Library | Python                     | `beta`          | N/A                                         |\n \n - ✅ = Fully Available\n - 🚧 = Available, but requires external tools or configuration\ndiff --git a/apps/docs/public/img/database/replication/etl-add-destination.png b/apps/docs/public/img/database/replication/etl-add-destination.png\nnew file mode 100644\nindex 0000000000000..88154e6767763\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-add-destination.png differ\ndiff --git a/apps/docs/public/img/database/replication/etl-bigquery-details.png b/apps/docs/public/img/database/replication/etl-bigquery-details.png\nnew file mode 100644\nindex 0000000000000..587ddca2bf2ed\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-bigquery-details.png differ\ndiff --git a/apps/docs/public/img/database/replication/etl-destinations-list.png b/apps/docs/public/img/database/replication/etl-destinations-list.png\nnew file mode 100644\nindex 0000000000000..b33f6c20f1f98\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-destinations-list.png differ\ndiff --git a/apps/docs/public/img/database/replication/etl-enable-replication.png b/apps/docs/public/img/database/replication/etl-enable-replication.png\nnew file mode 100644\nindex 0000000000000..e6c34f117a554\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-enable-replication.png differ\ndiff --git a/apps/docs/public/img/database/replication/etl-iceberg-bucket-details.png b/apps/docs/public/img/database/replication/etl-iceberg-bucket-details.png\nnew file mode 100644\nindex 0000000000000..367d7080dce70\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-iceberg-bucket-details.png differ\ndiff --git a/apps/docs/public/img/database/replication/etl-iceberg-details.png b/apps/docs/public/img/database/replication/etl-iceberg-details.png\nnew file mode 100644\nindex 0000000000000..ba51c58c3a56b\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-iceberg-details.png differ\ndiff --git a/apps/docs/public/img/database/replication/etl-iceberg-new-bucket.png b/apps/docs/public/img/database/replication/etl-iceberg-new-bucket.png\nnew file mode 100644\nindex 0000000000000..fbd860ef20af0\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-iceberg-new-bucket.png differ\ndiff --git a/apps/docs/public/img/database/replication/etl-pipeline-actions.png b/apps/docs/public/img/database/replication/etl-pipeline-actions.png\nnew file mode 100644\nindex 0000000000000..870e96fab51d5\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-pipeline-actions.png differ\ndiff --git a/apps/docs/public/img/database/replication/etl-pipeline-error.png b/apps/docs/public/img/database/replication/etl-pipeline-error.png\nnew file mode 100644\nindex 0000000000000..a1c672c94a5f6\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-pipeline-error.png differ\ndiff --git a/apps/docs/public/img/database/replication/etl-pipeline-table-error.png b/apps/docs/public/img/database/replication/etl-pipeline-table-error.png\nnew file mode 100644\nindex 0000000000000..667a6a5b1ceb3\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-pipeline-table-error.png differ\ndiff --git a/apps/docs/public/img/database/replication/etl-replication-logs.png b/apps/docs/public/img/database/replication/etl-replication-logs.png\nnew file mode 100644\nindex 0000000000000..449ae39077cbc\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-replication-logs.png differ\ndiff --git a/apps/docs/public/img/database/replication/etl-view-status.png b/apps/docs/public/img/database/replication/etl-view-status.png\nnew file mode 100644\nindex 0000000000000..3c34ebf4cd63e\nBinary files /dev/null and b/apps/docs/public/img/database/replication/etl-view-status.png differ\n",
			"diffSize": 66223,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "6781e0010f3994da0a1d2802b240c309c745d1f0",
			"message": "feat(ForeignRowSelector): persist and retrieve sort preferences in select record modal (#39261)\n\n* feat(ForeignRowSelector): persist and retrieve sort preferences in sessionStorage\n\n* feat(ForeignRowSelector): use existing table sort local storage\n\n* fix(ForeignRowSelector): prevent re-hydration of persisted sorts on subsequent renders\n\n* small refactors\n\n---------\n\nCo-authored-by: Alaister Young <a@alaisteryoung.com>",
			"user": "tylerclark",
			"timestamp": "2025-11-21T08:44:40Z",
			"author": {
				"name": "Tyler Clark",
				"email": "tyler@tylerclark.com",
				"username": "tylerclark"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/ForeignRowSelector/ForeignRowSelector.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/ForeignRowSelector/ForeignRowSelector.tsx b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/ForeignRowSelector/ForeignRowSelector.tsx\nindex e815f7c3873f8..9b2c8d2f4192d 100644\n--- a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/ForeignRowSelector/ForeignRowSelector.tsx\n+++ b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/ForeignRowSelector/ForeignRowSelector.tsx\n@@ -1,9 +1,15 @@\n import { Loader2 } from 'lucide-react'\n-import { useState } from 'react'\n+import { useEffect, useState } from 'react'\n import { DndProvider } from 'react-dnd'\n import { HTML5Backend } from 'react-dnd-html5-backend'\n \n import { useParams } from 'common'\n+import {\n+  formatSortURLParams,\n+  loadTableEditorStateFromLocalStorage,\n+  saveTableEditorStateToLocalStorage,\n+  sortsToUrlParams,\n+} from 'components/grid/SupabaseGrid.utils'\n import { RefreshButton } from 'components/grid/components/header/RefreshButton'\n import { FilterPopoverPrimitive } from 'components/grid/components/header/filter/FilterPopoverPrimitive'\n import { SortPopoverPrimitive } from 'components/grid/components/header/sort/SortPopoverPrimitive'\n@@ -23,6 +29,8 @@ import { convertByteaToHex } from '../RowEditor.utils'\n import Pagination from './Pagination'\n import SelectorGrid from './SelectorGrid'\n \n+const FOREIGN_ROW_SELECTOR_TABLE_NAME_SUFFIX = '__frselector'\n+\n export interface ForeignRowSelectorProps {\n   visible: boolean\n   foreignKey?: ForeignKey\n@@ -107,6 +115,49 @@ const ForeignRowSelector = ({\n     }\n   )\n \n+  // Only start saving sorts after the previous sorts have been loaded\n+  const [shouldSaveSorts, setShouldSaveSorts] = useState(false)\n+\n+  // Load sorts from local storage\n+  useEffect(() => {\n+    if (!project?.ref || !table?.name || !table?.schema) return\n+\n+    try {\n+      const persistenceTableName = table.name + FOREIGN_ROW_SELECTOR_TABLE_NAME_SUFFIX\n+      const savedState = loadTableEditorStateFromLocalStorage(\n+        project.ref,\n+        persistenceTableName,\n+        table.schema\n+      )\n+      const urlSorts = savedState?.sorts ?? []\n+      const parsedSorts = formatSortURLParams(table.name, urlSorts)\n+      if (parsedSorts.length > 0) {\n+        setFiltersAndSorts((prev) => ({ ...prev, sort: parsedSorts }))\n+      }\n+    } catch (e) {\n+      console.error(e)\n+    } finally {\n+      setShouldSaveSorts(true)\n+    }\n+  }, [project?.ref, table?.schema, table?.name])\n+\n+  // Persist sorts to local storage\n+  useEffect(() => {\n+    if (!project?.ref || !table?.name || !table?.schema || !shouldSaveSorts) return\n+    try {\n+      const urlSorts = sortsToUrlParams(sorts)\n+      const persistenceTableName = table.name + FOREIGN_ROW_SELECTOR_TABLE_NAME_SUFFIX\n+      saveTableEditorStateToLocalStorage({\n+        projectRef: project.ref,\n+        tableName: persistenceTableName,\n+        schema: table.schema,\n+        sorts: urlSorts,\n+      })\n+    } catch (e) {\n+      console.error(e)\n+    }\n+  }, [shouldSaveSorts, sorts, project?.ref, table?.schema, table?.name])\n+\n   return (\n     <SidePanel\n       visible={visible}\n",
			"diffSize": 3209,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "2209d72990e646cab9481f0a006c591ccae6d3e8",
			"message": "Update UI to de-couple ETL replication context from Analytics Buckets (#40645)\n\n* Update UI to de-couple ETL replication context from Analytics Buckets\n\n* Nit\n\n* Nit\n\n* nit\n\n* Address all feedback\n\n* Address feedback\n\n* Add enabled feature check for analytics and vector buckets\n\n* FIXX\n\n* Update apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx\n\nCo-authored-by: Charis <26616127+charislam@users.noreply.github.com>\n\n---------\n\nCo-authored-by: Alaister Young <alaister@users.noreply.github.com>\nCo-authored-by: Charis <26616127+charislam@users.noreply.github.com>",
			"user": "joshenlim",
			"timestamp": "2025-11-21T08:28:31Z",
			"author": {
				"name": "Joshen Lim",
				"email": "joshenlimek@gmail.com",
				"username": "joshenlim"
			},
			"files": {
				"added": [
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/CreateTableInstructions.constants.ts",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/CreateTableInstructionsDialog.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/index.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/InitializeForeignSchemaDialog.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/UpdateForeignSchemaDialog.tsx",
					"apps/studio/data/storage/iceberg-namespace-delete-mutation.ts"
				],
				"modified": [
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/AnalyticsBucketDetails.constants.ts",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/BucketHeader.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/index.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/index.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/useAnalyticsBucketAssociatedEntities.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/CreateAnalyticsBucketModal.tsx",
					"apps/studio/components/interfaces/Storage/ImportForeignSchemaDialog.tsx",
					"apps/studio/data/config/project-storage-config-query.ts",
					"apps/studio/data/storage/iceberg-namespace-create-mutation.ts",
					"apps/studio/data/storage/iceberg-namespace-table-delete-mutation.ts",
					"apps/studio/data/storage/iceberg-namespaces-query.ts",
					"apps/studio/data/storage/keys.ts",
					"apps/studio/data/vault/vault-secret-decrypted-value-query.ts",
					"packages/common/enabled-features/enabled-features.json",
					"packages/common/enabled-features/enabled-features.schema.json",
					"packages/ui-patterns/src/ShimmeringLoader/index.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/AnalyticsBucketDetails.constants.ts b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/AnalyticsBucketDetails.constants.ts\nindex 21957b2208bb9..7efe6904c95b4 100644\n--- a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/AnalyticsBucketDetails.constants.ts\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/AnalyticsBucketDetails.constants.ts\n@@ -24,3 +24,9 @@ export const DESCRIPTIONS: Record<string, string> = {\n   's3.endpoint': '',\n   catalog_uri: '',\n }\n+\n+// [Joshen] For context we've decided to decouple ETL from Analytics Buckets for now\n+// So this flag just hides all \"connect table\" ETL flow related UI\n+// Depending on future decision if we intend to keep it that way, then we might be able\n+// to clean up + deprecate ConnectTablesDialog and other ETL related UI within Analytics Buckets\n+export const HIDE_REPLICATION_USER_FLOW = true\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/BucketHeader.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/BucketHeader.tsx\nindex 685f8ab9264eb..d2802ff321201 100644\n--- a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/BucketHeader.tsx\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/BucketHeader.tsx\n@@ -1,15 +1,14 @@\n import { noop } from 'lodash'\n \n-import { useParams } from 'common'\n import { FormattedWrapperTable } from 'components/interfaces/Integrations/Wrappers/Wrappers.utils'\n import {\n   ScaffoldHeader,\n   ScaffoldSectionDescription,\n   ScaffoldSectionTitle,\n } from 'components/layouts/Scaffold'\n-import { useReplicationPipelineStatusQuery } from 'data/etl/pipeline-status-query'\n+import { HIDE_REPLICATION_USER_FLOW } from './AnalyticsBucketDetails.constants'\n import { ConnectTablesDialog } from './ConnectTablesDialog'\n-import { useAnalyticsBucketAssociatedEntities } from './useAnalyticsBucketAssociatedEntities'\n+import { CreateTableInstructionsDialog } from './CreateTableInstructions/CreateTableInstructionsDialog'\n \n interface BucketHeaderProps {\n   showActions?: boolean\n@@ -26,13 +25,6 @@ export const BucketHeader = ({\n   namespaces = [],\n   onSuccessConnectTables = noop,\n }: BucketHeaderProps) => {\n-  const { ref: projectRef, bucketId } = useParams()\n-\n-  const { pipeline } = useAnalyticsBucketAssociatedEntities({ projectRef, bucketId })\n-  const { data } = useReplicationPipelineStatusQuery({ projectRef, pipelineId: pipeline?.id })\n-  const pipelineStatus = data?.status.name\n-  const isPipelineRunning = pipelineStatus === 'started'\n-\n   return (\n     <ScaffoldHeader className=\"pt-0 flex flex-row justify-between items-end gap-x-8\">\n       <div>\n@@ -44,7 +36,13 @@ export const BucketHeader = ({\n       {showActions && (\n         <div className=\"flex items-center gap-x-2\">\n           {namespaces.length > 0 && (\n-            <ConnectTablesDialog onSuccessConnectTables={onSuccessConnectTables} />\n+            <>\n+              {HIDE_REPLICATION_USER_FLOW ? (\n+                <CreateTableInstructionsDialog />\n+              ) : (\n+                <ConnectTablesDialog onSuccessConnectTables={onSuccessConnectTables} />\n+              )}\n+            </>\n           )}\n         </div>\n       )}\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/CreateTableInstructions.constants.ts b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/CreateTableInstructions.constants.ts\nnew file mode 100644\nindex 0000000000000..f5371e970689f\n--- /dev/null\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/CreateTableInstructions.constants.ts\n@@ -0,0 +1,88 @@\n+export const getPyicebergSnippet = ({\n+  ref,\n+  warehouse,\n+  catalogUri,\n+  s3Endpoint,\n+  s3Region,\n+  s3AccessKey,\n+  s3SecretKey,\n+  token,\n+}: {\n+  ref?: string\n+  warehouse?: string\n+  catalogUri?: string\n+  s3Endpoint?: string\n+  s3Region?: string\n+  s3AccessKey?: string\n+  s3SecretKey?: string\n+  token?: string\n+}) =>\n+  `\n+from pyiceberg.catalog import load_catalog\n+import pyarrow as pa\n+import datetime\n+\n+# Supabase project ref\n+PROJECT_REF = \"${ref ?? '<your-supabase-project-ref>'}\"\n+\n+# Configuration for Iceberg REST Catalog\n+WAREHOUSE = \"${warehouse ?? 'your-analytics-bucket-name'}\"\n+TOKEN = \"${token ?? '•••••••••••••'}\"\n+\n+# Configuration for S3-Compatible Storage\n+S3_ACCESS_KEY = \"${s3AccessKey ?? '•••••••••••••'}\"\n+S3_SECRET_KEY = \"${s3SecretKey ?? '•••••••••••••'}\"\n+S3_REGION = \"${s3Region}\"\n+S3_ENDPOINT = f\"${s3Endpoint ?? 'https://{PROJECT_REF}.supabase.co/storage/v1/s3'}\"\n+CATALOG_URI = f\"${catalogUri ?? 'https://{PROJECT_REF}.supabase.co/storage/v1/iceberg'}\"\n+\n+# Load the Iceberg catalog\n+catalog = load_catalog(\n+    \"supabase\",\n+    type=\"rest\",\n+    warehouse=WAREHOUSE,\n+    uri=CATALOG_URI,\n+    token=TOKEN,\n+    **{\n+        \"py-io-impl\": \"pyiceberg.io.pyarrow.PyArrowFileIO\",\n+        \"s3.endpoint\": S3_ENDPOINT,\n+        \"s3.access-key-id\": S3_ACCESS_KEY,\n+        \"s3.secret-access-key\": S3_SECRET_KEY,\n+        \"s3.region\": S3_REGION,\n+        \"s3.force-virtual-addressing\": False,\n+    },\n+)\n+\n+# Create namespace if it doesn't exist\n+print(\"Creating catalog 'default'...\")\n+catalog.create_namespace_if_not_exists(\"default\")\n+\n+# Define schema for your Iceberg table\n+schema = pa.schema([\n+    pa.field(\"event_id\", pa.int64()),\n+    pa.field(\"event_name\", pa.string()),\n+    pa.field(\"event_timestamp\", pa.timestamp(\"ms\")),\n+])\n+\n+# Create table (if it doesn't exist already)\n+print(\"Creating table 'events'...\")\n+table = catalog.create_table_if_not_exists((\"default\", \"events\"), schema=schema)\n+\n+# Generate and insert sample data\n+print(\"Preparing sample data to be inserted...\")\n+current_time = datetime.datetime.now()\n+data = pa.table({\n+    \"event_id\": [1, 2, 3],\n+    \"event_name\": [\"login\", \"logout\", \"purchase\"],\n+    \"event_timestamp\": [current_time, current_time, current_time],\n+})\n+\n+# Append data to the Iceberg table\n+print(\"Inserting data into 'events'...\")\n+table.append(data)\n+\n+print(\"Completed!\")\n+# Scan table and print data as pandas DataFrame\n+df = table.scan().to_pandas()\n+print(df)\n+`.trim()\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/CreateTableInstructionsDialog.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/CreateTableInstructionsDialog.tsx\nnew file mode 100644\nindex 0000000000000..19c08f08015cd\n--- /dev/null\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/CreateTableInstructionsDialog.tsx\n@@ -0,0 +1,32 @@\n+import { Plus } from 'lucide-react'\n+import {\n+  Button,\n+  Dialog,\n+  DialogContent,\n+  DialogDescription,\n+  DialogHeader,\n+  DialogTitle,\n+  DialogTrigger,\n+} from 'ui'\n+import { CreateTableInstructions } from '.'\n+\n+export const CreateTableInstructionsDialog = () => {\n+  return (\n+    <Dialog>\n+      <DialogTrigger asChild>\n+        <Button type=\"primary\" icon={<Plus />}>\n+          Create table\n+        </Button>\n+      </DialogTrigger>\n+      <DialogContent size=\"xlarge\">\n+        <DialogHeader>\n+          <DialogTitle>Adding tables to your Analytics Bucket</DialogTitle>\n+          <DialogDescription>\n+            Tables can be created or added to your bucket via Pyiceberg\n+          </DialogDescription>\n+        </DialogHeader>\n+        <CreateTableInstructions hideHeader className=\"rounded-t-none border-x-0 border-b-0\" />\n+      </DialogContent>\n+    </Dialog>\n+  )\n+}\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/index.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/index.tsx\nnew file mode 100644\nindex 0000000000000..a4ad80992055f\n--- /dev/null\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CreateTableInstructions/index.tsx\n@@ -0,0 +1,266 @@\n+import { useMemo, useState } from 'react'\n+\n+import { useParams } from 'common'\n+import CommandRender from 'components/interfaces/Functions/CommandRender'\n+import { convertKVStringArrayToJson } from 'components/interfaces/Integrations/Wrappers/Wrappers.utils'\n+import { ButtonTooltip } from 'components/ui/ButtonTooltip'\n+import CopyButton from 'components/ui/CopyButton'\n+import { InlineLink } from 'components/ui/InlineLink'\n+import { useProjectSettingsV2Query } from 'data/config/project-settings-v2-query'\n+import {\n+  getDecryptedValues,\n+  useVaultSecretDecryptedValueQuery,\n+} from 'data/vault/vault-secret-decrypted-value-query'\n+import { useSelectedProjectQuery } from 'hooks/misc/useSelectedProject'\n+import { DOCS_URL } from 'lib/constants'\n+import { Eye, EyeOff } from 'lucide-react'\n+import {\n+  Accordion_Shadcn_,\n+  AccordionContent_Shadcn_,\n+  AccordionItem_Shadcn_,\n+  AccordionTrigger_Shadcn_,\n+  Card,\n+  CardFooter,\n+  CardHeader,\n+  CardTitle,\n+  CodeBlock,\n+} from 'ui'\n+import { useAnalyticsBucketWrapperInstance } from '../useAnalyticsBucketWrapperInstance'\n+import { getPyicebergSnippet } from './CreateTableInstructions.constants'\n+\n+export const CreateTableInstructions = ({\n+  hideHeader = false,\n+  className,\n+}: {\n+  hideHeader?: boolean\n+  className?: string\n+}) => {\n+  const { ref, bucketId } = useParams()\n+  const { data: project } = useSelectedProjectQuery()\n+  const [showKeys, setShowKeys] = useState(false)\n+  const [isFetchingSecretsOnCopy, setIsFetchingSecretsOnCopy] = useState(false)\n+\n+  const { data: projectSettings } = useProjectSettingsV2Query({ projectRef: ref })\n+  const { data: wrapperInstance } = useAnalyticsBucketWrapperInstance({ bucketId })\n+  const wrapperValues = convertKVStringArrayToJson(wrapperInstance?.server_options ?? [])\n+\n+  const s3AccessKeyVaultID = wrapperValues.vault_aws_access_key_id\n+  const s3SecretKeyVaultID = wrapperValues.vault_aws_secret_access_key\n+  const tokenVaultID = wrapperValues.vault_token\n+\n+  const { data: decryptedS3AccessKey, isLoading: isDecryptingS3AccessKey } =\n+    useVaultSecretDecryptedValueQuery(\n+      {\n+        projectRef: project?.ref,\n+        connectionString: project?.connectionString,\n+        id: s3AccessKeyVaultID,\n+      },\n+      { enabled: showKeys }\n+    )\n+\n+  const { data: decryptedS3SecretKey, isLoading: isDecryptingS3SecretKey } =\n+    useVaultSecretDecryptedValueQuery(\n+      {\n+        projectRef: project?.ref,\n+        connectionString: project?.connectionString,\n+        id: s3SecretKeyVaultID,\n+      },\n+      { enabled: showKeys }\n+    )\n+\n+  const { data: decryptedToken, isLoading: isDecryptingToken } = useVaultSecretDecryptedValueQuery(\n+    {\n+      projectRef: project?.ref,\n+      connectionString: project?.connectionString,\n+      id: tokenVaultID,\n+    },\n+    { enabled: showKeys }\n+  )\n+\n+  const isFetchingSecretValues =\n+    showKeys && (isDecryptingS3AccessKey || isDecryptingS3SecretKey || isDecryptingToken)\n+\n+  const snippetContent = useMemo(\n+    () =>\n+      getPyicebergSnippet({\n+        ref,\n+        warehouse: wrapperValues.warehouse,\n+        catalogUri: wrapperValues.catalog_uri,\n+        s3Endpoint: wrapperValues['s3.endpoint'],\n+        s3Region: projectSettings?.region,\n+        s3AccessKey: showKeys ? decryptedS3AccessKey : undefined,\n+        s3SecretKey: showKeys ? decryptedS3SecretKey : undefined,\n+        token: showKeys ? decryptedToken : undefined,\n+      }),\n+    [\n+      decryptedS3AccessKey,\n+      decryptedS3SecretKey,\n+      decryptedToken,\n+      projectSettings?.region,\n+      ref,\n+      showKeys,\n+      wrapperValues,\n+    ]\n+  )\n+\n+  return (\n+    <Card className={className}>\n+      {!hideHeader && (\n+        <CardHeader>\n+          <CardTitle>Create your first table via Pyiceberg</CardTitle>\n+        </CardHeader>\n+      )}\n+\n+      <Accordion_Shadcn_ defaultValue={['step-1']} type=\"multiple\">\n+        <AccordionItem_Shadcn_ value=\"step-1\">\n+          <AccordionTrigger_Shadcn_ className=\"px-6 py-3 text-sm\">\n+            <div className=\"flex items-center gap-x-4\">\n+              <div className=\"w-6 h-6 rounded-full border flex items-center justify-center text-xs font-mono\">\n+                1\n+              </div>\n+              <p className=\"prose text-sm font-normal\">\n+                Set up Python project with <code>uv</code>\n+              </p>\n+            </div>\n+          </AccordionTrigger_Shadcn_>\n+          <AccordionContent_Shadcn_ className=\"border-0 px-6 pt-1\">\n+            <CommandRender\n+              commands={[\n+                {\n+                  comment: '1. Install uv as a preferred package manager',\n+                  command: 'curl -LsSf https://astral.sh/uv/install.sh | sh',\n+                  jsx: () => 'curl -LsSf https://astral.sh/uv/install.sh | sh',\n+                },\n+                {\n+                  comment: '2. Initialize a new Python project with uv',\n+                  command: 'uv init <project-name>',\n+                  jsx: () => 'uv init <project-name>',\n+                },\n+                {\n+                  comment: '3. Install required packages',\n+                  command: 'uv add pyiceberg pyarrow pandas',\n+                  jsx: () => 'uv add pyiceberg pyarrow pandas',\n+                },\n+              ]}\n+            />\n+          </AccordionContent_Shadcn_>\n+        </AccordionItem_Shadcn_>\n+\n+        <AccordionItem_Shadcn_ value=\"step-2\">\n+          <AccordionTrigger_Shadcn_ className=\"px-6 py-3 text-sm\">\n+            <div className=\"flex items-center gap-x-4\">\n+              <div className=\"w-6 h-6 rounded-full border flex items-center justify-center text-xs font-mono\">\n+                2\n+              </div>\n+              <p className=\"prose text-sm font-normal\">\n+                Replace <code>main.py</code> with the following snippet\n+              </p>\n+            </div>\n+          </AccordionTrigger_Shadcn_>\n+          <AccordionContent_Shadcn_ className=\"border-0 px-6 pt-2\">\n+            <p className=\"text-foreground mb-3 prose max-w-full text-sm\">\n+              The following snippet creates a namespace <code>default</code>, then creates a sample\n+              table\n+              <code>events</code> into that namespace.\n+            </p>\n+            <div className=\"relative group\">\n+              <CodeBlock\n+                hideCopy\n+                language=\"python\"\n+                className=\"max-h-[330px]\"\n+                value={snippetContent}\n+              />\n+              <div className=\"flex items-center gap-x-1.5 absolute top-2 right-2\">\n+                <CopyButton\n+                  type=\"default\"\n+                  loading={isFetchingSecretsOnCopy}\n+                  asyncText={async () => {\n+                    if (!!decryptedS3AccessKey && !!decryptedS3SecretKey && !!decryptedToken) {\n+                      return getPyicebergSnippet({\n+                        ref,\n+                        warehouse: wrapperValues.warehouse,\n+                        catalogUri: wrapperValues.catalog_uri,\n+                        s3Endpoint: wrapperValues['s3.endpoint'],\n+                        s3Region: projectSettings?.region,\n+                        s3AccessKey: decryptedS3AccessKey,\n+                        s3SecretKey: decryptedS3SecretKey,\n+                        token: decryptedToken,\n+                      })\n+                    } else {\n+                      setIsFetchingSecretsOnCopy(true)\n+                      const decryptedSecrets = await getDecryptedValues({\n+                        projectRef: project?.ref,\n+                        connectionString: project?.connectionString,\n+                        ids: [s3AccessKeyVaultID, s3SecretKeyVaultID, tokenVaultID],\n+                      })\n+                      setIsFetchingSecretsOnCopy(false)\n+                      return getPyicebergSnippet({\n+                        ref,\n+                        warehouse: wrapperValues.warehouse,\n+                        catalogUri: wrapperValues.catalog_uri,\n+                        s3Endpoint: wrapperValues['s3.endpoint'],\n+                        s3Region: projectSettings?.region,\n+                        s3AccessKey: decryptedSecrets[s3AccessKeyVaultID],\n+                        s3SecretKey: decryptedSecrets[s3SecretKeyVaultID],\n+                        token: decryptedSecrets[tokenVaultID],\n+                      })\n+                    }\n+                  }}\n+                />\n+                <ButtonTooltip\n+                  type=\"default\"\n+                  className=\"w-7\"\n+                  loading={isFetchingSecretValues}\n+                  onClick={() => setShowKeys(!showKeys)}\n+                  icon={showKeys ? <EyeOff /> : <Eye />}\n+                  tooltip={{\n+                    content: {\n+                      side: 'bottom',\n+                      text: showKeys\n+                        ? 'Hide keys'\n+                        : isFetchingSecretValues\n+                          ? 'Retrieving keys'\n+                          : 'Reveal keys',\n+                    },\n+                  }}\n+                />\n+              </div>\n+            </div>\n+          </AccordionContent_Shadcn_>\n+        </AccordionItem_Shadcn_>\n+\n+        <AccordionItem_Shadcn_ value=\"step-3\">\n+          <AccordionTrigger_Shadcn_ className=\"px-6 py-3 text-sm\">\n+            <div className=\"flex items-center gap-x-4\">\n+              <div className=\"w-6 h-6 rounded-full border flex items-center justify-center text-xs font-mono\">\n+                3\n+              </div>\n+              <p className=\"prose text-sm font-normal\">Run the Python script</p>\n+            </div>\n+          </AccordionTrigger_Shadcn_>\n+          <AccordionContent_Shadcn_ className=\"border-0 px-6 pt-2\">\n+            <CommandRender\n+              commands={[\n+                {\n+                  comment: 'Run the main.py script with uv',\n+                  command: 'uv run main.py',\n+                  jsx: () => 'uv run main.py',\n+                },\n+              ]}\n+            />\n+          </AccordionContent_Shadcn_>\n+        </AccordionItem_Shadcn_>\n+      </Accordion_Shadcn_>\n+\n+      <CardFooter className=\"bg\">\n+        <p className=\"text-xs text-foreground-light\">\n+          Connecting to bucket with other Iceberg clients? Read more in our{' '}\n+          <InlineLink href={`${DOCS_URL}/guides/storage/analytics/connecting-to-analytics-bucket`}>\n+            documentation\n+          </InlineLink>\n+          .\n+        </p>\n+      </CardFooter>\n+    </Card>\n+  )\n+}\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/InitializeForeignSchemaDialog.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/InitializeForeignSchemaDialog.tsx\nnew file mode 100644\nindex 0000000000000..03b4e00b22bed\n--- /dev/null\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/InitializeForeignSchemaDialog.tsx\n@@ -0,0 +1,129 @@\n+import { zodResolver } from '@hookform/resolvers/zod'\n+import { useState } from 'react'\n+import { SubmitHandler, useForm } from 'react-hook-form'\n+import { toast } from 'sonner'\n+import z from 'zod'\n+\n+import { useParams } from 'common'\n+import { useSchemaCreateMutation } from 'data/database/schema-create-mutation'\n+import { useSchemasQuery } from 'data/database/schemas-query'\n+import { useFDWImportForeignSchemaMutation } from 'data/fdw/fdw-import-foreign-schema-mutation'\n+import { useSelectedProjectQuery } from 'hooks/misc/useSelectedProject'\n+import {\n+  Button,\n+  Dialog,\n+  DialogContent,\n+  DialogFooter,\n+  DialogHeader,\n+  DialogSection,\n+  DialogSectionSeparator,\n+  DialogTitle,\n+  DialogTrigger,\n+  Form_Shadcn_,\n+  FormField_Shadcn_,\n+  Input_Shadcn_,\n+} from 'ui'\n+import { FormItemLayout } from 'ui-patterns/form/FormItemLayout/FormItemLayout'\n+import { getAnalyticsBucketFDWServerName } from './AnalyticsBucketDetails.utils'\n+\n+// Create foreign tables for namespace tables\n+export const InitializeForeignSchemaDialog = ({ namespace }: { namespace: string }) => {\n+  const { ref: projectRef, bucketId } = useParams()\n+  const { data: project } = useSelectedProjectQuery()\n+  const { data: schemas } = useSchemasQuery({ projectRef })\n+\n+  const [isOpen, setIsOpen] = useState(false)\n+  const [isCreating, setIsCreating] = useState(false)\n+\n+  const serverName = getAnalyticsBucketFDWServerName(bucketId ?? '')\n+\n+  const FormSchema = z.object({\n+    schema: z\n+      .string()\n+      .trim()\n+      .min(1, 'Schema name is required')\n+      .refine((val) => !schemas?.find((s) => s.name === val), {\n+        message: 'This schema already exists. Please specify a unique schema name.',\n+      }),\n+  })\n+  const form = useForm<z.infer<typeof FormSchema>>({\n+    resolver: zodResolver(FormSchema),\n+    defaultValues: { schema: '' },\n+  })\n+\n+  const { mutateAsync: createSchema } = useSchemaCreateMutation()\n+  const { mutateAsync: importForeignSchema } = useFDWImportForeignSchemaMutation()\n+\n+  const onSubmit: SubmitHandler<z.infer<typeof FormSchema>> = async (values) => {\n+    if (!projectRef) return console.error('Project ref is required')\n+\n+    try {\n+      setIsCreating(true)\n+\n+      await createSchema({\n+        projectRef,\n+        connectionString: project?.connectionString,\n+        name: values.schema,\n+      })\n+\n+      await importForeignSchema({\n+        projectRef,\n+        connectionString: project?.connectionString,\n+        serverName: serverName,\n+        sourceSchema: namespace,\n+        targetSchema: values.schema,\n+      })\n+\n+      toast.success(\n+        `Successfully created \"${values.schema}\" schema! Data from tables in the \"${namespace}\" namespace can now be queried from there.`\n+      )\n+      setIsOpen(false)\n+    } catch (error: any) {\n+      toast.error(`Failed to expose tables: ${error.message}`)\n+    } finally {\n+      setIsCreating(false)\n+    }\n+  }\n+\n+  return (\n+    <Dialog open={isOpen} onOpenChange={setIsOpen}>\n+      <DialogTrigger asChild>\n+        <Button type=\"default\">Query from Postgres</Button>\n+      </DialogTrigger>\n+      <DialogContent size=\"medium\" aria-describedby={undefined}>\n+        <Form_Shadcn_ {...form}>\n+          <form onSubmit={form.handleSubmit(onSubmit)}>\n+            <DialogHeader>\n+              <DialogTitle>Query this namespace from Postgres</DialogTitle>\n+            </DialogHeader>\n+            <DialogSectionSeparator />\n+            <DialogSection className=\"flex flex-col gap-y-4\">\n+              <p className=\"text-sm\">\n+                Iceberg data can be queried from Postgres with the Iceberg Foreign Data Wrapper.\n+                Create a Postgres schema to expose tables from the \"{namespace}\" namespace as\n+                foreign tables.\n+              </p>\n+              <FormField_Shadcn_\n+                control={form.control}\n+                name=\"schema\"\n+                render={({ field }) => (\n+                  <FormItemLayout layout=\"vertical\" label=\"Schema name\">\n+                    <Input_Shadcn_ {...field} placeholder=\"Provide a name for your schema\" />\n+                  </FormItemLayout>\n+                )}\n+              />\n+            </DialogSection>\n+            <DialogFooter>\n+              <Button type=\"default\" disabled={isCreating} onClick={() => setIsOpen(false)}>\n+                Cancel\n+              </Button>\n+              <Button htmlType=\"submit\" type=\"primary\" loading={isCreating}>\n+                Create schema\n+              </Button>\n+            </DialogFooter>\n+          </form>\n+        </Form_Shadcn_>\n+      </DialogContent>\n+    </Dialog>\n+  )\n+}\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx\nindex 905641ba86d8b..ffd58a652cf32 100644\n--- a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx\n@@ -1,5 +1,5 @@\n import { uniq } from 'lodash'\n-import { Eye, Loader2, MoreVertical, Pause, Play, Trash } from 'lucide-react'\n+import { Eye, Loader2, MoreVertical, Pause, Play, Table2, Trash } from 'lucide-react'\n import Link from 'next/link'\n import { useMemo, useState } from 'react'\n import { toast } from 'sonner'\n@@ -16,12 +16,14 @@ import { useReplicationPipelineStatusQuery } from 'data/etl/pipeline-status-quer\n import { useUpdatePublicationMutation } from 'data/etl/publication-update-mutation'\n import { useStartPipelineMutation } from 'data/etl/start-pipeline-mutation'\n import { useReplicationTablesQuery } from 'data/etl/tables-query'\n+import { useFDWDropForeignTableMutation } from 'data/fdw/fdw-drop-foreign-table-mutation'\n import { useFDWUpdateMutation } from 'data/fdw/fdw-update-mutation'\n import { useIcebergNamespaceTableDeleteMutation } from 'data/storage/iceberg-namespace-table-delete-mutation'\n import { useSelectedProjectQuery } from 'hooks/misc/useSelectedProject'\n-import { SqlEditor } from 'icons'\n+import { SqlEditor, TableEditor } from 'icons'\n import {\n   Button,\n+  cn,\n   DropdownMenu,\n   DropdownMenuContent,\n   DropdownMenuItem,\n@@ -34,6 +36,7 @@ import {\n   TooltipTrigger,\n } from 'ui'\n import { ConfirmationModal } from 'ui-patterns/Dialogs/ConfirmationModal'\n+import { HIDE_REPLICATION_USER_FLOW } from '../AnalyticsBucketDetails.constants'\n import {\n   getAnalyticsBucketFDWServerName,\n   getNamespaceTableNameFromPostgresTableName,\n@@ -46,15 +49,9 @@ interface TableRowComponentProps {\n   table: { id: number; name: string; isConnected: boolean }\n   schema: string\n   namespace: string\n-  isLoading?: boolean\n }\n \n-export const TableRowComponent = ({\n-  table,\n-  schema,\n-  namespace,\n-  isLoading,\n-}: TableRowComponentProps) => {\n+export const TableRowComponent = ({ table, schema, namespace }: TableRowComponentProps) => {\n   const { ref: projectRef, bucketId } = useParams()\n   const { data: project } = useSelectedProjectQuery()\n \n@@ -64,7 +61,7 @@ export const TableRowComponent = ({\n   const [isUpdatingReplication, setIsUpdatingReplication] = useState(false)\n   const [isRemovingTable, setIsRemovingTable] = useState(false)\n \n-  const { sourceId, publication, pipeline } = useAnalyticsBucketAssociatedEntities({\n+  const { sourceId, publication, pipeline, icebergWrapper } = useAnalyticsBucketAssociatedEntities({\n     projectRef,\n     bucketId,\n   })\n@@ -80,9 +77,9 @@ export const TableRowComponent = ({\n   })\n \n   const { mutateAsync: updateFDW } = useFDWUpdateMutation()\n-  const { mutateAsync: deleteNamespaceTable } = useIcebergNamespaceTableDeleteMutation({\n-    projectRef,\n-  })\n+  const { mutateAsync: dropForeignTable } = useFDWDropForeignTableMutation()\n+  const { mutateAsync: deleteNamespaceTable, isLoading: isDeletingNamespaceTable } =\n+    useIcebergNamespaceTableDeleteMutation({ projectRef, onError: () => {} })\n   const { mutateAsync: updatePublication } = useUpdatePublicationMutation()\n   const { mutateAsync: startPipeline } = useStartPipelineMutation()\n \n@@ -179,6 +176,7 @@ export const TableRowComponent = ({\n     }\n   }\n \n+  // [Joshen] For ETL replication context\n   const onConfirmRemoveTable = async () => {\n     if (!bucketId) return console.error('Bucket ID is required')\n     if (!wrapperInstance || !wrapperMeta) return toast.error('Unable to find wrapper')\n@@ -243,11 +241,57 @@ export const TableRowComponent = ({\n     }\n   }\n \n+  const connectedForeignTablesInNamespace = (icebergWrapper?.tables ?? []).filter((x) =>\n+    x.options[0].includes(`table=${namespace}.`)\n+  )\n+\n+  const connectedForeignTables = (icebergWrapper?.tables ?? []).filter(\n+    (x) => x.options[0] === `table=${namespace}.${table.name}`\n+  )\n+\n+  // [Joshen] For purely Analytics Bucket context\n+  const onConfirmRemoveNamespaceTable = async () => {\n+    try {\n+      setIsRemovingTable(true)\n+      const wrapperValues = convertKVStringArrayToJson(wrapperInstance?.server_options ?? [])\n+      await deleteNamespaceTable({\n+        catalogUri: wrapperValues.catalog_uri,\n+        warehouse: wrapperValues.warehouse,\n+        namespace: namespace,\n+        table: table.name,\n+      })\n+\n+      await Promise.all(\n+        connectedForeignTables.map((x) =>\n+          dropForeignTable({\n+            projectRef,\n+            connectionString: project?.connectionString,\n+            schemaName: x.schema,\n+            tableName: x.name,\n+          })\n+        )\n+      )\n+\n+      toast.success(`Successfully removed table \"${table.name}\"!`)\n+    } catch (error: any) {\n+      toast.error(`Failed to remove table: ${error.message}`)\n+    } finally {\n+      setIsRemovingTable(false)\n+    }\n+  }\n+\n   return (\n     <>\n       <TableRow>\n-        <TableCell className=\"min-w-[120px]\">{table.name}</TableCell>\n-        {!!hasReplication && (\n+        <TableCell className=\"min-w-[120px]\">\n+          <div className=\"flex items-center gap-x-3\">\n+            <div className=\"w-5 flex justify-center items-center\">\n+              <Table2 size={16} />\n+            </div>\n+            <p>{table.name}</p>\n+          </div>\n+        </TableCell>\n+        {!HIDE_REPLICATION_USER_FLOW && !!hasReplication && (\n           <TableCell colSpan={table.isConnected ? 1 : 2} className=\"min-w-[150px]\">\n             <div className=\"flex items-center\">\n               <Tooltip>\n@@ -280,29 +324,17 @@ export const TableRowComponent = ({\n           </TableCell>\n         )}\n \n-        {table.isConnected && (\n+        {!HIDE_REPLICATION_USER_FLOW && table.isConnected ? (\n+          // [Joshen] These are if there's the context of replication which we're currently not doing\n+          // May need to clean up if we decided to move forward de-coupling replication and Analytics Buckets\n           <TableCell className=\"text-right flex flex-row items-center gap-x-2 justify-end\">\n             <>\n-              <Button asChild type=\"default\" size=\"tiny\">\n-                <Link href={`/project/${project?.ref}/editor/${table.id}?schema=${schema}`}>\n-                  <p>View table</p>\n-                </Link>\n-              </Button>\n               <DropdownMenu>\n                 <DropdownMenuTrigger asChild>\n-                  <Button type=\"default\" className=\"px-1\" icon={<MoreVertical />} />\n+                  <Button type=\"default\" className=\"w-7\" icon={<MoreVertical />} />\n                 </DropdownMenuTrigger>\n \n                 <DropdownMenuContent side=\"bottom\" align=\"end\" className=\"w-fit min-w-[180px]\">\n-                  <DropdownMenuItem asChild className=\"flex items-center gap-x-2\">\n-                    <Link\n-                      href={`/project/${projectRef}/sql/new?content=${encodeURIComponent(`select * from ${schema}.${table.name};`)}`}\n-                    >\n-                      <SqlEditor size={12} className=\"text-foreground-lighter\" />\n-                      <p>Query in SQL Editor</p>\n-                    </Link>\n-                  </DropdownMenuItem>\n-\n                   {!!publication && (\n                     <>\n                       {!!inferredPostgresTable && (\n@@ -332,11 +364,10 @@ export const TableRowComponent = ({\n                           <p>Enable replication</p>\n                         </DropdownMenuItem>\n                       )}\n+                      <DropdownMenuSeparator />\n                     </>\n                   )}\n \n-                  <DropdownMenuSeparator />\n-\n                   <DropdownMenuItemTooltip\n                     disabled={isReplicating}\n                     className=\"flex items-center gap-x-2\"\n@@ -349,14 +380,111 @@ export const TableRowComponent = ({\n                     }}\n                   >\n                     <Trash size={12} className=\"text-foreground-lighter\" />\n-                    <p>Remove table</p>\n+                    <p>Delete table</p>\n                   </DropdownMenuItemTooltip>\n                 </DropdownMenuContent>\n               </DropdownMenu>\n             </>\n           </TableCell>\n+        ) : (\n+          // [Joshen] These are for purely Analytics Bucket context\n+          <TableCell className=\"text-right flex flex-row items-center gap-x-2 justify-end\">\n+            <DropdownMenu>\n+              <DropdownMenuTrigger asChild>\n+                <Button\n+                  loading={isDeletingNamespaceTable}\n+                  type=\"default\"\n+                  className=\"w-7\"\n+                  icon={<MoreVertical />}\n+                />\n+              </DropdownMenuTrigger>\n+              <DropdownMenuContent align=\"end\" className=\"w-fit min-w-[180px]\">\n+                <DropdownMenuItem\n+                  className=\"flex items-center gap-x-2\"\n+                  onClick={() => setShowRemoveTableModal(true)}\n+                >\n+                  <Trash size={12} className=\"text-foreground-lighter\" />\n+                  <p>Delete table</p>\n+                </DropdownMenuItem>\n+              </DropdownMenuContent>\n+            </DropdownMenu>\n+          </TableCell>\n         )}\n       </TableRow>\n+\n+      {/* [Joshen] Render each foreign table associated to the namespace table as its own row */}\n+      {connectedForeignTables?.map((x) => (\n+        <TableRow key={x.id}>\n+          <TableCell className=\"pl-6\">\n+            <div className=\"flex items-center gap-x-2 rounded\">\n+              <div className=\"w-4 h-4 rounded-bl-lg border-l-2 border-b-2 border-control -translate-y-1.5\" />\n+              <div\n+                className={cn(\n+                  'flex items-center justify-center text-xs h-4 w-4 rounded-[2px] font-bold',\n+                  'text-warning-600/80 dark:text-yellow-900 bg-yellow-500'\n+                )}\n+              >\n+                F\n+              </div>\n+              <p>\n+                {x.schema}.{x.name}\n+              </p>\n+            </div>\n+          </TableCell>\n+          <TableCell className=\"flex flex-row justify-end\">\n+            <DropdownMenu>\n+              <DropdownMenuTrigger asChild>\n+                <Button type=\"default\" className=\"w-7\" icon={<MoreVertical />} />\n+              </DropdownMenuTrigger>\n+              <DropdownMenuContent className=\"w-fit min-w-[180px]\" align=\"end\">\n+                <DropdownMenuItem asChild className=\"flex items-center gap-x-2\">\n+                  <Link\n+                    href={`/project/${projectRef}/sql/new?content=${encodeURIComponent(`select * from ${schema}.${table.name};`)}`}\n+                  >\n+                    <SqlEditor size={12} className=\"text-foreground-lighter\" />\n+                    <p>Query in SQL Editor</p>\n+                  </Link>\n+                </DropdownMenuItem>\n+                <DropdownMenuItem asChild className=\"flex items-center gap-x-2\">\n+                  <Link href={`/project/${projectRef}/editor/${x.id}?schema=${x.schema}`}>\n+                    <TableEditor size={12} className=\"text-foreground-lighter\" />\n+                    <p>View in Table Editor</p>\n+                  </Link>\n+                </DropdownMenuItem>\n+              </DropdownMenuContent>\n+            </DropdownMenu>\n+          </TableCell>\n+        </TableRow>\n+      ))}\n+\n+      {/* [Joshen] If the iceberg table doesn't have a corresponding namespace table, but the namespace itself already has some tables connected */}\n+      {connectedForeignTablesInNamespace.length > 0 && connectedForeignTables.length === 0 && (\n+        <TableRow>\n+          <TableCell className=\"pl-6\">\n+            <Tooltip>\n+              <TooltipTrigger>\n+                <div className=\"flex items-center gap-x-2 rounded\">\n+                  <div className=\"w-4 h-4 rounded-bl-lg border-l-2 border-b-2 border-control -translate-y-1.5\" />\n+                  <div\n+                    className={cn(\n+                      'flex items-center justify-center text-xs h-4 w-4 rounded-[2px]',\n+                      'font-bold border border-dashed border-control text-foreground-lighter'\n+                    )}\n+                  >\n+                    ?\n+                  </div>\n+                  <p className=\"text-foreground-lighter\">No matching foreign table in schema</p>\n+                </div>\n+              </TooltipTrigger>\n+              <TooltipContent side=\"right\">\n+                Update the schema tables if you'd like to query this table from Postgres\n+              </TooltipContent>\n+            </Tooltip>\n+          </TableCell>\n+          <TableCell className=\"flex flex-row justify-end\"></TableCell>\n+        </TableRow>\n+      )}\n+\n       <ConfirmationModal\n         size=\"medium\"\n         variant=\"warning\"\n@@ -390,17 +518,25 @@ export const TableRowComponent = ({\n       </ConfirmationModal>\n \n       <ConfirmationModal\n-        size=\"small\"\n+        size=\"medium\"\n         variant=\"warning\"\n         visible={showRemoveTableModal}\n         loading={isRemovingTable}\n-        title=\"Confirm to remove table\"\n-        description=\"Data from the analytics table will be lost\"\n-        confirmLabel=\"Remove table\"\n+        title={`Confirm to delete table \"${table.name}\"`}\n+        description=\"This action cannot be undone.\"\n+        confirmLabel=\"Delete table\"\n         onCancel={() => setShowRemoveTableModal(false)}\n-        onConfirm={() => onConfirmRemoveTable()}\n+        onConfirm={() => {\n+          if (HIDE_REPLICATION_USER_FLOW) {\n+            onConfirmRemoveNamespaceTable()\n+          } else {\n+            onConfirmRemoveTable()\n+          }\n+        }}\n       >\n-        <p className=\"text-sm text-foreground-light\">Are you sure? This action cannot be undone.</p>\n+        <p className=\"text-sm text-foreground-light\">\n+          Data from this Iceberg table will be permanently lost. Are you sure?\n+        </p>\n       </ConfirmationModal>\n     </>\n   )\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/index.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/index.tsx\nindex b64829a622798..9672e9b7bf15a 100644\n--- a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/index.tsx\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/index.tsx\n@@ -1,19 +1,28 @@\n-import { ChevronRight, Info, Loader2, Plus, RefreshCw } from 'lucide-react'\n+import { ChevronRight, Info, Loader2, MoreVertical, Plus, RefreshCw, Trash } from 'lucide-react'\n import { useEffect, useMemo, useState } from 'react'\n+import { toast } from 'sonner'\n \n import { useParams } from 'common'\n-import type { WrapperMeta } from 'components/interfaces/Integrations/Wrappers/Wrappers.types'\n import { FormattedWrapperTable } from 'components/interfaces/Integrations/Wrappers/Wrappers.utils'\n import { ImportForeignSchemaDialog } from 'components/interfaces/Storage/ImportForeignSchemaDialog'\n+import { getCatalogURI } from 'components/interfaces/Storage/StorageSettings/StorageSettings.utils'\n+import { useProjectSettingsV2Query } from 'data/config/project-settings-v2-query'\n+import { useFDWDropForeignTableMutation } from 'data/fdw/fdw-drop-foreign-table-mutation'\n import { useFDWImportForeignSchemaMutation } from 'data/fdw/fdw-import-foreign-schema-mutation'\n-import { FDW } from 'data/fdw/fdws-query'\n+import { useIcebergNamespaceDeleteMutation } from 'data/storage/iceberg-namespace-delete-mutation'\n+import { useIcebergNamespaceTableDeleteMutation } from 'data/storage/iceberg-namespace-table-delete-mutation'\n import { useIcebergNamespaceTablesQuery } from 'data/storage/iceberg-namespace-tables-query'\n import { useSelectedProjectQuery } from 'hooks/misc/useSelectedProject'\n+import { BASE_PATH } from 'lib/constants'\n import {\n   Button,\n   Card,\n   CardHeader,\n   CardTitle,\n+  DropdownMenu,\n+  DropdownMenuContent,\n+  DropdownMenuItem,\n+  DropdownMenuTrigger,\n   LoadingLine,\n   Table,\n   TableBody,\n@@ -25,40 +34,44 @@ import {\n   TooltipContent,\n   TooltipTrigger,\n } from 'ui'\n+import ConfirmationModal from 'ui-patterns/Dialogs/ConfirmationModal'\n+import { HIDE_REPLICATION_USER_FLOW } from '../AnalyticsBucketDetails.constants'\n import { getNamespaceTableNameFromPostgresTableName } from '../AnalyticsBucketDetails.utils'\n+import { InitializeForeignSchemaDialog } from '../InitializeForeignSchemaDialog'\n+import { UpdateForeignSchemaDialog } from '../UpdateForeignSchemaDialog'\n import { useAnalyticsBucketAssociatedEntities } from '../useAnalyticsBucketAssociatedEntities'\n import { TableRowComponent } from './TableRowComponent'\n \n type NamespaceWithTablesProps = {\n-  bucketName?: string\n   namespace: string\n   sourceType: 'replication' | 'direct'\n   schema: string\n   tables: (FormattedWrapperTable & { id: number })[]\n-  wrapperInstance: FDW\n   wrapperValues: Record<string, string>\n-  wrapperMeta: WrapperMeta\n   pollIntervalNamespaceTables: number\n   setPollIntervalNamespaceTables: (value: number) => void\n }\n \n export const NamespaceWithTables = ({\n-  bucketName,\n   namespace,\n   sourceType = 'direct',\n   schema,\n   tables,\n-  wrapperInstance,\n   wrapperValues,\n-  wrapperMeta,\n   pollIntervalNamespaceTables,\n   setPollIntervalNamespaceTables,\n }: NamespaceWithTablesProps) => {\n   const { ref: projectRef, bucketId } = useParams()\n   const { data: project } = useSelectedProjectQuery()\n   const [importForeignSchemaShown, setImportForeignSchemaShown] = useState(false)\n+  const [showConfirmDeleteNamespace, setShowConfirmDeleteNamespace] = useState(false)\n+  const [isDeletingNamespace, setIsDeletingNamespace] = useState(false)\n \n-  const { publication } = useAnalyticsBucketAssociatedEntities({ projectRef, bucketId })\n+  const { data: projectSettings } = useProjectSettingsV2Query({ projectRef })\n+  const { publication, icebergWrapper } = useAnalyticsBucketAssociatedEntities({\n+    projectRef,\n+    bucketId,\n+  })\n \n   const {\n     data: tablesData = [],\n@@ -90,6 +103,17 @@ export const NamespaceWithTables = ({\n     }\n   )\n \n+  const connectedForeignTablesForNamespace = (icebergWrapper?.tables ?? []).filter((x) =>\n+    x.options[0].startsWith(`table=${namespace}.`)\n+  )\n+  const tablesWithConnectedForeignTables = connectedForeignTablesForNamespace.reduce((a, b) => {\n+    const table = b.options[0].split(`table=${namespace}.`)[1]\n+    a.add(table)\n+    return a\n+  }, new Set<string>())\n+  const unconnectedTables = tablesData.filter((x) => !tablesWithConnectedForeignTables.has(x))\n+  const hasUnconnectedForeignTablesForNamespace = unconnectedTables.length > 0\n+\n   const publicationTables = publication?.tables ?? []\n   const publicationTablesNotSyncedToNamespaceTables = publicationTables.filter(\n     (x) => !tablesData.includes(getNamespaceTableNameFromPostgresTableName(x))\n@@ -99,12 +123,19 @@ export const NamespaceWithTables = ({\n \n   const { mutateAsync: importForeignSchema, isPending: isImportingForeignSchema } =\n     useFDWImportForeignSchemaMutation()\n+  const { mutateAsync: deleteNamespace } = useIcebergNamespaceDeleteMutation({ projectRef })\n+  const { mutateAsync: dropForeignTable } = useFDWDropForeignTableMutation()\n+  const { mutateAsync: deleteNamespaceTable } = useIcebergNamespaceTableDeleteMutation({\n+    projectRef,\n+  })\n \n   const rescanNamespace = async () => {\n+    if (!icebergWrapper) return console.error('Iceberg wrapper cannot be found')\n+\n     await importForeignSchema({\n       projectRef: project?.ref,\n       connectionString: project?.connectionString,\n-      serverName: wrapperInstance.server_name,\n+      serverName: icebergWrapper.server_name,\n       sourceSchema: namespace,\n       targetSchema: schema,\n     })\n@@ -142,15 +173,58 @@ export const NamespaceWithTables = ({\n     return !hasClashes\n   }, [schema, tables.length])\n \n-  // Determine what schema name to display\n   const displaySchema = useMemo(() => {\n-    // If we have a target schema, use it\n+    // If we have a target schema, use it, otherwise show the incoming schema (namespace name)\n     if (schema) return schema\n-\n-    // Otherwise, show the incoming schema (namespace name)\n     return `fdw_analytics_${namespace.replaceAll('-', '_')}`\n   }, [schema, namespace])\n \n+  const onConfirmDeleteNamespace = async () => {\n+    if (!bucketId) return console.error('Bucket ID is required')\n+    // Construct catalog URI for namespace creation\n+    const protocol = projectSettings?.app_config?.protocol ?? 'https'\n+    const endpoint =\n+      projectSettings?.app_config?.storage_endpoint || projectSettings?.app_config?.endpoint\n+    const catalogUri = getCatalogURI(project?.ref ?? '', protocol, endpoint)\n+\n+    try {\n+      setIsDeletingNamespace(true)\n+\n+      // [Joshen] Delete all namespace tables\n+      await Promise.all(\n+        allTables.map((table) =>\n+          deleteNamespaceTable({\n+            catalogUri,\n+            warehouse: bucketId,\n+            namespace,\n+            table: table.name,\n+          })\n+        )\n+      )\n+\n+      // Delete all foreign tables that corresponding to the namespace tables\n+      await Promise.all(\n+        tables.map((table) =>\n+          dropForeignTable({\n+            projectRef,\n+            connectionString: project?.connectionString,\n+            schemaName: table.schema_name,\n+            tableName: table.table_name,\n+          })\n+        )\n+      )\n+\n+      await deleteNamespace({ catalogUri, warehouse: bucketId, namespace })\n+\n+      toast.success(`Successfully deleted namespace \"${namespace}\"`)\n+      setShowConfirmDeleteNamespace(false)\n+    } catch (error: any) {\n+      toast.error(`Failed to delete namespace: ${error.message}`)\n+    } finally {\n+      setIsDeletingNamespace(false)\n+    }\n+  }\n+\n   useEffect(() => {\n     if (isSuccessNamespaceTables && !isSyncedPublicationTablesAndNamespaceTables) {\n       setPollIntervalNamespaceTables(4000)\n@@ -160,40 +234,46 @@ export const NamespaceWithTables = ({\n \n   return (\n     <Card>\n-      <CardHeader className=\"flex flex-row justify-between items-center px-4 py-5 space-y-0\">\n+      <CardHeader className=\"flex flex-row justify-between items-center px-4 py-4 space-y-0\">\n         <CardTitle className=\"text-sm font-normal font-sans normal-case leading-none flex flex-row items-center gap-x-1\">\n-          <Tooltip>\n-            <TooltipTrigger asChild>\n-              <span className=\"flex flex-row items-center gap-x-1 text-foreground-lighter\">\n-                {sourceType === 'direct' ? namespace : 'public'}\n-                <ChevronRight size={12} className=\"text-foreground-muted\" />\n-              </span>\n-            </TooltipTrigger>\n-            <TooltipContent side=\"bottom\">\n-              <p>{sourceType === 'direct' ? 'Analytics' : 'Postgres'} schema</p>\n-            </TooltipContent>\n-          </Tooltip>\n-          {validSchema && (\n-            <Tooltip>\n-              <TooltipTrigger\n-                asChild\n-                className={tables.length === 0 ? `flex flex-row items-center gap-x-1` : undefined}\n-              >\n-                <span\n-                  className={\n-                    tables.length > 0\n-                      ? `text-foreground`\n-                      : `text-foreground-muted flex flex-row items-center gap-x-1`\n-                  }\n+          <div className=\"flex flex-row items-center gap-x-3 text-foreground\">\n+            <img\n+              src={`${BASE_PATH}/img/icons/iceberg-icon.svg`}\n+              alt=\"Apache Iceberg icon\"\n+              className=\"w-5 h-5\"\n+            />\n+            <div className=\"flex flex-col gap-y-0.5\">\n+              <p className=\"text-xs font-mono uppercase text-foreground-lighter\">\n+                Iceberg namespace\n+              </p>\n+              <p className=\"text-sm\">{namespace}</p>\n+            </div>\n+          </div>\n+\n+          {!HIDE_REPLICATION_USER_FLOW && validSchema && (\n+            <>\n+              <ChevronRight size={12} className=\"text-foreground-muted\" />\n+              <Tooltip>\n+                <TooltipTrigger\n+                  asChild\n+                  className={tables.length === 0 ? `flex flex-row items-center gap-x-1` : undefined}\n                 >\n-                  {displaySchema}\n-                  {tables.length === 0 && <Info size={12} />}\n-                </span>\n-              </TooltipTrigger>\n-              <TooltipContent side=\"bottom\">\n-                <p>Postgres schema{tables.length === 0 && ' that will be created'}</p>\n-              </TooltipContent>\n-            </Tooltip>\n+                  <span\n+                    className={\n+                      tables.length > 0\n+                        ? `text-foreground`\n+                        : `text-foreground-muted flex flex-row items-center gap-x-1`\n+                    }\n+                  >\n+                    {displaySchema}\n+                    {tables.length === 0 && <Info size={12} />}\n+                  </span>\n+                </TooltipTrigger>\n+                <TooltipContent side=\"bottom\">\n+                  <p>Postgres schema{tables.length === 0 && ' that will be created'}</p>\n+                </TooltipContent>\n+              </Tooltip>\n+            </>\n           )}\n         </CardTitle>\n \n@@ -220,17 +300,43 @@ export const NamespaceWithTables = ({\n               </TooltipContent>\n             </Tooltip>\n           )}\n-          {missingTables.length > 0 && (\n-            <Button\n-              type={schema ? 'default' : 'warning'}\n-              size=\"tiny\"\n-              icon={schema ? <RefreshCw /> : <Plus size={14} />}\n-              onClick={() => (schema ? rescanNamespace() : setImportForeignSchemaShown(true))}\n-              loading={isImportingForeignSchema || isLoadingNamespaceTables}\n-            >\n-              {schema ? 'Sync tables' : `Connect to table${missingTables.length > 1 ? 's' : ''}`}\n-            </Button>\n-          )}\n+\n+          <div className=\"flex items-center gap-x-2\">\n+            {HIDE_REPLICATION_USER_FLOW ? (\n+              <>\n+                {/* Is this just the import foreign schema dialog then? */}\n+                {connectedForeignTablesForNamespace.length === 0 ? (\n+                  <InitializeForeignSchemaDialog namespace={namespace} />\n+                ) : hasUnconnectedForeignTablesForNamespace ? (\n+                  <UpdateForeignSchemaDialog namespace={namespace} tables={unconnectedTables} />\n+                ) : null}\n+                <DropdownMenu>\n+                  <DropdownMenuTrigger asChild>\n+                    <Button type=\"default\" className=\"w-7\" icon={<MoreVertical />} />\n+                  </DropdownMenuTrigger>\n+                  <DropdownMenuContent align=\"end\" className=\"w-fit min-w-[180px]\">\n+                    <DropdownMenuItem\n+                      className=\"flex items-center gap-x-2\"\n+                      onClick={() => setShowConfirmDeleteNamespace(true)}\n+                    >\n+                      <Trash size={12} className=\"text-foreground-lighter\" />\n+                      <p>Delete namespace</p>\n+                    </DropdownMenuItem>\n+                  </DropdownMenuContent>\n+                </DropdownMenu>\n+              </>\n+            ) : missingTables.length > 0 ? (\n+              <Button\n+                type={schema ? 'default' : 'warning'}\n+                size=\"tiny\"\n+                icon={schema ? <RefreshCw /> : <Plus size={14} />}\n+                onClick={() => (schema ? rescanNamespace() : setImportForeignSchemaShown(true))}\n+                loading={isImportingForeignSchema || isLoadingNamespaceTables}\n+              >\n+                {schema ? 'Sync tables' : `Connect to table${missingTables.length > 1 ? 's' : ''}`}\n+              </Button>\n+            ) : null}\n+          </div>\n         </div>\n       </CardHeader>\n \n@@ -240,7 +346,7 @@ export const NamespaceWithTables = ({\n         <TableHeader>\n           <TableRow>\n             <TableHead className={allTables.length === 0 ? 'text-foreground-muted' : undefined}>\n-              Name\n+              <span className=\"pl-8\">Table name</span>\n             </TableHead>\n             {!!publication && (\n               <TableHead className={allTables.length === 0 ? 'hidden' : undefined}>\n@@ -269,20 +375,34 @@ export const NamespaceWithTables = ({\n                 table={table}\n                 namespace={namespace}\n                 schema={displaySchema}\n-                isLoading={isImportingForeignSchema || isLoadingNamespaceTables}\n               />\n             ))\n           )}\n         </TableBody>\n       </Table>\n+\n       <ImportForeignSchemaDialog\n-        bucketName={bucketName ?? ''}\n         namespace={namespace}\n         circumstance=\"clash\"\n-        wrapperMeta={wrapperMeta}\n         visible={importForeignSchemaShown}\n         onClose={() => setImportForeignSchemaShown(false)}\n       />\n+\n+      <ConfirmationModal\n+        size=\"medium\"\n+        variant=\"warning\"\n+        loading={isDeletingNamespace}\n+        title={`Confirm to delete \"${namespace}\"`}\n+        description=\"This action cannot be undone.\"\n+        visible={showConfirmDeleteNamespace}\n+        onCancel={() => setShowConfirmDeleteNamespace(false)}\n+        onConfirm={() => onConfirmDeleteNamespace()}\n+      >\n+        <p className=\"text-sm\">\n+          This will remove all Iceberg tables under the namespace, as well as any associated foreign\n+          tables. Are you sure?\n+        </p>\n+      </ConfirmationModal>\n     </Card>\n   )\n }\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/UpdateForeignSchemaDialog.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/UpdateForeignSchemaDialog.tsx\nnew file mode 100644\nindex 0000000000000..909e46bde548e\n--- /dev/null\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/UpdateForeignSchemaDialog.tsx\n@@ -0,0 +1,169 @@\n+import { zodResolver } from '@hookform/resolvers/zod'\n+import { useState } from 'react'\n+import { SubmitHandler, useForm } from 'react-hook-form'\n+import { toast } from 'sonner'\n+import z from 'zod'\n+\n+import { useParams } from 'common'\n+import { InlineLinkClassName } from 'components/ui/InlineLink'\n+import { useFDWImportForeignSchemaMutation } from 'data/fdw/fdw-import-foreign-schema-mutation'\n+import { useSelectedProjectQuery } from 'hooks/misc/useSelectedProject'\n+import {\n+  Button,\n+  Dialog,\n+  DialogContent,\n+  DialogFooter,\n+  DialogHeader,\n+  DialogSection,\n+  DialogSectionSeparator,\n+  DialogTitle,\n+  DialogTrigger,\n+  Form_Shadcn_,\n+  FormField_Shadcn_,\n+  Select_Shadcn_,\n+  SelectContent_Shadcn_,\n+  SelectItem_Shadcn_,\n+  SelectTrigger_Shadcn_,\n+  SelectValue_Shadcn_,\n+  Tooltip,\n+  TooltipContent,\n+  TooltipTrigger,\n+} from 'ui'\n+import { FormItemLayout } from 'ui-patterns/form/FormItemLayout/FormItemLayout'\n+import { getAnalyticsBucketFDWServerName } from './AnalyticsBucketDetails.utils'\n+import { useAnalyticsBucketAssociatedEntities } from './useAnalyticsBucketAssociatedEntities'\n+\n+export const UpdateForeignSchemaDialog = ({\n+  namespace,\n+  tables,\n+}: {\n+  namespace: string\n+  tables: string[]\n+}) => {\n+  const { ref: projectRef, bucketId } = useParams()\n+  const { data: project } = useSelectedProjectQuery()\n+\n+  const [isOpen, setIsOpen] = useState(false)\n+\n+  const { icebergWrapper } = useAnalyticsBucketAssociatedEntities({ bucketId })\n+  const connectedForeignTablesForNamespace = (icebergWrapper?.tables ?? []).filter((x) =>\n+    x.options[0].startsWith(`table=${namespace}.`)\n+  )\n+  const schemasAssociatedWithNamespace = [\n+    ...new Set(connectedForeignTablesForNamespace.map((x) => x.schema)),\n+  ]\n+\n+  const serverName = getAnalyticsBucketFDWServerName(bucketId ?? '')\n+\n+  const FormSchema = z.object({\n+    schema: z.string().trim().min(1, 'Schema name is required'),\n+  })\n+  const form = useForm<z.infer<typeof FormSchema>>({\n+    resolver: zodResolver(FormSchema),\n+    defaultValues: { schema: schemasAssociatedWithNamespace[0] },\n+    values: { schema: schemasAssociatedWithNamespace[0] },\n+  })\n+\n+  const { mutateAsync: importForeignSchema, isLoading: isUpdating } =\n+    useFDWImportForeignSchemaMutation()\n+\n+  const onSubmit: SubmitHandler<z.infer<typeof FormSchema>> = async (values) => {\n+    if (!projectRef) return console.error('Project ref is required')\n+\n+    try {\n+      await importForeignSchema({\n+        projectRef,\n+        connectionString: project?.connectionString,\n+        serverName: serverName,\n+        sourceSchema: namespace,\n+        targetSchema: values.schema,\n+      })\n+\n+      toast.success(`Successfully updated \"${values.schema}\" schema!`)\n+      setIsOpen(false)\n+    } catch (error: any) {\n+      toast.error(`Failed to update schema: ${error.message}`)\n+    }\n+  }\n+\n+  return (\n+    <Dialog open={isOpen} onOpenChange={setIsOpen}>\n+      <DialogTrigger asChild>\n+        <Button type=\"default\">Update schema tables</Button>\n+      </DialogTrigger>\n+      <DialogContent size=\"medium\" aria-describedby={undefined}>\n+        <Form_Shadcn_ {...form}>\n+          <form onSubmit={form.handleSubmit(onSubmit)}>\n+            <DialogHeader>\n+              <DialogTitle>Update schema to expose foreign tables</DialogTitle>\n+            </DialogHeader>\n+            <DialogSectionSeparator />\n+            <DialogSection className=\"flex flex-col gap-y-4\">\n+              <p className=\"text-sm\">\n+                {tables.length > 1 ? (\n+                  <>\n+                    There are{' '}\n+                    <Tooltip>\n+                      <TooltipTrigger>\n+                        <span className={InlineLinkClassName}>{tables.length} tables</span>\n+                      </TooltipTrigger>\n+                      <TooltipContent className=\"max-w-64 text-center\" side=\"bottom\">\n+                        {tables.join(', ')}\n+                      </TooltipContent>\n+                    </Tooltip>{' '}\n+                    that aren't included in the Iceberg Foreign Data Wrapper. Update the wrapper to\n+                    create foreign tables for all unexposed tables. This will let you query the\n+                    tables from Postgres.\n+                  </>\n+                ) : (\n+                  `The table \"${tables[0]}\" in the \"${namespace}\" namespace is not yet included in the Iceberg Foreign Data Wrapper. The schema can be updated to expose this table as a foreign table.`\n+                )}\n+              </p>\n+\n+              {schemasAssociatedWithNamespace.length > 1 ? (\n+                <FormField_Shadcn_\n+                  control={form.control}\n+                  name=\"schema\"\n+                  render={({ field }) => (\n+                    <FormItemLayout\n+                      layout=\"vertical\"\n+                      label=\"Select which Postgres schema to update\"\n+                    >\n+                      <Select_Shadcn_\n+                        value={field.value}\n+                        onValueChange={(val) => field.onChange(val)}\n+                      >\n+                        <SelectTrigger_Shadcn_>\n+                          <SelectValue_Shadcn_ />\n+                        </SelectTrigger_Shadcn_>\n+                        <SelectContent_Shadcn_>\n+                          {schemasAssociatedWithNamespace.map((x) => (\n+                            <SelectItem_Shadcn_ key={x} value={x}>\n+                              {x}\n+                            </SelectItem_Shadcn_>\n+                          ))}\n+                        </SelectContent_Shadcn_>\n+                      </Select_Shadcn_>\n+                    </FormItemLayout>\n+                  )}\n+                />\n+              ) : (\n+                <p className=\"text-sm\">\n+                  Confirm to update foreign schema on the \"{namespace}\" namespace?\n+                </p>\n+              )}\n+            </DialogSection>\n+            <DialogFooter>\n+              <Button type=\"default\" disabled={isUpdating} onClick={() => setIsOpen(false)}>\n+                Cancel\n+              </Button>\n+              <Button htmlType=\"submit\" type=\"primary\" loading={isUpdating}>\n+                Update schema\n+              </Button>\n+            </DialogFooter>\n+          </form>\n+        </Form_Shadcn_>\n+      </DialogContent>\n+    </Dialog>\n+  )\n+}\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/index.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/index.tsx\nindex 48d8a950d97d9..877b0d0006d4f 100644\n--- a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/index.tsx\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/index.tsx\n@@ -34,12 +34,13 @@ import { Admonition } from 'ui-patterns/admonition'\n import { GenericTableLoader } from 'ui-patterns/ShimmeringLoader'\n import { DeleteAnalyticsBucketModal } from '../DeleteAnalyticsBucketModal'\n import { useSelectedAnalyticsBucket } from '../useSelectedAnalyticsBucket'\n+import { HIDE_REPLICATION_USER_FLOW } from './AnalyticsBucketDetails.constants'\n import { BucketHeader } from './BucketHeader'\n import { ConnectTablesDialog } from './ConnectTablesDialog'\n+import { CreateTableInstructions } from './CreateTableInstructions'\n import { NamespaceWithTables } from './NamespaceWithTables'\n import { SimpleConfigurationDetails } from './SimpleConfigurationDetails'\n import { useAnalyticsBucketAssociatedEntities } from './useAnalyticsBucketAssociatedEntities'\n-import { useAnalyticsBucketWrapperInstance } from './useAnalyticsBucketWrapperInstance'\n import { useIcebergWrapperExtension } from './useIcebergWrapper'\n \n export const AnalyticBucketDetails = () => {\n@@ -67,10 +68,12 @@ export const AnalyticBucketDetails = () => {\n \n   const { mutateAsync: startPipeline, isPending: isStartingPipeline } = useStartPipelineMutation()\n \n-  /** The wrapper instance is the wrapper that is installed for this Analytics bucket. */\n-  const { data: wrapperInstance, isLoading: isLoadingWrapperInstance } =\n-    useAnalyticsBucketWrapperInstance({ bucketId: bucket?.name })\n-  const { publication, pipeline } = useAnalyticsBucketAssociatedEntities({\n+  const {\n+    publication,\n+    pipeline,\n+    icebergWrapper: wrapperInstance,\n+    isLoadingWrapperInstance,\n+  } = useAnalyticsBucketAssociatedEntities({\n     projectRef,\n     bucketId: bucket?.name,\n   })\n@@ -111,10 +114,8 @@ export const AnalyticBucketDetails = () => {\n \n   const {\n     data: namespacesData = [],\n-    error: namespacesError,\n     isLoading: isLoadingNamespaces,\n     isSuccess: isSuccessNamespaces,\n-    isError: isErrorNamespaces,\n   } = useIcebergNamespacesQuery(\n     {\n       projectRef,\n@@ -179,7 +180,7 @@ export const AnalyticBucketDetails = () => {\n           {state === 'loading' ? (\n             <ScaffoldSection isFullWidth>\n               <BucketHeader showActions={false} />\n-              <GenericTableLoader headers={['Name']} />\n+              <GenericTableLoader />\n             </ScaffoldSection>\n           ) : state === 'not-installed' ? (\n             <ExtensionNotInstalled\n@@ -210,11 +211,11 @@ export const AnalyticBucketDetails = () => {\n \n                 {isLoadingNamespaces || isLoadingWrapperInstance ? (\n                   <GenericTableLoader headers={['Name']} />\n-                ) : isErrorNamespaces ? (\n-                  <AlertError subject=\"Failed to retrieve namespaces\" error={namespacesError} />\n                 ) : namespaces.length === 0 ? (\n                   <>\n-                    {isPollingForData ? (\n+                    {HIDE_REPLICATION_USER_FLOW ? (\n+                      <CreateTableInstructions />\n+                    ) : isPollingForData ? (\n                       <aside className=\"border border-dashed w-full bg-surface-100 rounded-lg px-4 py-10 flex flex-col gap-y-3 items-center text-center gap-1 text-balance\">\n                         <Loader2\n                           size={24}\n@@ -299,14 +300,11 @@ export const AnalyticBucketDetails = () => {\n                       {namespaces.map(({ namespace, schema, tables }) => (\n                         <NamespaceWithTables\n                           key={namespace}\n-                          bucketName={bucket?.name}\n                           namespace={namespace}\n                           sourceType=\"direct\"\n                           schema={schema}\n                           tables={tables as any}\n-                          wrapperInstance={wrapperInstance}\n                           wrapperValues={wrapperValues}\n-                          wrapperMeta={wrapperMeta}\n                           pollIntervalNamespaceTables={pollIntervalNamespaceTables}\n                           setPollIntervalNamespaceTables={setPollIntervalNamespaceTables}\n                         />\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/useAnalyticsBucketAssociatedEntities.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/useAnalyticsBucketAssociatedEntities.tsx\nindex f046a1ed733f1..106b74cf9cb0c 100644\n--- a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/useAnalyticsBucketAssociatedEntities.tsx\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/useAnalyticsBucketAssociatedEntities.tsx\n@@ -31,10 +31,11 @@ export const useAnalyticsBucketAssociatedEntities = (\n     '*'\n   )\n \n-  const { data: icebergWrapper, meta: icebergWrapperMeta } = useAnalyticsBucketWrapperInstance(\n-    { bucketId },\n-    { enabled: options.enabled }\n-  )\n+  const {\n+    data: icebergWrapper,\n+    meta: icebergWrapperMeta,\n+    isLoading: isLoadingWrapperInstance,\n+  } = useAnalyticsBucketWrapperInstance({ bucketId }, { enabled: options.enabled })\n \n   const { data: s3AccessKeys } = useStorageCredentialsQuery(\n     { projectRef },\n@@ -50,8 +51,10 @@ export const useAnalyticsBucketAssociatedEntities = (\n   )\n   const sourceId = sourcesData?.sources.find((s) => s.name === projectRef)?.id\n \n-  const { data: publications = [], isLoading: isLoadingPublications } =\n-    useReplicationPublicationsQuery({ projectRef, sourceId }, { enabled: options.enabled })\n+  const { data: publications = [] } = useReplicationPublicationsQuery(\n+    { projectRef, sourceId },\n+    { enabled: options.enabled }\n+  )\n   const publication = publications.find(\n     (p) => p.name === getAnalyticsBucketPublicationName(bucketId ?? '')\n   )\n@@ -73,6 +76,7 @@ export const useAnalyticsBucketAssociatedEntities = (\n     publication,\n     pipeline,\n     destination,\n+    isLoadingWrapperInstance,\n   }\n }\n \ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/CreateAnalyticsBucketModal.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/CreateAnalyticsBucketModal.tsx\nindex 9c40b53232dbb..fb64c16b2f249 100644\n--- a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/CreateAnalyticsBucketModal.tsx\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/CreateAnalyticsBucketModal.tsx\n@@ -262,10 +262,10 @@ export const CreateAnalyticsBucketModal = ({\n                   title=\"Wrappers extension must be updated for Iceberg Wrapper support\"\n                 >\n                   <p className=\"prose max-w-full text-sm !leading-normal\">\n-                    Update the <code className=\"text-xs\">wrappers</code> extension by disabling and\n-                    enabling it in{' '}\n-                    <InlineLink href={`/project/${ref}/database/extensions?filter=wrappers`}>\n-                      database extensions\n+                    Update the <code className=\"text-xs\">wrappers</code> extension by upgrading your\n+                    project from your{' '}\n+                    <InlineLink href={`/project/${ref}/settings/infrastructure`}>\n+                      project settings\n                     </InlineLink>{' '}\n                     before creating an Analytics bucket.{' '}\n                     <InlineLink href={`${DOCS_URL}/guides/database/extensions/wrappers/iceberg`}>\ndiff --git a/apps/studio/components/interfaces/Storage/ImportForeignSchemaDialog.tsx b/apps/studio/components/interfaces/Storage/ImportForeignSchemaDialog.tsx\nindex f606d89b0a94e..7d982581e39cd 100644\n--- a/apps/studio/components/interfaces/Storage/ImportForeignSchemaDialog.tsx\n+++ b/apps/studio/components/interfaces/Storage/ImportForeignSchemaDialog.tsx\n@@ -14,35 +14,35 @@ import { getFDWs } from 'data/fdw/fdws-query'\n import { useSelectedProjectQuery } from 'hooks/misc/useSelectedProject'\n import { Button, Form_Shadcn_, FormField_Shadcn_, Input_Shadcn_, Modal, Separator } from 'ui'\n import { FormItemLayout } from 'ui-patterns/form/FormItemLayout/FormItemLayout'\n-import type { WrapperMeta } from '../Integrations/Wrappers/Wrappers.types'\n import { formatWrapperTables } from '../Integrations/Wrappers/Wrappers.utils'\n import SchemaEditor from '../TableGridEditor/SidePanelEditor/SchemaEditor'\n import { getAnalyticsBucketFDWServerName } from './AnalyticsBuckets/AnalyticsBucketDetails/AnalyticsBucketDetails.utils'\n+import { useAnalyticsBucketAssociatedEntities } from './AnalyticsBuckets/AnalyticsBucketDetails/useAnalyticsBucketAssociatedEntities'\n import { getDecryptedParameters } from './ImportForeignSchemaDialog.utils'\n \n export interface ImportForeignSchemaDialogProps {\n-  bucketName: string\n   namespace: string\n-  wrapperMeta: WrapperMeta\n   circumstance?: 'fresh' | 'clash'\n   visible: boolean\n   onClose: () => void\n }\n \n export const ImportForeignSchemaDialog = ({\n-  bucketName,\n   namespace,\n-  wrapperMeta,\n   visible,\n   onClose,\n   circumstance = 'fresh',\n }: ImportForeignSchemaDialogProps) => {\n-  const { ref } = useParams()\n+  const { ref, bucketId: bucketName } = useParams()\n   const { data: project } = useSelectedProjectQuery()\n   const [loading, setLoading] = useState(false)\n   const [createSchemaSheetOpen, setCreateSchemaSheetOpen] = useState(false)\n \n   const { data: schemas } = useSchemasQuery({ projectRef: project?.ref! })\n+  const { icebergWrapperMeta: wrapperMeta } = useAnalyticsBucketAssociatedEntities({\n+    projectRef: ref,\n+    bucketId: bucketName,\n+  })\n \n   const { mutateAsync: createSchema } = useSchemaCreateMutation()\n   const { mutateAsync: importForeignSchema } = useFDWImportForeignSchemaMutation({})\n@@ -83,6 +83,7 @@ export const ImportForeignSchemaDialog = ({\n     const serverName = getAnalyticsBucketFDWServerName(values.bucketName)\n \n     if (!ref) return console.error('Project ref is required')\n+    if (!wrapperMeta) return console.error('Wrapper meta is required')\n     setLoading(true)\n \n     try {\ndiff --git a/apps/studio/data/config/project-storage-config-query.ts b/apps/studio/data/config/project-storage-config-query.ts\nindex 3b460103e9bbb..3a789af2ce7dd 100644\n--- a/apps/studio/data/config/project-storage-config-query.ts\n+++ b/apps/studio/data/config/project-storage-config-query.ts\n@@ -3,6 +3,7 @@ import { useQuery } from '@tanstack/react-query'\n import { useFlag } from 'common'\n import { components } from 'data/api'\n import { get, handleError } from 'data/fetchers'\n+import { useIsFeatureEnabled } from 'hooks/misc/useIsFeatureEnabled'\n import { IS_PLATFORM } from 'lib/constants'\n import type { ResponseError, UseCustomQueryOptions } from 'types'\n import { configKeys } from './keys'\n@@ -54,13 +55,15 @@ export const useProjectStorageConfigQuery = <TData = ProjectStorageConfigData>(\n   })\n \n export const useIsAnalyticsBucketsEnabled = ({ projectRef }: { projectRef?: string }) => {\n+  const { storageAnalytics } = useIsFeatureEnabled(['storage:analytics'])\n   const { data } = useProjectStorageConfigQuery({ projectRef })\n   const isIcebergCatalogEnabled = !!data?.features.icebergCatalog?.enabled\n-  return isIcebergCatalogEnabled\n+  return storageAnalytics && isIcebergCatalogEnabled\n }\n \n export const useIsVectorBucketsEnabled = ({ projectRef }: { projectRef?: string }) => {\n+  const { storageVectors } = useIsFeatureEnabled(['storage:vectors'])\n   // [Joshen] Temp using feature flag - will need to shift to storage config like analytics bucket once ready\n   const isVectorBucketsEnabled = useFlag('storageAnalyticsVector')\n-  return isVectorBucketsEnabled\n+  return storageVectors && isVectorBucketsEnabled\n }\ndiff --git a/apps/studio/data/storage/iceberg-namespace-create-mutation.ts b/apps/studio/data/storage/iceberg-namespace-create-mutation.ts\nindex 126d50bdcfb4e..7a86983df7c92 100644\n--- a/apps/studio/data/storage/iceberg-namespace-create-mutation.ts\n+++ b/apps/studio/data/storage/iceberg-namespace-create-mutation.ts\n@@ -72,14 +72,16 @@ export const useIcebergNamespaceCreateMutation = ({\n     mutationFn: (vars) => createIcebergNamespace({ ...vars, tempApiKey }),\n     async onSuccess(data, variables, context) {\n       await queryClient.invalidateQueries({\n-        queryKey: storageKeys.icebergNamespace(\n-          variables.catalogUri,\n-          variables.warehouse,\n-          variables.namespace\n-        ),\n+        queryKey: storageKeys.icebergNamespace({\n+          projectRef,\n+          catalog: variables.catalogUri,\n+          warehouse: variables.warehouse,\n+          namespace: variables.namespace,\n+        }),\n       })\n       await queryClient.invalidateQueries({\n         queryKey: storageKeys.icebergNamespaces({\n+          projectRef,\n           catalog: variables.catalogUri,\n           warehouse: variables.warehouse,\n         }),\ndiff --git a/apps/studio/data/storage/iceberg-namespace-delete-mutation.ts b/apps/studio/data/storage/iceberg-namespace-delete-mutation.ts\nnew file mode 100644\nindex 0000000000000..b22c82c628617\n--- /dev/null\n+++ b/apps/studio/data/storage/iceberg-namespace-delete-mutation.ts\n@@ -0,0 +1,88 @@\n+import { useMutation, useQueryClient } from '@tanstack/react-query'\n+import { toast } from 'sonner'\n+\n+import { useTemporaryAPIKeyQuery } from 'data/api-keys/temp-api-keys-query'\n+import { constructHeaders, fetchHandler, handleError } from 'data/fetchers'\n+import type { ResponseError, UseCustomMutationOptions } from 'types'\n+import { storageKeys } from './keys'\n+\n+type DeleteIcebergNamespaceVariables = {\n+  catalogUri: string\n+  warehouse: string\n+  namespace: string\n+}\n+\n+const errorPrefix = 'Failed to delete Iceberg namespace'\n+\n+async function deleteIcebergNamespace({\n+  catalogUri,\n+  warehouse,\n+  namespace,\n+  tempApiKey,\n+}: DeleteIcebergNamespaceVariables & { tempApiKey?: string }) {\n+  try {\n+    if (!tempApiKey) throw new Error(`${errorPrefix}: API Key missing`)\n+\n+    let headers = new Headers()\n+    headers = await constructHeaders({\n+      'Content-Type': 'application/json',\n+      apikey: tempApiKey,\n+    })\n+    headers.delete('Authorization')\n+\n+    const url = `${catalogUri}/v1/${warehouse}/namespaces/${namespace}`.replaceAll(\n+      /(?<!:)\\/\\//g,\n+      '/'\n+    )\n+\n+    const response = await fetchHandler(url, {\n+      headers,\n+      method: 'DELETE',\n+    })\n+    return response.status === 204\n+  } catch (error) {\n+    handleError(error)\n+  }\n+}\n+\n+type IcebergNamespaceDeleteData = Awaited<ReturnType<typeof deleteIcebergNamespace>>\n+\n+export const useIcebergNamespaceDeleteMutation = ({\n+  projectRef,\n+  onSuccess,\n+  onError,\n+  ...options\n+}: { projectRef?: string } & Omit<\n+  UseCustomMutationOptions<\n+    IcebergNamespaceDeleteData,\n+    ResponseError,\n+    DeleteIcebergNamespaceVariables\n+  >,\n+  'mutationFn'\n+> = {}) => {\n+  const queryClient = useQueryClient()\n+  const { data } = useTemporaryAPIKeyQuery({ projectRef })\n+  const tempApiKey = data?.api_key\n+\n+  return useMutation<IcebergNamespaceDeleteData, ResponseError, DeleteIcebergNamespaceVariables>({\n+    mutationFn: (vars) => deleteIcebergNamespace({ ...vars, tempApiKey }),\n+    async onSuccess(data, variables, context) {\n+      await queryClient.invalidateQueries({\n+        queryKey: storageKeys.icebergNamespaces({\n+          projectRef,\n+          catalog: variables.catalogUri,\n+          warehouse: variables.warehouse,\n+        }),\n+      })\n+      await onSuccess?.(data, variables, context)\n+    },\n+    async onError(data, variables, context) {\n+      if (onError === undefined) {\n+        toast.error(`Failed to delete Iceberg namespace: ${data.message}`)\n+      } else {\n+        onError(data, variables, context)\n+      }\n+    },\n+    ...options,\n+  })\n+}\ndiff --git a/apps/studio/data/storage/iceberg-namespace-table-delete-mutation.ts b/apps/studio/data/storage/iceberg-namespace-table-delete-mutation.ts\nindex 2af9d5401afc7..c89bc814074bf 100644\n--- a/apps/studio/data/storage/iceberg-namespace-table-delete-mutation.ts\n+++ b/apps/studio/data/storage/iceberg-namespace-table-delete-mutation.ts\n@@ -40,12 +40,6 @@ async function deleteIcebergNamespaceTable({\n       )\n \n     const response = await fetchHandler(url, { headers, method: 'DELETE' })\n-    const result = await response.json()\n-    if (result.error) {\n-      if (result.error.message) throw new Error(`${errorPrefix}: ${result.error.message}`)\n-      else throw new Error(errorPrefix)\n-    }\n-\n     return response.status === 204\n   } catch (error) {\n     handleError(error)\n@@ -79,11 +73,12 @@ export const useIcebergNamespaceTableDeleteMutation = ({\n     mutationFn: (vars) => deleteIcebergNamespaceTable({ ...vars, tempApiKey }),\n     async onSuccess(data, variables, context) {\n       await queryClient.invalidateQueries({\n-        queryKey: storageKeys.icebergNamespace(\n-          variables.catalogUri,\n-          variables.warehouse,\n-          variables.namespace\n-        ),\n+        queryKey: storageKeys.icebergNamespace({\n+          projectRef,\n+          catalog: variables.catalogUri,\n+          warehouse: variables.warehouse,\n+          namespace: variables.namespace,\n+        }),\n       })\n       await onSuccess?.(data, variables, context)\n     },\ndiff --git a/apps/studio/data/storage/iceberg-namespaces-query.ts b/apps/studio/data/storage/iceberg-namespaces-query.ts\nindex f770e7d332033..6f311e685264d 100644\n--- a/apps/studio/data/storage/iceberg-namespaces-query.ts\n+++ b/apps/studio/data/storage/iceberg-namespaces-query.ts\n@@ -11,14 +11,13 @@ type GetNamespacesVariables = {\n   projectRef?: string\n }\n \n-const errorPrefix = 'Failed to delete Iceberg namespaces'\n+const errorPrefix = 'Failed to retrieve Iceberg namespaces'\n \n async function getNamespaces({\n   catalogUri,\n   warehouse,\n   tempApiKey,\n }: GetNamespacesVariables & { tempApiKey?: string }) {\n-  console.log('getNamespaces', { warehouse })\n   try {\n     if (!tempApiKey) throw new Error(`${errorPrefix}: API Key missing`)\n \ndiff --git a/apps/studio/data/storage/keys.ts b/apps/studio/data/storage/keys.ts\nindex 6cfc534206fcb..952d0a59059f3 100644\n--- a/apps/studio/data/storage/keys.ts\n+++ b/apps/studio/data/storage/keys.ts\n@@ -18,8 +18,17 @@ export const storageKeys = {\n     catalog: string\n     warehouse: string\n   }) => [projectRef, 'catalog', catalog, 'warehouse', warehouse, 'namespaces'] as const,\n-  icebergNamespace: (catalog: string, warehouse: string, namespace: string) =>\n-    ['catalog', catalog, 'warehouse', warehouse, 'namespaces', namespace] as const,\n+  icebergNamespace: ({\n+    projectRef,\n+    catalog,\n+    warehouse,\n+    namespace,\n+  }: {\n+    projectRef?: string\n+    catalog: string\n+    warehouse: string\n+    namespace: string\n+  }) => [projectRef, 'catalog', catalog, 'warehouse', warehouse, 'namespaces', namespace] as const,\n   icebergNamespaceTables: ({\n     projectRef,\n     catalog,\ndiff --git a/apps/studio/data/vault/vault-secret-decrypted-value-query.ts b/apps/studio/data/vault/vault-secret-decrypted-value-query.ts\nindex 18e465b8945f0..f63336b341483 100644\n--- a/apps/studio/data/vault/vault-secret-decrypted-value-query.ts\n+++ b/apps/studio/data/vault/vault-secret-decrypted-value-query.ts\n@@ -1,8 +1,8 @@\n import { Query } from '@supabase/pg-meta/src/query'\n import { useQuery } from '@tanstack/react-query'\n+import { UseCustomQueryOptions } from 'types'\n import { executeSql } from '../sql/execute-sql-query'\n import { vaultSecretsKeys } from './keys'\n-import { UseCustomQueryOptions } from 'types'\n \n const vaultSecretDecryptedValueQuery = (id: string) => {\n   const sql = new Query()\n@@ -64,7 +64,7 @@ export const useVaultSecretDecryptedValueQuery = <TData = string>(\n     select(data) {\n       return (data[0]?.decrypted_secret ?? '') as TData\n     },\n-    enabled: enabled && typeof projectRef !== 'undefined',\n+    enabled: enabled && typeof projectRef !== 'undefined' && typeof id !== 'undefined',\n     ...options,\n   })\n \ndiff --git a/packages/common/enabled-features/enabled-features.json b/packages/common/enabled-features/enabled-features.json\nindex e86431605becd..5c5155fd6539a 100644\n--- a/packages/common/enabled-features/enabled-features.json\n+++ b/packages/common/enabled-features/enabled-features.json\n@@ -121,6 +121,9 @@\n   \"sdk:python\": true,\n   \"sdk:swift\": true,\n \n+  \"storage:analytics\": true,\n+  \"storage:vectors\": false,\n+\n   \"search:fullIndex\": true,\n \n   \"support:show_client_libraries\": true\ndiff --git a/packages/common/enabled-features/enabled-features.schema.json b/packages/common/enabled-features/enabled-features.schema.json\nindex 3c4520832aa24..15f56226bd147 100644\n--- a/packages/common/enabled-features/enabled-features.schema.json\n+++ b/packages/common/enabled-features/enabled-features.schema.json\n@@ -409,6 +409,15 @@\n       \"description\": \"Enable the Swift SDK\"\n     },\n \n+    \"storage:analytics\": {\n+      \"type\": \"boolean\",\n+      \"description\": \"Enable Analytics Buckets in Storage\"\n+    },\n+    \"storage:vectors\": {\n+      \"type\": \"boolean\",\n+      \"description\": \"Enable Vector Buckets in Storage\"\n+    },\n+\n     \"search:fullIndex\": {\n       \"type\": \"boolean\",\n       \"description\": \"Enable the full search index. When true, uses the  full search; when false, uses the alternate search index.\"\n@@ -509,6 +518,8 @@\n     \"sdk:kotlin\",\n     \"sdk:python\",\n     \"sdk:swift\",\n+    \"storage:analytics\",\n+    \"storage:vectors\",\n     \"search:fullIndex\"\n   ],\n   \"additionalProperties\": false\ndiff --git a/packages/ui-patterns/src/ShimmeringLoader/index.tsx b/packages/ui-patterns/src/ShimmeringLoader/index.tsx\nindex af582426138bd..50fe487884cad 100644\n--- a/packages/ui-patterns/src/ShimmeringLoader/index.tsx\n+++ b/packages/ui-patterns/src/ShimmeringLoader/index.tsx\n@@ -35,10 +35,10 @@ export const GenericSkeletonLoader = ({ className }: GenericSkeletonLoaderProps)\n )\n \n export const GenericTableLoader = ({\n-  headers,\n+  headers = [],\n   numRows = 3,\n }: {\n-  headers: (string | null)[]\n+  headers?: (string | null)[]\n   numRows?: number\n }) => {\n   return (\n@@ -46,9 +46,11 @@ export const GenericTableLoader = ({\n       <Table>\n         <TableHeader>\n           <TableRow>\n-            {headers.map((h, i) => (\n-              <TableHead key={`${h}_${i}`}>{h}</TableHead>\n-            ))}\n+            {headers.length === 0 ? (\n+              <TableHead />\n+            ) : (\n+              headers.map((h, i) => <TableHead key={`${h}_${i}`}>{h}</TableHead>)\n+            )}\n           </TableRow>\n         </TableHeader>\n         <TableBody>\n",
			"diffSize": 83366,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "562a5a4540535a9ee22ebf21d93bb9bfb4d1e54d",
			"message": "Update humans.txt (#35994)\n\nAdded my name to the list!!\n\nCo-authored-by: Ivan Vasilov <vasilov.ivan@gmail.com>",
			"user": "jimbrodeur",
			"timestamp": "2025-11-21T08:22:07Z",
			"author": {
				"name": "jimbrodeur",
				"email": "jim.brodeur@supabase.io",
				"username": "jimbrodeur"
			},
			"files": {
				"added": [],
				"modified": ["apps/docs/public/humans.txt"],
				"removed": []
			},
			"diff": "diff --git a/apps/docs/public/humans.txt b/apps/docs/public/humans.txt\nindex db54a75b227b2..d8c124d5ed31a 100644\n--- a/apps/docs/public/humans.txt\n+++ b/apps/docs/public/humans.txt\n@@ -80,6 +80,7 @@ Jean-Paul Argudo\n Jeff Smick\n Jenny Kibiri\n Jess Shears\n+Jim Brodeur\n Jim Chanco Jr\n Joakim Ahrlin\n John Pena\n",
			"diffSize": 309,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "cf9f685279437b550714ff9187b38d764601fae6",
			"message": "docs: add Nick B to humans.txt (#40129)\n\nCo-authored-by: Ivan Vasilov <vasilov.ivan@gmail.com>",
			"user": "pgnickb",
			"timestamp": "2025-11-21T08:17:56Z",
			"author": {
				"name": "Nick Babadzhanian",
				"email": "33933459+pgnickb@users.noreply.github.com",
				"username": "pgnickb"
			},
			"files": {
				"added": [],
				"modified": ["apps/docs/public/humans.txt"],
				"removed": []
			},
			"diff": "diff --git a/apps/docs/public/humans.txt b/apps/docs/public/humans.txt\nindex e85ce4cab6c0d..db54a75b227b2 100644\n--- a/apps/docs/public/humans.txt\n+++ b/apps/docs/public/humans.txt\n@@ -117,6 +117,7 @@ Matt Johnston\n Matt Rossman\n Monica Khoury\n Mykhailo Mischa Lieibenson\n+Nick B\n Nick Littman\n Nyannyacha\n Oli R\n",
			"diffSize": 313,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "2a5b49848b1a40ba9d41faade2c0040e71752f61",
			"message": "Add myself to humans.txt (#40338)\n\nCo-authored-by: Ivan Vasilov <vasilov.ivan@gmail.com>",
			"user": "AkashM398",
			"timestamp": "2025-11-21T08:16:25Z",
			"author": {
				"name": "Akash M",
				"email": "38563661+AkashM398@users.noreply.github.com",
				"username": "AkashM398"
			},
			"files": {
				"added": [],
				"modified": ["apps/docs/public/humans.txt"],
				"removed": []
			},
			"diff": "diff --git a/apps/docs/public/humans.txt b/apps/docs/public/humans.txt\nindex ae6d78f1b7d37..e85ce4cab6c0d 100644\n--- a/apps/docs/public/humans.txt\n+++ b/apps/docs/public/humans.txt\n@@ -4,6 +4,7 @@ Supabase is 100% remote.\n \n Aaron Byrne\n Adam Mokan\n+Akash Manimaran\n Alaister Young\n Alan De Los Santos\n Aleksi Immonen\n",
			"diffSize": 318,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "63e40c8fe989d982b8fe3e9518b6a4b259d98beb",
			"message": "Add Kostas Botsas to contributors (#40341)\n\nadd myself to humans.txt\n\nadd Kostas Botsas\n\nCo-authored-by: Ivan Vasilov <vasilov.ivan@gmail.com>",
			"user": "kostasb",
			"timestamp": "2025-11-21T08:15:06Z",
			"author": {
				"name": "Kostas Botsas",
				"email": "kostas.botsas@supabase.io",
				"username": "kostasb"
			},
			"files": {
				"added": [],
				"modified": ["apps/docs/public/humans.txt"],
				"removed": []
			},
			"diff": "diff --git a/apps/docs/public/humans.txt b/apps/docs/public/humans.txt\nindex f6922f1f08e4b..ae6d78f1b7d37 100644\n--- a/apps/docs/public/humans.txt\n+++ b/apps/docs/public/humans.txt\n@@ -98,6 +98,7 @@ Katerina Skroumpelou\n Kemal Y\n Kevin Brolly\n Kevin Grüneberg\n+Kostas Botsas\n Krishna Sai Vandavasi\n Lakshan Perera\n Laura C\n",
			"diffSize": 323,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "4a25a26052602890fcf5ea3a7c87ec8336d3b2bb",
			"message": "docs: add Matthew Hambright to  humans.txt (#40630)",
			"user": "Hamm1",
			"timestamp": "2025-11-21T08:05:42Z",
			"author": {
				"name": "Matthew Hambright",
				"email": "39998558+Hamm1@users.noreply.github.com",
				"username": "Hamm1"
			},
			"files": {
				"added": [],
				"modified": ["apps/docs/public/humans.txt"],
				"removed": []
			},
			"diff": "diff --git a/apps/docs/public/humans.txt b/apps/docs/public/humans.txt\nindex dce66077a6be6..f6922f1f08e4b 100644\n--- a/apps/docs/public/humans.txt\n+++ b/apps/docs/public/humans.txt\n@@ -110,6 +110,7 @@ Luca Forstner\n Manan Gupta\n Margarita Sandomirskaia\n Mark Burggraf\n+Matthew Hambright\n Matt Johnston\n Matt Rossman\n Monica Khoury\n",
			"diffSize": 331,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "8e7e8084d195e8bd6ff78f2351187eae445e3533",
			"message": "[FE-2147] feat(studio): maintenance mode (#40655)\n\nfeat(studio): maintenance mode",
			"user": "alaister",
			"timestamp": "2025-11-21T07:10:18Z",
			"author": {
				"name": "Alaister Young",
				"email": "alaister@users.noreply.github.com",
				"username": "alaister"
			},
			"files": {
				"added": ["apps/studio/pages/maintenance.tsx"],
				"modified": ["apps/studio/next.config.js", "turbo.json"],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/next.config.js b/apps/studio/next.config.js\nindex 3e1e931248a5c..2177d91b3a9f0 100644\n--- a/apps/studio/next.config.js\n+++ b/apps/studio/next.config.js\n@@ -438,6 +438,22 @@ const nextConfig = {\n             },\n           ]\n         : []),\n+\n+      ...(process.env.MAINTENANCE_MODE === 'true'\n+        ? [\n+            {\n+              source: '/((?!maintenance).*)', // Redirect all paths except /maintenance\n+              destination: '/maintenance',\n+              permanent: false,\n+            },\n+          ]\n+        : [\n+            {\n+              source: '/maintenance',\n+              destination: '/',\n+              permanent: false,\n+            },\n+          ]),\n     ]\n   },\n   async headers() {\ndiff --git a/apps/studio/pages/maintenance.tsx b/apps/studio/pages/maintenance.tsx\nnew file mode 100644\nindex 0000000000000..44b956478694e\n--- /dev/null\n+++ b/apps/studio/pages/maintenance.tsx\n@@ -0,0 +1,60 @@\n+import { RefreshCw } from 'lucide-react'\n+import { useTheme } from 'next-themes'\n+import Head from 'next/head'\n+\n+import { BASE_PATH } from 'lib/constants'\n+import type { NextPageWithLayout } from 'types'\n+import { Button, cn } from 'ui'\n+import { useMemo } from 'react'\n+\n+const MaintenancePage: NextPageWithLayout = () => {\n+  const { resolvedTheme } = useTheme()\n+  const isDarkMode = resolvedTheme?.includes('dark')\n+\n+  const imgUrl = useMemo(\n+    () =>\n+      isDarkMode ? `${BASE_PATH}/img/supabase-dark.svg` : `${BASE_PATH}/img/supabase-light.svg`,\n+    [isDarkMode]\n+  )\n+\n+  return (\n+    <>\n+      <Head>\n+        <title>Supabase | Under Maintenance</title>\n+      </Head>\n+      <div className=\"flex flex-col items-center gap-6 text-center\">\n+        <div className=\"flex items-center justify-center mb-4\">\n+          <img src={imgUrl} alt=\"Supabase\" className=\"h-8\" />\n+        </div>\n+        <div className=\"space-y-1\">\n+          <h1 className=\"text-2xl font-medium text-foreground\">Under Maintenance</h1>\n+          <p className=\"text-foreground-light max-w-xs mx-auto\">\n+            We are currently improving our services. The dashboard will be back online shortly.\n+          </p>\n+        </div>\n+        <div className=\"flex flex-col items-center gap-2 mt-4\">\n+          <p className=\"text-sm text-foreground-lighter\">\n+            Reload the page to check if the maintenance window has ended\n+          </p>\n+          <Button onClick={() => window.location.reload()} type=\"primary\" icon={<RefreshCw />}>\n+            Reload\n+          </Button>\n+        </div>\n+      </div>\n+    </>\n+  )\n+}\n+\n+MaintenancePage.getLayout = (page) => (\n+  <div\n+    className={cn(\n+      'flex h-full min-h-screen bg-studio',\n+      'w-full flex-col place-items-center',\n+      'items-center justify-center gap-8 px-5'\n+    )}\n+  >\n+    {page}\n+  </div>\n+)\n+\n+export default MaintenancePage\ndiff --git a/turbo.json b/turbo.json\nindex 2137fa130e121..1888dac5b6e9e 100644\n--- a/turbo.json\n+++ b/turbo.json\n@@ -73,6 +73,7 @@\n         \"SUPABASE_URL\",\n         \"VERCEL\",\n         \"VERCEL_ENV\",\n+        \"MAINTENANCE_MODE\",\n         // These envs are used in the packages\n         \"NEXT_PUBLIC_STORAGE_KEY\",\n         \"NEXT_PUBLIC_AUTH_DEBUG_KEY\",\n",
			"diffSize": 3197,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "3ace7cbcacb966311adc09d72c724e1e97dba245",
			"message": "Fix transfer project button (#40672)",
			"user": "joshenlim",
			"timestamp": "2025-11-21T05:12:08Z",
			"author": {
				"name": "Joshen Lim",
				"email": "joshenlimek@gmail.com",
				"username": "joshenlim"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/Settings/General/TransferProjectPanel/TransferProjectButton.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Settings/General/TransferProjectPanel/TransferProjectButton.tsx b/apps/studio/components/interfaces/Settings/General/TransferProjectPanel/TransferProjectButton.tsx\nindex 945b2cd9a39f9..4388d275dc6be 100644\n--- a/apps/studio/components/interfaces/Settings/General/TransferProjectPanel/TransferProjectButton.tsx\n+++ b/apps/studio/components/interfaces/Settings/General/TransferProjectPanel/TransferProjectButton.tsx\n@@ -61,7 +61,8 @@ export const TransferProjectButton = () => {\n         queryKey: projectKeys.projectTransferPreview(projectRef, selectedOrg),\n       })\n     }\n-  }, [isOpen, projectRef, selectedOrg, queryClient])\n+    // eslint-disable-next-line react-hooks/exhaustive-deps\n+  }, [isOpen])\n \n   const { can: canTransferProject } = useAsyncCheckPermissions(\n     PermissionAction.UPDATE,\n",
			"diffSize": 849,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		}
	]
}
