{
	"date": "2025-11-24",
	"commits": [
		{
			"sha": "ba16b2c189fbc62c11c0c58062175839464c1641",
			"message": "docs: vector and analytics storage (#39716)\n\n* Docs skeleton\n\n* Create strcuture\n\n* Revert \"Docs skeleton\"\n\nThis reverts commit 1788972dd2bde38147a2e14fb497cf5becf1d244.\n\n* Add analytics\n\n* basic updates\n\n* Fix docs reference\n\n* Apply suggestions from code review\n\nCo-authored-by: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>\n\n* docs(storage): analytics buckets\n\n* Apply suggestions from code review\n\nCo-authored-by: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>\n\n* Apply suggestions from code review\n\n* format\n\n---------\n\nCo-authored-by: Danny White <3104761+dnywh@users.noreply.github.com>\nCo-authored-by: github-actions[bot] <41898282+github-actions[bot]@users.noreply.github.com>\nCo-authored-by: fenos <fabri.feno@gmail.com>\nCo-authored-by: Charis <26616127+charislam@users.noreply.github.com>",
			"user": "ChrisChinchilla",
			"timestamp": "2025-11-24T20:57:52Z",
			"author": {
				"name": "Chris Chinchilla",
				"email": "chris.ward@supabase.io",
				"username": "ChrisChinchilla"
			},
			"files": {
				"added": [
					"apps/docs/content/guides/storage/analytics/etl.mdx",
					"apps/docs/content/guides/storage/analytics/examples/apache-spark.mdx",
					"apps/docs/content/guides/storage/analytics/examples/duckdb.mdx",
					"apps/docs/content/guides/storage/analytics/examples/pyiceberg.mdx",
					"apps/docs/content/guides/storage/analytics/pricing.mdx",
					"apps/docs/content/guides/storage/analytics/query-with-postgres.mdx",
					"apps/docs/content/guides/storage/vector/creating-vector-buckets.mdx",
					"apps/docs/content/guides/storage/vector/introduction.mdx",
					"apps/docs/content/guides/storage/vector/limits.mdx",
					"apps/docs/content/guides/storage/vector/querying-vectors.mdx",
					"apps/docs/content/guides/storage/vector/storing-vectors.mdx",
					"apps/docs/content/guides/storage/vector/working-with-indexes.mdx",
					"apps/docs/public/img/storage/query-analytics-schema-name.png",
					"apps/docs/public/img/storage/query-analytics-with-postgres.png"
				],
				"modified": [
					"apps/docs/components/Navigation/NavigationMenu/NavigationMenu.constants.ts",
					"apps/docs/content/guides/storage.mdx",
					"apps/docs/content/guides/storage/analytics/connecting-to-analytics-bucket.mdx",
					"apps/docs/content/guides/storage/analytics/creating-analytics-buckets.mdx",
					"apps/docs/content/guides/storage/analytics/introduction.mdx",
					"apps/docs/content/guides/storage/analytics/limits.mdx",
					"apps/studio/components/interfaces/Storage/Storage.constants.ts",
					"packages/config/ui.config.js",
					"supa-mdx-lint/Rule001HeadingCase.toml",
					"supa-mdx-lint/Rule003Spelling.toml"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/docs/components/Navigation/NavigationMenu/NavigationMenu.constants.ts b/apps/docs/components/Navigation/NavigationMenu/NavigationMenu.constants.ts\nindex 5c358d9fd3270..408492b92b3f4 100644\n--- a/apps/docs/components/Navigation/NavigationMenu/NavigationMenu.constants.ts\n+++ b/apps/docs/components/Navigation/NavigationMenu/NavigationMenu.constants.ts\n@@ -1878,143 +1878,201 @@ export const storage: NavMenuConstant = {\n   url: '/guides/storage',\n   items: [\n     { name: 'Overview', url: '/guides/storage' },\n-    { name: 'Quickstart', url: '/guides/storage/quickstart' },\n     {\n-      name: 'Buckets',\n+      name: 'File Buckets',\n       url: undefined,\n       items: [\n+        { name: 'Quickstart', url: '/guides/storage/quickstart' },\n         { name: 'Fundamentals', url: '/guides/storage/buckets/fundamentals' },\n         {\n           name: 'Creating Buckets',\n           url: '/guides/storage/buckets/creating-buckets' as `/${string}`,\n         },\n-      ],\n-    },\n-    {\n-      name: 'Security',\n-      url: undefined,\n-      items: [\n         {\n-          name: 'Ownership',\n-          url: '/guides/storage/security/ownership' as `/${string}`,\n+          name: 'Security',\n+          url: '/guides/storage/security',\n+          items: [\n+            {\n+              name: 'Ownership',\n+              url: '/guides/storage/security/ownership' as `/${string}`,\n+            },\n+            {\n+              name: 'Access Control',\n+              url: '/guides/storage/security/access-control' as `/${string}`,\n+            },\n+          ],\n         },\n         {\n-          name: 'Access Control',\n-          url: '/guides/storage/security/access-control' as `/${string}`,\n+          name: 'Uploads',\n+          url: '/guides/storage/uploads',\n+          items: [\n+            {\n+              name: 'Standard Uploads',\n+              url: '/guides/storage/uploads/standard-uploads' as `/${string}`,\n+            },\n+            {\n+              name: 'Resumable Uploads',\n+              url: '/guides/storage/uploads/resumable-uploads' as `/${string}`,\n+            },\n+            {\n+              name: 'S3 Uploads',\n+              url: '/guides/storage/uploads/s3-uploads' as `/${string}`,\n+            },\n+            { name: 'Limits', url: '/guides/storage/uploads/file-limits', enabled: billingEnabled },\n+          ],\n         },\n-      ],\n-    },\n-    {\n-      name: 'Uploads',\n-      url: undefined,\n-      items: [\n         {\n-          name: 'Standard Uploads',\n-          url: '/guides/storage/uploads/standard-uploads' as `/${string}`,\n+          name: 'Serving',\n+          url: '/guides/storage/serving',\n+          items: [\n+            { name: 'Serving assets', url: '/guides/storage/serving/downloads' },\n+            {\n+              name: 'Image Transformations',\n+              url: '/guides/storage/serving/image-transformations' as `/${string}`,\n+            },\n+            {\n+              name: 'Bandwidth & Storage Egress',\n+              url: '/guides/storage/serving/bandwidth' as `/${string}`,\n+              enabled: billingEnabled,\n+            },\n+          ],\n         },\n         {\n-          name: 'Resumable Uploads',\n-          url: '/guides/storage/uploads/resumable-uploads' as `/${string}`,\n+          name: 'Management',\n+          url: '/guides/storage/management',\n+          items: [\n+            { name: 'Copy / Move Objects', url: '/guides/storage/management/copy-move-objects' },\n+            { name: 'Delete Objects', url: '/guides/storage/management/delete-objects' },\n+          ],\n         },\n         {\n-          name: 'S3 Uploads',\n-          url: '/guides/storage/uploads/s3-uploads' as `/${string}`,\n+          name: 'S3',\n+          url: '/guides/storage/s3',\n+          items: [\n+            { name: 'Authentication', url: '/guides/storage/s3/authentication' },\n+            { name: 'API Compatibility', url: '/guides/storage/s3/compatibility' },\n+          ],\n         },\n-        { name: 'Limits', url: '/guides/storage/uploads/file-limits', enabled: billingEnabled },\n-      ],\n-    },\n-    {\n-      name: 'Serving',\n-      url: undefined,\n-      items: [\n-        { name: 'Serving assets', url: '/guides/storage/serving/downloads' },\n         {\n-          name: 'Image Transformations',\n-          url: '/guides/storage/serving/image-transformations' as `/${string}`,\n+          name: 'CDN',\n+          url: '/guides/storage/cdn',\n+          items: [\n+            { name: 'Fundamentals', url: '/guides/storage/cdn/fundamentals' },\n+            { name: 'Smart CDN', url: '/guides/storage/cdn/smart-cdn' },\n+            { name: 'Metrics', url: '/guides/storage/cdn/metrics' },\n+          ],\n         },\n         {\n-          name: 'Bandwidth & Storage Egress',\n-          url: '/guides/storage/serving/bandwidth' as `/${string}`,\n-          enabled: billingEnabled,\n+          name: 'Debugging',\n+          url: '/guides/storage/debugging',\n+          items: [\n+            { name: 'Logs', url: '/guides/storage/debugging/logs' },\n+            { name: 'Error Codes', url: '/guides/storage/debugging/error-codes' },\n+            { name: 'Troubleshooting', url: '/guides/storage/troubleshooting' },\n+          ],\n+        },\n+        {\n+          name: 'Schema',\n+          url: '/guides/storage/schema',\n+          items: [\n+            { name: 'Database Design', url: '/guides/storage/schema/design' },\n+            {\n+              name: 'Helper Functions',\n+              url: '/guides/storage/schema/helper-functions' as `/${string}`,\n+            },\n+            { name: 'Custom Roles', url: '/guides/storage/schema/custom-roles' },\n+          ],\n+        },\n+        {\n+          name: 'Going to production',\n+          url: '/guides/storage/production',\n+          items: [{ name: 'Scaling', url: '/guides/storage/production/scaling' }],\n         },\n-      ],\n-    },\n-    {\n-      name: 'Management',\n-      url: undefined,\n-      items: [\n-        { name: 'Copy / Move Objects', url: '/guides/storage/management/copy-move-objects' },\n-        { name: 'Delete Objects', url: '/guides/storage/management/delete-objects' },\n         {\n           name: 'Pricing',\n-          url: '/guides/storage/management/pricing' as `/${string}`,\n+          url: '/guides/storage/pricing' as `/${string}`,\n           enabled: billingEnabled,\n         },\n       ],\n     },\n-    {\n-      name: 'S3',\n-      url: undefined,\n-      items: [\n-        { name: 'Authentication', url: '/guides/storage/s3/authentication' },\n-        { name: 'API Compatibility', url: '/guides/storage/s3/compatibility' },\n-      ],\n-    },\n     {\n       name: 'Analytics Buckets',\n-      url: undefined,\n       items: [\n         { name: 'Introduction', url: '/guides/storage/analytics/introduction' },\n         {\n-          name: 'Creating Analytics Buckets',\n+          name: 'Creating Buckets',\n           url: '/guides/storage/analytics/creating-analytics-buckets' as `/${string}`,\n         },\n         {\n-          name: 'Connecting to Analytics Buckets',\n+          name: 'Iceberg Catalog',\n           url: '/guides/storage/analytics/connecting-to-analytics-bucket' as `/${string}`,\n         },\n+        {\n+          name: 'Realtime Data-Sync',\n+          url: '/guides/storage/analytics/etl' as `/${string}`,\n+        },\n+        {\n+          name: 'Query with Postgres',\n+          url: '/guides/storage/analytics/query-with-postgres' as `/${string}`,\n+        },\n+        {\n+          name: 'Examples',\n+          url: '/guides/storage/analytics/examples' as `/${string}`,\n+          items: [\n+            {\n+              name: 'Using DuckDB',\n+              url: '/guides/storage/analytics/examples/duckdb',\n+            },\n+            {\n+              name: 'Using PyIceberg',\n+              url: '/guides/storage/analytics/examples/pyiceberg',\n+            },\n+            {\n+              name: 'Using Apache Spark',\n+              url: '/guides/storage/analytics/examples/apache-spark',\n+            },\n+          ],\n+        },\n         {\n           name: 'Limits',\n           url: '/guides/storage/analytics/limits' as `/${string}`,\n           enabled: billingEnabled,\n         },\n+        {\n+          name: 'Pricing',\n+          url: '/guides/storage/analytics/pricing' as `/${string}`,\n+          enabled: billingEnabled,\n+        },\n       ],\n     },\n     {\n-      name: 'CDN',\n-      url: undefined,\n-      items: [\n-        { name: 'Fundamentals', url: '/guides/storage/cdn/fundamentals' },\n-        { name: 'Smart CDN', url: '/guides/storage/cdn/smart-cdn' },\n-        { name: 'Metrics', url: '/guides/storage/cdn/metrics' },\n-      ],\n-    },\n-    {\n-      name: 'Debugging',\n-      url: undefined,\n-      items: [\n-        { name: 'Logs', url: '/guides/storage/debugging/logs' },\n-        { name: 'Error Codes', url: '/guides/storage/debugging/error-codes' },\n-        { name: 'Troubleshooting', url: '/guides/storage/troubleshooting' },\n-      ],\n-    },\n-    {\n-      name: 'Schema',\n-      url: undefined,\n+      name: 'Vector Buckets',\n+      url: '/guides/storage/vector',\n       items: [\n-        { name: 'Database Design', url: '/guides/storage/schema/design' },\n+        { name: 'Introduction', url: '/guides/storage/vector/introduction' },\n         {\n-          name: 'Helper Functions',\n-          url: '/guides/storage/schema/helper-functions' as `/${string}`,\n+          name: 'Creating Buckets',\n+          url: '/guides/storage/vector/creating-vector-buckets' as `/${string}`,\n+        },\n+        {\n+          name: 'Working with Indexes',\n+          url: '/guides/storage/vector/working-with-indexes' as `/${string}`,\n+        },\n+        {\n+          name: 'Storing Vectors',\n+          url: '/guides/storage/vector/storing-vectors' as `/${string}`,\n+        },\n+        {\n+          name: 'Querying Vectors',\n+          url: '/guides/storage/vector/querying-vectors' as `/${string}`,\n+        },\n+        {\n+          name: 'Limits',\n+          url: '/guides/storage/vector/limits' as `/${string}`,\n+          enabled: billingEnabled,\n         },\n-        { name: 'Custom Roles', url: '/guides/storage/schema/custom-roles' },\n       ],\n     },\n-    {\n-      name: 'Going to production',\n-      url: undefined,\n-      items: [{ name: 'Scaling', url: '/guides/storage/production/scaling' }],\n-    },\n   ],\n }\n \ndiff --git a/apps/docs/content/guides/storage.mdx b/apps/docs/content/guides/storage.mdx\nindex fd840fdec1309..5139bd5873e32 100644\n--- a/apps/docs/content/guides/storage.mdx\n+++ b/apps/docs/content/guides/storage.mdx\n@@ -7,11 +7,64 @@ sidebar_label: 'Overview'\n hideToc: true\n ---\n \n-Supabase Storage makes it simple to upload and serve files of any size, providing a robust framework for file access controls.\n+Supabase Storage is a robust, scalable solution for managing files of any size with fine-grained access controls and optimized delivery. Whether you're storing user-generated content, analytics data, or vector embeddings, Supabase Storage provides specialized bucket types to meet your specific needs.\n \n-## Features\n+## Key features\n \n-You can use Supabase Storage to store images, videos, documents, and any other file type. Serve your assets with a global CDN to reduce latency from over 285 cities globally. Supabase Storage includes a built-in image optimizer, so you can resize and compress your media files on the fly.\n+- **Multi Protocol** - S3 compatible Storage, RESTful API, TUS resumable uploads\n+- **Global CDN** - Serve your assets with lightning-fast performance from over 285 cities worldwide\n+- **Image Optimization** - Resize, compress, and transform media files on the fly with built-in image processing\n+- **Fine-grained Access Control** - Manage file permissions with row-level security and custom policies\n+- **Multiple Bucket Types** - Specialized storage solutions for different use cases\n+\n+## Storage bucket types\n+\n+Supabase Storage offers different bucket types optimized for specific use cases:\n+\n+### Files buckets\n+\n+Store and serve traditional files including images, videos, documents, and general-purpose content. Ideal for user-generated content, media libraries, and asset management.\n+\n+**Use cases:** Images, videos, documents, PDFs, archives\n+\n+**Features:**\n+\n+- Global CDN delivery\n+- Image optimization and transformation\n+- Row-level security integration\n+- Direct URL access for files\n+\n+[Learn more about Files Buckets](/docs/guides/storage/quickstart)\n+\n+### Analytics buckets\n+\n+Purpose-built for storing and analyzing data in open table formats like Apache Iceberg. Perfect for time-series data, logs, and large-scale analytical workloads.\n+\n+**Use cases:** Data lakes, analytics pipelines, ETL operations, historical data analysis\n+\n+**Features:**\n+\n+- Apache Iceberg table format support\n+- SQL-accessible via Postgres foreign tables\n+- Partitioned data organization\n+- Efficient data querying and transformation\n+\n+[Learn more about Analytics Buckets](/docs/guides/storage/analytics/introduction)\n+\n+### Vector buckets\n+\n+Specialized storage for vector embeddings and similarity search operations. Designed for AI and ML applications requiring semantic search capabilities.\n+\n+**Use cases:** AI-powered search, semantic similarity matching, embedding storage, RAG systems\n+\n+**Features:**\n+\n+- Optimized vector indexing (HNSW, Flat)\n+- Multiple distance metrics (cosine, euclidean, L2)\n+- Metadata filtering for vectors\n+- Similarity search queries\n+\n+[Learn more about Vector Buckets](/docs/guides/storage/vector/introduction)\n \n ## Examples\n \ndiff --git a/apps/docs/content/guides/storage/analytics/connecting-to-analytics-bucket.mdx b/apps/docs/content/guides/storage/analytics/connecting-to-analytics-bucket.mdx\nindex b68b367779e19..d5fd6ac718dfd 100644\n--- a/apps/docs/content/guides/storage/analytics/connecting-to-analytics-bucket.mdx\n+++ b/apps/docs/content/guides/storage/analytics/connecting-to-analytics-bucket.mdx\n@@ -1,187 +1,65 @@\n ---\n-title: 'Connecting to Analytics Buckets'\n+title: 'Iceberg Catalog'\n ---\n \n-<Admonition type=\"caution\">\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n \n-This feature is in **Private Alpha**. API stability and backward compatibility are not guaranteed at this stage. Reach out from this [Form](https://forms.supabase.com/analytics-buckets) to request access\n+Expect rapid changes, limited features, and possible breaking updates. [share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n \n </Admonition>\n \n-When interacting with Analytics Buckets, you authenticate against two main services - the Iceberg REST Catalog and the S3-Compatible Storage Endpoint.\n+Analytics buckets require authentication with two distinct services:\n \n-The **Iceberg REST Catalog** acts as the central management system for Iceberg tables. It allows Iceberg clients, such as PyIceberg and Apache Spark, to perform metadata operations including:\n+## Architecture overview\n+\n+**Iceberg REST Catalog** serves as the metadata management system for your Iceberg tables. It enables Iceberg clients such as PyIceberg and Apache Spark to perform critical operations:\n \n - Creating and managing tables and namespaces\n - Tracking schemas and handling schema evolution\n-- Managing partitions and snapshots\n+- Managing partitions and table snapshots\n - Ensuring transactional consistency and isolation\n \n-The REST Catalog itself does not store the actual data. Instead, it stores metadata describing the structure, schema, and partitioning strategy of Iceberg tables.\n-\n-Actual data storage and retrieval operations occur through the separate S3-compatible endpoint, optimized for reading and writing large analytical datasets stored in Parquet files.\n+The REST Catalog only stores metadata describing your data's structure, schema, and partitioning strategy—not the actual data itself.\n \n-## Authentication\n+**S3-Compatible Storage Endpoint** handles the actual data storage and retrieval. It's optimized for reading and writing large analytical datasets stored in Parquet format, separate from the metadata management layer.\n \n-To connect to an Analytics Bucket, you will need\n+## Authentication setup\n \n-- An Iceberg client (Spark, PyIceberg, etc) which supports the REST Catalog interface.\n-- S3 credentials to authenticate your Iceberg client with the underlying S3 Bucket.\n-  To create S3 Credentials go to [**Project Settings > Storage**](/dashboard/project/_/storage/settings), for more information, see the [S3 Authentication Guide](/docs/guides/storage/s3/authentication). We will support other authentication methods in the future.\n+To connect to an analytics bucket, you need:\n \n-- The project reference and Service key for your Supabase project.\n-  You can find your Service key in the Supabase Dashboard under [**Project Settings > API**.](/dashboard/project/_/settings/api-keys)\n+### 1. S3 credentials\n \n-You will now have an **Access Key** and a **Secret Key** that you can use to authenticate your Iceberg client.\n+Create S3 credentials through [**Project Settings > Storage**](/dashboard/project/_/storage/settings). See the [S3 Authentication Guide](/docs/guides/storage/s3/authentication) for detailed instructions.\n \n-## Connecting via PyIceberg\n+You'll obtain:\n \n-PyIceberg is a Python client for Apache Iceberg, facilitating interaction with Iceberg Buckets.\n+- **Access Key ID**\n+- **Secret Access Key**\n+- **Region** (e.g., `us-east-1`)\n \n-**Installation**\n+### 2. Supabase service key\n \n-```bash\n-pip install pyiceberg pyarrow\n-```\n+Retrieve your Service Key from [**Project Settings > API**](/dashboard/project/_/settings/api-keys). This key authenticates requests to the Iceberg REST Catalog.\n \n-Here's a comprehensive example using PyIceberg with clearly separated configuration:\n-\n-```python\n-from pyiceberg.catalog import load_catalog\n-import pyarrow as pa\n-import datetime\n-\n-# Supabase project ref\n-PROJECT_REF = \"<your-supabase-project-ref>\"\n-\n-# Configuration for Iceberg REST Catalog\n-WAREHOUSE = \"your-analytics-bucket-name\"\n-TOKEN = \"SERVICE_KEY\"\n-\n-# Configuration for S3-Compatible Storage\n-S3_ACCESS_KEY = \"KEY\"\n-S3_SECRET_KEY = \"SECRET\"\n-S3_REGION = \"PROJECT_REGION\"\n-\n-S3_ENDPOINT = f\"https://{PROJECT_REF}.supabase.co/storage/v1/s3\"\n-CATALOG_URI = f\"https://{PROJECT_REF}.supabase.co/storage/v1/iceberg\"\n-\n-# Load the Iceberg catalog\n-catalog = load_catalog(\n-    \"analytics-bucket\",\n-    type=\"rest\",\n-    warehouse=WAREHOUSE,\n-    uri=CATALOG_URI,\n-    token=TOKEN,\n-    **{\n-        \"py-io-impl\": \"pyiceberg.io.pyarrow.PyArrowFileIO\",\n-        \"s3.endpoint\": S3_ENDPOINT,\n-        \"s3.access-key-id\": S3_ACCESS_KEY,\n-        \"s3.secret-access-key\": S3_SECRET_KEY,\n-        \"s3.region\": S3_REGION,\n-        \"s3.force-virtual-addressing\": False,\n-    },\n-)\n-\n-# Create namespace if it doesn't exist\n-catalog.create_namespace_if_not_exists(\"default\")\n-\n-# Define schema for your Iceberg table\n-schema = pa.schema([\n-    pa.field(\"event_id\", pa.int64()),\n-    pa.field(\"event_name\", pa.string()),\n-    pa.field(\"event_timestamp\", pa.timestamp(\"ms\")),\n-])\n-\n-# Create table (if it doesn't exist already)\n-table = catalog.create_table_if_not_exists((\"default\", \"events\"), schema=schema)\n-\n-# Generate and insert sample data\n-current_time = datetime.datetime.now()\n-data = pa.table({\n-    \"event_id\": [1, 2, 3],\n-    \"event_name\": [\"login\", \"logout\", \"purchase\"],\n-    \"event_timestamp\": [current_time, current_time, current_time],\n-})\n-\n-# Append data to the Iceberg table\n-table.append(data)\n-\n-# Scan table and print data as pandas DataFrame\n-df = table.scan().to_pandas()\n-print(df)\n-```\n+### 3. Project reference\n \n-## Connecting via Apache Spark\n-\n-Apache Spark allows distributed analytical queries against Iceberg Buckets.\n-\n-```python\n-from pyspark.sql import SparkSession\n-\n-# Supabase project ref\n-PROJECT_REF = \"<your-supabase-ref>\"\n-\n-# Configuration for Iceberg REST Catalog\n-WAREHOUSE = \"your-analytics-bucket-name\"\n-TOKEN = \"SERVICE_KEY\"\n-\n-# Configuration for S3-Compatible Storage\n-S3_ACCESS_KEY = \"KEY\"\n-S3_SECRET_KEY = \"SECRET\"\n-S3_REGION = \"PROJECT_REGION\"\n-\n-S3_ENDPOINT = f\"https://{PROJECT_REF}.supabase.co/storage/v1/s3\"\n-CATALOG_URI = f\"https://{PROJECT_REF}.supabase.co/storage/v1/iceberg\"\n-\n-# Initialize Spark session with Iceberg configuration\n-spark = SparkSession.builder \\\n-    .master(\"local[*]\") \\\n-    .appName(\"SupabaseIceberg\") \\\n-    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n-    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n-    .config('spark.jars.packages', 'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1,org.apache.iceberg:iceberg-aws-bundle:1.6.1') \\\n-    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n-    .config(\"spark.sql.catalog.my_catalog\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n-    .config(\"spark.sql.catalog.my_catalog.type\", \"rest\") \\\n-    .config(\"spark.sql.catalog.my_catalog.uri\", CATALOG_URI) \\\n-    .config(\"spark.sql.catalog.my_catalog.warehouse\", WAREHOUSE) \\\n-    .config(\"spark.sql.catalog.my_catalog.token\", TOKEN) \\\n-    .config(\"spark.sql.catalog.my_catalog.s3.endpoint\", S3_ENDPOINT) \\\n-    .config(\"spark.sql.catalog.my_catalog.s3.path-style-access\", \"true\") \\\n-    .config(\"spark.sql.catalog.my_catalog.s3.access-key-id\", S3_ACCESS_KEY) \\\n-    .config(\"spark.sql.catalog.my_catalog.s3.secret-access-key\", S3_SECRET_KEY) \\\n-    .config(\"spark.sql.catalog.my_catalog.s3.remote-signing-enabled\", \"false\") \\\n-    .config(\"spark.sql.defaultCatalog\", \"my_catalog\") \\\n-    .getOrCreate()\n-\n-# SQL Operations\n-spark.sql(\"CREATE NAMESPACE IF NOT EXISTS analytics\")\n-\n-spark.sql(\"\"\"\n-    CREATE TABLE IF NOT EXISTS analytics.users (\n-        user_id BIGINT,\n-        username STRING\n-    )\n-    USING iceberg\n-\"\"\")\n-\n-spark.sql(\"\"\"\n-    INSERT INTO analytics.users (user_id, username)\n-    VALUES (1, 'Alice'), (2, 'Bob'), (3, 'Charlie')\n-\"\"\")\n-\n-result_df = spark.sql(\"SELECT * FROM analytics.users\")\n-result_df.show()\n-```\n+Your Supabase project reference is the subdomain in your project URL (e.g., `your-project-ref` in `https://your-project-ref.supabase.co`).\n \n-## Connecting to the Iceberg REST Catalog directly\n+## Testing your connection\n \n-To authenticate with the Iceberg REST Catalog directly, you need to provide a valid Supabase **Service key** as a Bearer token.\n+You can verify your setup by making a direct request to the Iceberg REST Catalog. Provide your Service Key as a Bearer token:\n \n-```\n+```bash\n curl \\\n   --request GET -sL \\\n-  --url 'https://<your-supabase-project>.supabase.co/storage/v1/iceberg/v1/config?warehouse=<bucket-name>' \\\n+  --url 'https://<your-project-ref>.supabase.co/storage/v1/iceberg/v1/config?warehouse=<bucket-name>' \\\n   --header 'Authorization: Bearer <your-service-key>'\n ```\n+\n+A successful response returns the catalog configuration including warehouse location and settings.\n+\n+## Next steps\n+\n+- [Connect with PyIceberg](/docs/guides/storage/analytics/examples/pyiceberg)\n+- [Connect with Apache Spark](/docs/guides/storage/analytics/examples/apache-spark)\n+- [Query with Postgres](/docs/guides/storage/analytics/query-with-postgres)\ndiff --git a/apps/docs/content/guides/storage/analytics/creating-analytics-buckets.mdx b/apps/docs/content/guides/storage/analytics/creating-analytics-buckets.mdx\nindex 16f0b3831a0d4..d22a283f4b811 100644\n--- a/apps/docs/content/guides/storage/analytics/creating-analytics-buckets.mdx\n+++ b/apps/docs/content/guides/storage/analytics/creating-analytics-buckets.mdx\n@@ -1,41 +1,50 @@\n ---\n title: 'Creating Analytics Buckets'\n-subtitle: ''\n+subtitle: 'Set up your first analytics bucket using the SDK or dashboard.'\n ---\n \n <Admonition type=\"caution\">\n \n-This feature is in **Private Alpha**. API stability and backward compatibility are not guaranteed at this stage. Reach out from this [Form](https://forms.supabase.com/analytics-buckets) to request access\n+This feature is in **Private Alpha**. API stability and backward compatibility are not guaranteed at this stage. Request access through this [form](https://forms.supabase.com/analytics-buckets).\n \n </Admonition>\n \n-Analytics Buckets use [Apache Iceberg](https://iceberg.apache.org/), an open-table format for managing large analytical datasets.\n-You can interact with them using tools such as [PyIceberg](https://py.iceberg.apache.org/), [Apache Spark](https://spark.apache.org/) or any client which supports the [standard Iceberg REST Catalog API](https://editor-next.swagger.io/?url=https://raw.githubusercontent.com/apache/iceberg/main/open-api/rest-catalog-open-api.yaml).\n+Analytics buckets use [Apache Iceberg](https://iceberg.apache.org/), an open-table format for efficient management of large analytical datasets. You can interact with analytics buckets using tools such as [PyIceberg](https://py.iceberg.apache.org/), [Apache Spark](https://spark.apache.org/), or any client supporting the [Iceberg REST Catalog API](https://editor-next.swagger.io/?url=https://raw.githubusercontent.com/apache/iceberg/main/open-api/rest-catalog-open-api.yaml).\n \n-You can create an Analytics Bucket using either the Supabase SDK or the Supabase Dashboard.\n+## Creating an Analytics bucket\n+\n+You can create an analytics bucket using either the Supabase SDK or the Supabase Dashboard.\n \n ### Using the Supabase SDK\n \n-{/* prettier-ignore */}\n ```ts\n import { createClient } from '@supabase/supabase-js'\n \n-const supabase = createClient(\n-  'https://your-project.supabase.co',\n-  'publishable-or-anon-key'\n-)\n+const supabase = createClient('https://your-project.supabase.co', 'your-service-key')\n+\n+const { data, error } = await supabase.storage.analytics.createBucket('analytics-data')\n \n-const { data, error } =\n-  await supabase.storage.analytics.createBucket('analytics-data')\n+if (error) {\n+  console.error('Failed to create analytics bucket:', error)\n+} else {\n+  console.log('Analytics bucket created:', data)\n+}\n ```\n \n ### Using the Supabase Dashboard\n \n-1. Navigate to the Storage section in the Supabase Dashboard.\n-2. Click on \"Create Bucket\".\n-3. Enter a name for your bucket (e.g., my-analytics-bucket).\n-4. Select \"Analytics Bucket\" as the bucket type.\n+1. Navigate to the **Storage** section in the Supabase Dashboard.\n+2. Click **Create Bucket**.\n+3. Enter a name for your bucket (e.g., `my-analytics-bucket`).\n+4. Select **Analytics Bucket** as the bucket type.\n+5. Click **Create**.\n+\n+<img alt=\"Create Analytics Bucket in Dashboard\" src=\"/docs/img/storage/iceberg-bucket.png\" />\n+\n+## Next steps\n \n-<img alt=\"Storage schema design\" src=\"/docs/img/storage/iceberg-bucket.png\" />\n+Once you've created your analytics bucket, you can:\n \n-Now, that you have created your Analytics Bucket, you can start [connecting to it](/docs/guides/storage/analytics/connecting-to-analytics-bucket) with Iceberg clients like PyIceberg or Apache Spark.\n+- [Connect with Iceberg clients](/docs/guides/storage/analytics/connecting-to-analytics-bucket) like PyIceberg or Apache Spark\n+- [Set up real-time replication](/docs/guides/storage/analytics/etl) from your Postgres database\n+- [Query data with Postgres](/docs/guides/storage/analytics/query-with-postgres) using the Iceberg Foreign Data Wrapper\ndiff --git a/apps/docs/content/guides/storage/analytics/etl.mdx b/apps/docs/content/guides/storage/analytics/etl.mdx\nnew file mode 100644\nindex 0000000000000..34f89f96383a3\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/analytics/etl.mdx\n@@ -0,0 +1,81 @@\n+---\n+title: 'Realtime Data Sync to Analytics Buckets'\n+subtitle: 'Replicate your PostgreSQL data to analytics buckets in real-time.'\n+---\n+\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n+\n+Expect rapid changes, limited features, and possible breaking updates. [Share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n+\n+</Admonition>\n+\n+By combining Supabase's **ETL service** with **Analytics Buckets**, you can build an end-to-end data warehouse solution that automatically syncs changes from your Postgres database to Iceberg tables.\n+\n+## How it works\n+\n+The ETL pipeline captures changes (INSERT, UPDATE, DELETE) from your Postgres database in real-time and writes them to your analytics bucket. This allows you to maintain an always-up-to-date data warehouse without impacting your production workloads.\n+\n+## Setup steps\n+\n+### Step 1: Create an Analytics bucket\n+\n+First, create a new analytics bucket to store your replicated data:\n+\n+1. Navigate to **Storage** in the Supabase Dashboard.\n+2. Click **Create Bucket**.\n+3. Enter a name (e.g., `my-warehouse`).\n+4. Select **Analytics Bucket** as the type.\n+5. Click **Create**.\n+\n+<Image\n+  alt=\"Creating a new analytics bucket\"\n+  src=\"/docs/img/database/replication/etl-iceberg-new-bucket.png\"\n+  zoomable\n+/>\n+\n+### Step 2: Create a publication\n+\n+A publication defines which tables and change types will be replicated. Create one using SQL in the Supabase SQL Editor:\n+\n+```sql\n+-- Create publication for tables you want to replicate\n+CREATE PUBLICATION pub_warehouse\n+  FOR TABLE users, orders, products;\n+```\n+\n+This publication will track all changes (INSERT, UPDATE, DELETE) for the specified tables. For advanced use cases, see the [Replication Configuration Guide](/docs/guides/database/replication/etl-replication-setup).\n+\n+### Step 3: Create the ETL pipeline\n+\n+Now set up the pipeline to sync data to your analytics bucket:\n+\n+1. Navigate to **Database > Replication** in the Supabase Dashboard.\n+2. Click **Create Pipeline**.\n+3. Select the **Publication** you created in Step 2.\n+4. Select your **Analytics Bucket** as the destination.\n+5. Configure any additional settings as needed.\n+6. Click **Create and Start**.\n+\n+<Image\n+  alt=\"ETL pipeline configuration\"\n+  src=\"/docs/img/database/replication/etl-iceberg-details.png\"\n+  zoomable\n+/>\n+\n+## Monitoring your pipeline\n+\n+Once started, you can monitor the pipeline status directly in the **Database > Replication** section:\n+\n+- **Status** - Shows if the pipeline is running, paused, or encountered errors\n+- **Sync Progress** - View the number of records replicated\n+- **Logs** - Check detailed logs for troubleshooting\n+\n+## Next steps\n+\n+Once data is flowing to your analytics bucket, you can:\n+\n+- [Query with SQL via Postgres](/docs/guides/storage/analytics/query-with-postgres)\n+- [Connect with PyIceberg](/docs/guides/storage/analytics/examples/pyiceberg)\n+- [Analyze with Apache Spark](/docs/guides/storage/analytics/examples/apache-spark)\n+\n+For advanced topics, see the [ETL Replication Monitoring Guide](/docs/guides/database/replication/etl-replication-monitoring).\ndiff --git a/apps/docs/content/guides/storage/analytics/examples/apache-spark.mdx b/apps/docs/content/guides/storage/analytics/examples/apache-spark.mdx\nnew file mode 100644\nindex 0000000000000..845b88ff469f1\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/analytics/examples/apache-spark.mdx\n@@ -0,0 +1,265 @@\n+---\n+title: 'Apache Spark'\n+---\n+\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n+\n+Expect rapid changes, limited features, and possible breaking updates. [Share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n+\n+</Admonition>\n+\n+Apache Spark enables distributed analytical processing of large datasets stored in your analytics buckets. Use it for complex transformations, aggregations, and machine learning workflows.\n+\n+## Installation\n+\n+First, ensure you have Spark installed. For Python-based workflows:\n+\n+```bash\n+pip install pyspark\n+```\n+\n+For detailed Spark setup instructions, see the [Apache Spark documentation](https://spark.apache.org/docs/latest/).\n+\n+## Basic setup\n+\n+Here's a complete example showing how to configure Spark with your Supabase analytics bucket:\n+\n+```python\n+from pyspark.sql import SparkSession\n+\n+# Configuration - Update with your Supabase credentials\n+PROJECT_REF = \"your-project-ref\"\n+WAREHOUSE = \"your-analytics-bucket-name\"\n+SERVICE_KEY = \"your-service-key\"\n+\n+# S3 credentials from Project Settings > Storage\n+S3_ACCESS_KEY = \"your-access-key\"\n+S3_SECRET_KEY = \"your-secret-key\"\n+S3_REGION = \"us-east-1\"\n+\n+# Construct Supabase endpoints\n+S3_ENDPOINT = f\"https://{PROJECT_REF}.supabase.co/storage/v1/s3\"\n+CATALOG_URI = f\"https://{PROJECT_REF}.supabase.co/storage/v1/iceberg\"\n+\n+# Initialize Spark session with Iceberg configuration\n+spark = SparkSession.builder \\\n+    .master(\"local[*]\") \\\n+    .appName(\"SupabaseIceberg\") \\\n+    .config(\"spark.driver.host\", \"127.0.0.1\") \\\n+    .config(\"spark.driver.bindAddress\", \"127.0.0.1\") \\\n+    .config(\n+        'spark.jars.packages',\n+        'org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1,org.apache.iceberg:iceberg-aws-bundle:1.6.1'\n+    ) \\\n+    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n+    .config(\"spark.sql.catalog.supabase\", \"org.apache.iceberg.spark.SparkCatalog\") \\\n+    .config(\"spark.sql.catalog.supabase.type\", \"rest\") \\\n+    .config(\"spark.sql.catalog.supabase.uri\", CATALOG_URI) \\\n+    .config(\"spark.sql.catalog.supabase.warehouse\", WAREHOUSE) \\\n+    .config(\"spark.sql.catalog.supabase.token\", SERVICE_KEY) \\\n+    .config(\"spark.sql.catalog.supabase.s3.endpoint\", S3_ENDPOINT) \\\n+    .config(\"spark.sql.catalog.supabase.s3.path-style-access\", \"true\") \\\n+    .config(\"spark.sql.catalog.supabase.s3.access-key-id\", S3_ACCESS_KEY) \\\n+    .config(\"spark.sql.catalog.supabase.s3.secret-access-key\", S3_SECRET_KEY) \\\n+    .config(\"spark.sql.catalog.supabase.s3.remote-signing-enabled\", \"false\") \\\n+    .config(\"spark.sql.defaultCatalog\", \"supabase\") \\\n+    .getOrCreate()\n+\n+print(\"✓ Spark session initialized with Iceberg\")\n+```\n+\n+## Creating tables\n+\n+```python\n+# Create a namespace for organization\n+spark.sql(\"CREATE NAMESPACE IF NOT EXISTS analytics\")\n+\n+# Create a new Iceberg table\n+spark.sql(\"\"\"\n+    CREATE TABLE IF NOT EXISTS analytics.events (\n+        event_id BIGINT,\n+        user_id BIGINT,\n+        event_name STRING,\n+        event_timestamp TIMESTAMP,\n+        properties STRING\n+    )\n+    USING iceberg\n+\"\"\")\n+\n+print(\"✓ Created table: analytics.events\")\n+```\n+\n+## Writing data\n+\n+```python\n+# Insert data into the table\n+spark.sql(\"\"\"\n+    INSERT INTO analytics.events (event_id, user_id, event_name, event_timestamp, properties)\n+    VALUES\n+        (1, 101, 'login', TIMESTAMP '2024-01-15 10:30:00', '{\"browser\":\"chrome\"}'),\n+        (2, 102, 'view_product', TIMESTAMP '2024-01-15 10:35:00', '{\"product_id\":\"123\"}'),\n+        (3, 101, 'logout', TIMESTAMP '2024-01-15 10:40:00', '{}'),\n+        (4, 103, 'purchase', TIMESTAMP '2024-01-15 10:45:00', '{\"amount\":99.99}')\n+\"\"\")\n+\n+print(\"✓ Inserted 4 rows into analytics.events\")\n+```\n+\n+## Reading data\n+\n+```python\n+# Read the entire table\n+result_df = spark.sql(\"SELECT * FROM analytics.events\")\n+result_df.show(truncate=False)\n+\n+# Apply filters\n+filtered_df = spark.sql(\"\"\"\n+    SELECT event_id, user_id, event_name\n+    FROM analytics.events\n+    WHERE event_name = 'login'\n+\"\"\")\n+filtered_df.show()\n+\n+# Aggregations\n+summary_df = spark.sql(\"\"\"\n+    SELECT\n+        event_name,\n+        COUNT(*) as event_count,\n+        COUNT(DISTINCT user_id) as unique_users\n+    FROM analytics.events\n+    GROUP BY event_name\n+    ORDER BY event_count DESC\n+\"\"\")\n+summary_df.show()\n+```\n+\n+## Advanced operations\n+\n+### Working with dataframes\n+\n+```python\n+# Read as DataFrame\n+events_df = spark.read.format(\"iceberg\").load(\"analytics.events\")\n+\n+# Apply Spark transformations\n+from pyspark.sql.functions import count, col, year, month\n+\n+# Monthly event counts\n+monthly_events = events_df \\\n+    .withColumn(\"month\", month(col(\"event_timestamp\"))) \\\n+    .withColumn(\"year\", year(col(\"event_timestamp\"))) \\\n+    .groupBy(\"year\", \"month\", \"event_name\") \\\n+    .agg(count(\"event_id\").alias(\"count\")) \\\n+    .orderBy(\"year\", \"month\")\n+\n+monthly_events.show()\n+```\n+\n+### Joining tables\n+\n+```python\n+# Create another table\n+spark.sql(\"\"\"\n+    CREATE TABLE IF NOT EXISTS analytics.users (\n+        user_id BIGINT,\n+        username STRING,\n+        email STRING\n+    )\n+    USING iceberg\n+\"\"\")\n+\n+spark.sql(\"\"\"\n+    INSERT INTO analytics.users VALUES\n+        (101, 'alice', 'alice@example.com'),\n+        (102, 'bob', 'bob@example.com'),\n+        (103, 'charlie', 'charlie@example.com')\n+\"\"\")\n+\n+# Join events with users\n+joined_df = spark.sql(\"\"\"\n+    SELECT\n+        e.event_id,\n+        e.event_name,\n+        u.username,\n+        u.email,\n+        e.event_timestamp\n+    FROM analytics.events e\n+    JOIN analytics.users u ON e.user_id = u.user_id\n+    ORDER BY e.event_timestamp\n+\"\"\")\n+\n+joined_df.show(truncate=False)\n+```\n+\n+### Exporting results\n+\n+```python\n+# Export to Parquet\n+spark.sql(\"\"\"\n+    SELECT event_name, COUNT(*) as count\n+    FROM analytics.events\n+    GROUP BY event_name\n+\"\"\").write \\\n+    .mode(\"overwrite\") \\\n+    .parquet(\"/tmp/event_summary.parquet\")\n+\n+# Export to CSV\n+spark.sql(\"\"\"\n+    SELECT *\n+    FROM analytics.events\n+    WHERE event_timestamp > TIMESTAMP '2024-01-15 10:30:00'\n+\"\"\").write \\\n+    .mode(\"overwrite\") \\\n+    .option(\"header\", \"true\") \\\n+    .csv(\"/tmp/recent_events.csv\")\n+\n+print(\"✓ Results exported\")\n+```\n+\n+## Performance best practices\n+\n+- **Partition tables** - Partition large tables by date or region for faster queries\n+- **Select columns** - Only select columns you need to reduce I/O\n+- **Use filters early** - Apply WHERE clauses to reduce data processed\n+- **Cache frequently accessed tables** - Use `spark.catalog.cacheTable()` for tables accessed multiple times\n+- **Cluster mode** - Use cluster mode for production workloads instead of local mode\n+\n+## Complete example: Data processing pipeline\n+\n+```python\n+from pyspark.sql import SparkSession\n+from pyspark.sql.functions import col, year, month, count\n+\n+# Setup (see Basic Setup section above)\n+spark = SparkSession.builder \\\n+    .master(\"local[*]\") \\\n+    .appName(\"SupabaseAnalytics\") \\\n+    .config(\"spark.sql.defaultCatalog\", \"supabase\") \\\n+    # ... (add all config from Basic Setup)\n+    .getOrCreate()\n+\n+# Step 1: Read raw events\n+raw_events = spark.sql(\"SELECT * FROM analytics.events\")\n+\n+# Step 2: Transform and aggregate\n+monthly_summary = raw_events \\\n+    .withColumn(\"month\", month(col(\"event_timestamp\"))) \\\n+    .withColumn(\"year\", year(col(\"event_timestamp\"))) \\\n+    .groupBy(\"year\", \"month\", \"event_name\") \\\n+    .agg(count(\"event_id\").alias(\"total_events\"))\n+\n+# Step 3: Save results\n+monthly_summary.write \\\n+    .mode(\"overwrite\") \\\n+    .option(\"path\", \"analytics.monthly_summary\") \\\n+    .saveAsTable(\"analytics.monthly_summary\")\n+\n+print(\"✓ Pipeline completed\")\n+monthly_summary.show()\n+```\n+\n+## Next steps\n+\n+- [Query with Postgres](/docs/guides/storage/analytics/query-with-postgres)\n+- [Connect with PyIceberg](/docs/guides/storage/analytics/examples/pyiceberg)\n+- [Explore with DuckDB](/docs/guides/storage/analytics/examples/duckdb)\ndiff --git a/apps/docs/content/guides/storage/analytics/examples/duckdb.mdx b/apps/docs/content/guides/storage/analytics/examples/duckdb.mdx\nnew file mode 100644\nindex 0000000000000..e622c94d0d201\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/analytics/examples/duckdb.mdx\n@@ -0,0 +1,158 @@\n+---\n+title: 'DuckDB'\n+---\n+\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n+\n+Expect rapid changes, limited features, and possible breaking updates. [Share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n+\n+</Admonition>\n+\n+DuckDB is a high-performance SQL database system optimized for analytical workloads. It can directly query Iceberg tables stored in your analytics buckets, making it ideal for data exploration and complex analytical queries.\n+\n+## Installation\n+\n+Install DuckDB and the Iceberg extension:\n+\n+```bash\n+pip install duckdb duckdb-iceberg\n+```\n+\n+## Connecting to Analytics buckets\n+\n+Here's a complete example of connecting to your Supabase analytics bucket and querying Iceberg tables:\n+\n+```python\n+import duckdb\n+import os\n+\n+# Configuration\n+PROJECT_REF = \"your-project-ref\"\n+WAREHOUSE = \"your-analytics-bucket-name\"\n+SERVICE_KEY = \"your-service-key\"\n+\n+# S3 credentials\n+S3_ACCESS_KEY = \"your-access-key\"\n+S3_SECRET_KEY = \"your-secret-key\"\n+S3_REGION = \"us-east-1\"\n+\n+# Construct endpoints\n+S3_ENDPOINT = f\"https://{PROJECT_REF}.supabase.co/storage/v1/s3\"\n+CATALOG_URI = f\"https://{PROJECT_REF}.supabase.co/storage/v1/iceberg\"\n+\n+# Initialize DuckDB connection\n+conn = duckdb.connect(\":memory:\")\n+\n+# Install and load the Iceberg extension\n+conn.install_extension(\"iceberg\")\n+conn.load_extension(\"iceberg\")\n+\n+# Configure Iceberg catalog with Supabase credentials\n+conn.execute(f\"\"\"\n+    CREATE SECRET (\n+        TYPE S3,\n+        KEY_ID '{S3_ACCESS_KEY}',\n+        SECRET '{S3_SECRET_KEY}',\n+        REGION '{S3_REGION}',\n+        ENDPOINT '{S3_ENDPOINT}',\n+        URL_STYLE 'virtual'\n+    );\n+\"\"\")\n+\n+# Configure the REST catalog\n+conn.execute(f\"\"\"\n+    ATTACH 'iceberg://{CATALOG_URI}' AS iceberg_catalog\n+    (\n+        TYPE ICEBERG_REST,\n+        WAREHOUSE '{WAREHOUSE}',\n+        TOKEN '{SERVICE_KEY}'\n+    );\n+\"\"\")\n+\n+# Query your Iceberg tables\n+result = conn.execute(\"\"\"\n+    SELECT *\n+    FROM iceberg_catalog.default.events\n+    LIMIT 10\n+\"\"\").fetchall()\n+\n+for row in result:\n+    print(row)\n+\n+# Complex aggregation example\n+analytics = conn.execute(\"\"\"\n+    SELECT\n+        event_name,\n+        COUNT(*) as event_count,\n+        COUNT(DISTINCT user_id) as unique_users\n+    FROM iceberg_catalog.default.events\n+    GROUP BY event_name\n+    ORDER BY event_count DESC\n+\"\"\").fetchdf()\n+\n+print(analytics)\n+```\n+\n+## Key features with DuckDB\n+\n+### Efficient data exploration\n+\n+DuckDB's lazy evaluation means it only scans the data you need:\n+\n+```python\n+# This only reads the columns you select\n+events = conn.execute(\"\"\"\n+    SELECT event_id, event_name, event_timestamp\n+    FROM iceberg_catalog.default.events\n+    WHERE event_timestamp > NOW() - INTERVAL '7 days'\n+\"\"\").fetchdf()\n+```\n+\n+### Converting to Pandas\n+\n+Convert results to Pandas DataFrames for further analysis:\n+\n+```python\n+df = conn.execute(\"\"\"\n+    SELECT *\n+    FROM iceberg_catalog.default.events\n+\"\"\").fetchdf()\n+\n+# Use pandas for visualization or further processing\n+print(df.describe())\n+```\n+\n+### Exporting results\n+\n+Save your analytical results to various formats:\n+\n+```python\n+# Export to Parquet\n+conn.execute(\"\"\"\n+    COPY (\n+        SELECT * FROM iceberg_catalog.default.events\n+    ) TO 'results.parquet'\n+\"\"\")\n+\n+# Export to CSV\n+conn.execute(\"\"\"\n+    COPY (\n+        SELECT event_name, COUNT(*) as count\n+        FROM iceberg_catalog.default.events\n+        GROUP BY event_name\n+    ) TO 'summary.csv' (FORMAT CSV, HEADER true)\n+\"\"\")\n+```\n+\n+## Best practices\n+\n+- **Connection pooling** - Reuse connections for multiple queries\n+- **Partition pruning** - Filter by partition columns to improve query performance\n+- **Column selection** - Only select columns you need to reduce I/O\n+- **Limit results** - Use LIMIT during exploration to avoid processing large datasets\n+\n+## Next steps\n+\n+- [Query with Postgres](/docs/guides/storage/analytics/query-with-postgres)\n+- [Connect with PyIceberg](/docs/guides/storage/analytics/examples/pyiceberg)\n+- [Analyze with Apache Spark](/docs/guides/storage/analytics/examples/apache-spark)\ndiff --git a/apps/docs/content/guides/storage/analytics/examples/pyiceberg.mdx b/apps/docs/content/guides/storage/analytics/examples/pyiceberg.mdx\nnew file mode 100644\nindex 0000000000000..200d39321ccf5\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/analytics/examples/pyiceberg.mdx\n@@ -0,0 +1,223 @@\n+---\n+title: 'PyIceberg'\n+---\n+\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n+\n+Expect rapid changes, limited features, and possible breaking updates. [Share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n+\n+</Admonition>\n+\n+PyIceberg is a Python client for Apache Iceberg that enables programmatic interaction with Iceberg tables. Use it to create, read, update, and delete data in your analytics buckets.\n+\n+## Installation\n+\n+```bash\n+pip install pyiceberg pyarrow\n+```\n+\n+## Basic setup\n+\n+Here's a complete example showing how to connect to your Supabase analytics bucket and perform operations:\n+\n+```python\n+from pyiceberg.catalog import load_catalog\n+import pyarrow as pa\n+import datetime\n+\n+# Configuration - Update with your Supabase credentials\n+PROJECT_REF = \"your-project-ref\"\n+WAREHOUSE = \"your-analytics-bucket-name\"\n+SERVICE_KEY = \"your-service-key\"\n+\n+# S3 credentials from Project Settings > Storage\n+S3_ACCESS_KEY = \"your-access-key\"\n+S3_SECRET_KEY = \"your-secret-key\"\n+S3_REGION = \"us-east-1\"\n+\n+# Construct Supabase endpoints\n+S3_ENDPOINT = f\"https://{PROJECT_REF}.supabase.co/storage/v1/s3\"\n+CATALOG_URI = f\"https://{PROJECT_REF}.supabase.co/storage/v1/iceberg\"\n+\n+# Load the Iceberg REST Catalog\n+catalog = load_catalog(\n+    \"supabase-analytics\",\n+    type=\"rest\",\n+    warehouse=WAREHOUSE,\n+    uri=CATALOG_URI,\n+    token=SERVICE_KEY,\n+    **{\n+        \"py-io-impl\": \"pyiceberg.io.pyarrow.PyArrowFileIO\",\n+        \"s3.endpoint\": S3_ENDPOINT,\n+        \"s3.access-key-id\": S3_ACCESS_KEY,\n+        \"s3.secret-access-key\": S3_SECRET_KEY,\n+        \"s3.region\": S3_REGION,\n+        \"s3.force-virtual-addressing\": False,\n+    },\n+)\n+\n+print(\"✓ Successfully connected to Iceberg catalog\")\n+```\n+\n+## Creating tables\n+\n+```python\n+# Create a namespace for organization\n+catalog.create_namespace_if_not_exists(\"analytics\")\n+\n+# Define the schema for your Iceberg table\n+schema = pa.schema([\n+    pa.field(\"event_id\", pa.int64()),\n+    pa.field(\"user_id\", pa.int64()),\n+    pa.field(\"event_name\", pa.string()),\n+    pa.field(\"event_timestamp\", pa.timestamp(\"ms\")),\n+    pa.field(\"properties\", pa.string()),\n+])\n+\n+# Create the table\n+table = catalog.create_table_if_not_exists(\n+    (\"analytics\", \"events\"),\n+    schema=schema\n+)\n+\n+print(\"✓ Created table: analytics.events\")\n+```\n+\n+## Writing data\n+\n+```python\n+import datetime\n+\n+# Prepare your data\n+current_time = datetime.datetime.now()\n+data = pa.table({\n+    \"event_id\": [1, 2, 3, 4, 5],\n+    \"user_id\": [101, 102, 101, 103, 102],\n+    \"event_name\": [\"login\", \"view_product\", \"logout\", \"purchase\", \"login\"],\n+    \"event_timestamp\": [current_time] * 5,\n+    \"properties\": [\n+        '{\"browser\":\"chrome\"}',\n+        '{\"product_id\":\"123\"}',\n+        '{}',\n+        '{\"amount\":99.99}',\n+        '{\"browser\":\"firefox\"}'\n+    ],\n+})\n+\n+# Append data to the table\n+table.append(data)\n+print(\"✓ Appended 5 rows to analytics.events\")\n+```\n+\n+## Reading data\n+\n+```python\n+# Scan the entire table\n+scan_result = table.scan().to_pandas()\n+print(f\"Total rows: {len(scan_result)}\")\n+print(scan_result.head())\n+\n+# Query with filters\n+filtered = table.scan(\n+    filter=\"event_name = 'login'\"\n+).to_pandas()\n+print(f\"Login events: {len(filtered)}\")\n+\n+# Select specific columns\n+selected = table.scan(\n+    selected_fields=[\"user_id\", \"event_name\", \"event_timestamp\"]\n+).to_pandas()\n+print(selected.head())\n+```\n+\n+## Advanced operations\n+\n+### Listing tables and namespaces\n+\n+```python\n+# List all namespaces\n+namespaces = catalog.list_namespaces()\n+print(\"Namespaces:\", namespaces)\n+\n+# List tables in a namespace\n+tables = catalog.list_tables(\"analytics\")\n+print(\"Tables in analytics:\", tables)\n+\n+# Get table metadata\n+table_metadata = catalog.load_table((\"analytics\", \"events\"))\n+print(\"Schema:\", table_metadata.schema())\n+print(\"Partitions:\", table_metadata.partitions())\n+```\n+\n+### Handling errors\n+\n+```python\n+try:\n+    # Attempt to load a table\n+    table = catalog.load_table((\"analytics\", \"nonexistent\"))\n+except Exception as e:\n+    print(f\"Error loading table: {e}\")\n+\n+# Check if table exists before creating\n+namespace = \"analytics\"\n+table_name = \"events\"\n+\n+try:\n+    existing_table = catalog.load_table((namespace, table_name))\n+    print(f\"Table already exists\")\n+except Exception:\n+    print(f\"Table does not exist, creating...\")\n+    table = catalog.create_table((namespace, table_name), schema=schema)\n+```\n+\n+## Performance tips\n+\n+- **Batch writes** - Insert data in batches rather than row-by-row for better performance\n+- **Partition strategies** - Use partitioning for large tables to improve query performance\n+- **Schema evolution** - PyIceberg supports schema changes without rewriting data\n+- **Data format** - Use Parquet for efficient columnar storage\n+\n+## Complete example: ETL pipeline\n+\n+```python\n+from pyiceberg.catalog import load_catalog\n+import pyarrow as pa\n+import pandas as pd\n+\n+# Setup (see Basic Setup section above)\n+catalog = load_catalog(...)\n+\n+# Step 1: Create analytics namespace\n+catalog.create_namespace_if_not_exists(\"warehouse\")\n+\n+# Step 2: Define table schema\n+schema = pa.schema([\n+    pa.field(\"id\", pa.int64()),\n+    pa.field(\"name\", pa.string()),\n+    pa.field(\"created_at\", pa.timestamp(\"ms\")),\n+])\n+\n+# Step 3: Create table\n+table = catalog.create_table_if_not_exists(\n+    (\"warehouse\", \"products\"),\n+    schema=schema\n+)\n+\n+# Step 4: Load data from CSV or database\n+df = pd.read_csv(\"products.csv\")\n+data = pa.Table.from_pandas(df)\n+\n+# Step 5: Write to analytics bucket\n+table.append(data)\n+print(f\"✓ Loaded {len(data)} products to warehouse.products\")\n+\n+# Step 6: Verify\n+result = table.scan().to_pandas()\n+print(result.describe())\n+```\n+\n+## Next steps\n+\n+- [Query with Postgres](/docs/guides/storage/analytics/query-with-postgres)\n+- [Analyze with Apache Spark](/docs/guides/storage/analytics/examples/apache-spark)\n+- [Explore with DuckDB](/docs/guides/storage/analytics/examples/duckdb)\ndiff --git a/apps/docs/content/guides/storage/analytics/introduction.mdx b/apps/docs/content/guides/storage/analytics/introduction.mdx\nindex 0f4249efe972b..9c15769def8ac 100644\n--- a/apps/docs/content/guides/storage/analytics/introduction.mdx\n+++ b/apps/docs/content/guides/storage/analytics/introduction.mdx\n@@ -1,24 +1,34 @@\n ---\n title: 'Analytics Buckets'\n-subtitle: ''\n+subtitle: 'Store large datasets for analytics and reporting.'\n ---\n \n-<Admonition type=\"caution\">\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n \n-This feature is in **Private Alpha**. API stability and backward compatibility are not guaranteed at this stage. Reach out from this [Form](https://forms.supabase.com/analytics-buckets) to request access\n+Expect rapid changes, limited features, and possible breaking updates. [share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n \n </Admonition>\n \n-**Analytics Buckets** are designed for analytical workflows on large datasets without impacting your main database.\n+Analytics buckets enable analytical workflows on large-scale datasets while keeping your primary database optimized for transactional operations.\n \n-Postgres tables are optimized for handling real-time, transactional workloads with frequent inserts, updates, deletes and low-latency queries. **Analytical workloads** have very different requirements: processing large volumes of historical data, running complex queries and aggregations, minimizing storage costs, and ensuring these analytical queries do not interfere with the production traffic.\n+## Why Analytics buckets?\n \n-**Analytics Buckets** address these requirements using [Apache Iceberg](https://iceberg.apache.org/), an open-table format for managing large analytical datasets efficiently.\n+Postgres tables are purpose-built for transactional workloads with frequent inserts, updates, deletes, and low-latency queries. Analytical workloads have fundamentally different requirements:\n \n-Analytics Buckets are ideal for\n-• Data warehousing and business intelligence\n-• Historical data archiving\n-• Periodically refreshed real-time analytics\n-• Complex analytical queries over large datasets\n+- Processing large volumes of historical data\n+- Running complex queries and aggregations\n+- Minimizing storage costs\n+- Preventing analytical queries from impacting production traffic\n \n-By separating transactional and analytical workloads, Supabase makes it easy to build scalable analytics pipelines without impacting your primary Postgres performance.\n+Analytics buckets address these requirements using [Apache Iceberg](https://iceberg.apache.org/), an open-table format specifically designed for efficient management of large analytical datasets.\n+\n+## Ideal use cases\n+\n+Analytics buckets are perfect for:\n+\n+- **Data warehousing and business intelligence** - Build scalable data warehouses for BI tools\n+- **Historical data archiving** - Retain large volumes of historical data cost-effectively\n+- **Periodically refreshed analytics** - Maintain near real-time analytical views\n+- **Complex analytical queries** - Execute sophisticated aggregations and joins over large datasets\n+\n+By separating transactional and analytical workloads, Supabase lets you build scalable analytics pipelines without compromising your primary Postgres performance.\ndiff --git a/apps/docs/content/guides/storage/analytics/limits.mdx b/apps/docs/content/guides/storage/analytics/limits.mdx\nindex 0eac0b0f57ca5..3e4ca58b94883 100644\n--- a/apps/docs/content/guides/storage/analytics/limits.mdx\n+++ b/apps/docs/content/guides/storage/analytics/limits.mdx\n@@ -3,21 +3,16 @@ title: 'Analytics Buckets Limits'\n subtitle: ''\n ---\n \n-<Admonition type=\"caution\">\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n \n-This feature is in **Private Alpha**. API stability and backward compatibility are not guaranteed at this stage. Reach out from this [Form](https://forms.supabase.com/analytics-buckets) to request access\n+Expect rapid changes, limited features, and possible breaking updates. [share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n \n </Admonition>\n \n-The following default limits are applied when this feature is in the private alpha stage, they can be adjusted on a case-by-case basis:\n+The following default limits are applied when this feature is in the alpha stage, they can be adjusted on a case-by-case basis:\n \n | **Category**                            | **Limit** |\n | --------------------------------------- | --------- |\n-| Number of Analytics Buckets per project | 2         |\n+| Number of analytics buckets per project | 2         |\n | Number of namespaces per bucket         | 10        |\n | Number of tables per namespace          | 10        |\n-\n-## Pricing\n-\n-Analytics Buckets are Free to use during the Private Alpha phase,\n-however, you'll still be charged for the underlying egress.\ndiff --git a/apps/docs/content/guides/storage/analytics/pricing.mdx b/apps/docs/content/guides/storage/analytics/pricing.mdx\nnew file mode 100644\nindex 0000000000000..f9c45a45b7b2b\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/analytics/pricing.mdx\n@@ -0,0 +1,12 @@\n+---\n+title: 'Analytics Buckets Pricing'\n+subtitle: ''\n+---\n+\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n+\n+Expect rapid changes, limited features, and possible breaking updates. [share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n+\n+</Admonition>\n+\n+Analytics buckets are **free** to use during the alpha phase. You will still be charged for the underlying egress.\ndiff --git a/apps/docs/content/guides/storage/analytics/query-with-postgres.mdx b/apps/docs/content/guides/storage/analytics/query-with-postgres.mdx\nnew file mode 100644\nindex 0000000000000..7ebcefca75e44\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/analytics/query-with-postgres.mdx\n@@ -0,0 +1,74 @@\n+---\n+title: 'Query with PostgreSQL'\n+subtitle: 'Query analytics bucket data directly from PostgreSQL using SQL.'\n+---\n+\n+Once your data flows into an analytics bucket—either via the [ETL Replication Pipeline](/docs/guides/storage/analytics/etl) or custom pipelines—you can query it directly from Postgres using standard SQL.\n+\n+This is made possible by the [Iceberg Foreign Data Wrapper](/docs/guides/database/extensions/wrappers/iceberg), which creates a bridge between your Postgres database and Iceberg tables.\n+\n+## Setup overview\n+\n+You have two options to enable querying:\n+\n+1. **Dashboard UI** (recommended) - Streamlined setup through the Supabase Dashboard\n+2. **Manual installation** - Install the wrapper using SQL and configuration\n+\n+## Installing via Dashboard UI\n+\n+The dashboard provides the easiest setup experience:\n+\n+1. Navigate to your **Analytics Bucket** page in the Supabase Dashboard.\n+2. Locate the namespace you want to query and click **Query with Postgres**.\n+\n+<Image\n+  alt=\"Query with PostgreSQL button on analytics bucket page\"\n+  src=\"/docs/img/storage/query-analytics-with-postgres.png\"\n+/>\n+\n+3. Enter the **Postgres schema** where you want to create the foreign tables.\n+\n+<Image\n+  alt=\"Select destination PostgreSQL schema\"\n+  src=\"/docs/img/storage/query-analytics-schema-name.png\"\n+/>\n+\n+4. Click **Connect**. The wrapper is now configured.\n+\n+## Querying your data\n+\n+Once the foreign data wrapper is installed, you can query your Iceberg tables using standard SQL:\n+\n+```sql\n+select *\n+from schema_name.table_name\n+limit 100;\n+```\n+\n+### Common query examples\n+\n+Get the latest events:\n+\n+```sql\n+select event_id, event_name, event_timestamp\n+from analytics.events\n+order by event_timestamp desc\n+limit 1000;\n+```\n+\n+Join with transactional data:\n+\n+```sql\n+SELECT\n+  e.event_id,\n+  e.event_name,\n+  u.user_email\n+FROM analytics.events e\n+JOIN public.users u ON e.user_id = u.id\n+WHERE e.event_timestamp > NOW() - INTERVAL '7 days'\n+LIMIT 100;\n+```\n+\n+## Manual installation\n+\n+For advanced use cases, you can manually install and configure the Iceberg Foreign Data Wrapper. See the [Iceberg Foreign Data Wrapper documentation](/docs/guides/database/extensions/wrappers/iceberg) for detailed instructions.\ndiff --git a/apps/docs/content/guides/storage/management/pricing.mdx b/apps/docs/content/guides/storage/pricing.mdx\nsimilarity index 100%\nrename from apps/docs/content/guides/storage/management/pricing.mdx\nrename to apps/docs/content/guides/storage/pricing.mdx\ndiff --git a/apps/docs/content/guides/storage/vector/creating-vector-buckets.mdx b/apps/docs/content/guides/storage/vector/creating-vector-buckets.mdx\nnew file mode 100644\nindex 0000000000000..389cb22238047\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/vector/creating-vector-buckets.mdx\n@@ -0,0 +1,85 @@\n+---\n+title: 'Creating Vector Buckets'\n+subtitle: 'Set up vector buckets and indexes using the dashboard or JavaScript SDK.'\n+---\n+\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n+\n+Expect rapid changes, limited features, and possible breaking updates. [Share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n+\n+</Admonition>\n+\n+Vector buckets organize your vector data into logical units. Within each bucket, you create indexes that define how vectors are stored and searched based on their dimensions and distance metrics.\n+\n+## Creating a Vector bucket\n+\n+You can create vector buckets using either the Supabase Dashboard or the JavaScript SDK.\n+\n+### Using the Supabase Dashboard\n+\n+1. Navigate to the **Storage** section in the Supabase Dashboard.\n+2. Click **Create Bucket**.\n+3. Enter a name for your bucket (e.g., `embeddings` or `semantic-search`).\n+4. Select **Vector Bucket** as the bucket type.\n+5. Click **Create**.\n+\n+Your vector bucket is now ready. The next step is to create indexes within it.\n+\n+### Using the JavaScript SDK\n+\n+```typescript\n+import { createClient } from '@supabase/supabase-js'\n+\n+const supabase = createClient('https://your-project.supabase.co', 'your-service-key')\n+\n+// Create a vector bucket\n+await supabase.storage.vectors.createBucket('embeddings')\n+\n+console.log('✓ Vector bucket created: embeddings')\n+```\n+\n+## Creating indexes\n+\n+Indexes organize vectors within a bucket with consistent dimensions and distance metrics. For comprehensive index management documentation, see [Working with Vector Indexes](/docs/guides/storage/vector/working-with-indexes).\n+\n+### Quick start: Creating an index via Dashboard\n+\n+1. Open your vector bucket.\n+2. Click **Create Index**.\n+3. Enter an index name (e.g., `documents-openai`).\n+4. Set the dimension matching your embeddings (e.g., `1536` for OpenAI's text-embedding-3-small).\n+5. Select the distance metric (`cosine`, `euclidean`, or `l2`).\n+6. Click **Create**.\n+\n+### Quick start: Creating an index via JavaScript SDK\n+\n+```typescript\n+const bucket = supabase.storage.vectors.from('embeddings')\n+\n+// Create an index\n+await bucket.createIndex({\n+  indexName: 'documents-openai',\n+  dataType: 'float32',\n+  dimension: 1536,\n+  distanceMetric: 'cosine',\n+})\n+\n+console.log('✓ Index created: documents-openai')\n+```\n+\n+### Key details\n+\n+- **Dimension** must match your embedding model (e.g., 1536 for OpenAI)\n+- **Distance metric** (`cosine`, `euclidean`, or `l2`) is immutable after creation\n+- **Maximum indexes per bucket**: 10\n+- **Maximum batch size**: 500 vectors per operation\n+\n+For detailed information on distance metrics, embedding dimensions, managing multiple indexes, and advanced index operations, see [Working with Vector Indexes](/docs/guides/storage/vector/working-with-indexes).\n+\n+## Next steps\n+\n+After creating your bucket and indexes, you can:\n+\n+- [Store vectors](/docs/guides/storage/vector/storing-vectors)\n+- [Query vectors with similarity search](/docs/guides/storage/vector/querying-vectors)\n+- [Explore vector bucket limits](/docs/guides/storage/vector/limits)\ndiff --git a/apps/docs/content/guides/storage/vector/introduction.mdx b/apps/docs/content/guides/storage/vector/introduction.mdx\nnew file mode 100644\nindex 0000000000000..bb08e7fd46cd5\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/vector/introduction.mdx\n@@ -0,0 +1,54 @@\n+---\n+title: 'Vector Buckets'\n+subtitle: 'Store, index, and query vector embeddings at scale with similarity search.'\n+---\n+\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n+\n+Expect rapid changes, limited features, and possible breaking updates. [Share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n+\n+</Admonition>\n+\n+Vector buckets enable efficient storage and similarity search of vector embeddings. Built on S3-compatible storage, they provide high-performance semantic search capabilities for AI and machine learning applications.\n+\n+## What are Vector buckets?\n+\n+Vector buckets are specialized storage containers optimized for vector data. Unlike traditional databases optimized for transactional queries, vector buckets use specialized indexing and distance metrics to perform fast similarity searches across millions of embeddings.\n+\n+Each vector bucket contains:\n+\n+- **Indexes** - Organized collections of vectors with consistent dimensions and distance metrics\n+- **Vectors** - Embeddings with associated metadata for filtering and enrichment\n+- **Metadata** - Additional context about vectors (text, tags, IDs, etc.)\n+\n+## Key features\n+\n+- **Similarity Search** - Find semantically similar vectors using cosine, euclidean, or L2 distance metrics\n+- **Metadata Filtering** - Filter results by associated metadata before/after similarity search\n+- **Batch Operations** - Insert, update, and query up to 500 vectors per request\n+- **Scalable Storage** - Store millions of vectors in a single index\n+- **S3 Native** - Built on proven S3 infrastructure for reliability and durability\n+\n+## Ideal use cases\n+\n+Vector buckets excel at:\n+\n+- **Semantic Search** - Find documents or images similar to a query\n+- **Recommendation Systems** - Suggest products, content, or connections based on embeddings\n+- **Clustering & Anomaly Detection** - Group similar items or identify outliers\n+- **Image Search** - Retrieve visually similar images from large catalogs\n+- **RAG (Retrieval-Augmented Generation)** - Find relevant context for LLM queries\n+- **Personalization** - Recommend tailored content based on user embeddings\n+\n+## How Vector buckets work\n+\n+1. **Create a bucket** to organize your vector data\n+2. **Create indexes** within the bucket with specified dimensions and distance metrics\n+3. **Store vectors** with embeddings and optional metadata\n+4. **Query vectors** using similarity search to find nearest neighbors\n+\n+The system automatically handles indexing and optimization, making searches fast and reliable even with millions of vectors.\n+\n+## Next steps\n+\n+Get started by learning how to [create vector buckets](/docs/guides/storage/vector/creating-vector-buckets) or dive into [storing vectors](/docs/guides/storage/vector/storing-vectors).\ndiff --git a/apps/docs/content/guides/storage/vector/limits.mdx b/apps/docs/content/guides/storage/vector/limits.mdx\nnew file mode 100644\nindex 0000000000000..0b0883367af39\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/vector/limits.mdx\n@@ -0,0 +1,21 @@\n+---\n+title: 'Vector Bucket Limits'\n+subtitle: 'Understanding capacity, quotas, and billing for vector buckets.'\n+---\n+\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n+\n+Expect rapid changes, limited features, and possible breaking updates. [Share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n+\n+</Admonition>\n+\n+Vector buckets have default limits during the alpha phase. These limits are designed to ensure fair resource allocation and can be adjusted on a case-by-case basis for production workloads.\n+\n+## Storage limits\n+\n+| Limit                   | Value        | Notes                                                 |\n+| ----------------------- | ------------ | ----------------------------------------------------- |\n+| **Buckets per project** | 10           | Maximum number of vector buckets per Supabase project |\n+| **Indexes per bucket**  | 10           | Maximum number of indexes per bucket                  |\n+| **Vector dimensions**   | Max 4096     | Maximum dimension size for embeddings                 |\n+| **Batch size**          | 1000 vectors | Maximum vectors per single insert/update request      |\ndiff --git a/apps/docs/content/guides/storage/vector/querying-vectors.mdx b/apps/docs/content/guides/storage/vector/querying-vectors.mdx\nnew file mode 100644\nindex 0000000000000..e90380128370c\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/vector/querying-vectors.mdx\n@@ -0,0 +1,489 @@\n+---\n+title: 'Querying Vectors'\n+subtitle: 'Perform similarity search and retrieve vectors using JavaScript SDK or PostgreSQL.'\n+---\n+\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n+\n+Expect rapid changes, limited features, and possible breaking updates. [Share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n+\n+</Admonition>\n+\n+Vector similarity search finds vectors most similar to a query vector using distance metrics. You can query vectors using the JavaScript SDK or directly from Postgres using SQL.\n+\n+## Basic similarity search\n+\n+<Tabs\n+  scrollable\n+  size=\"small\"\n+  type=\"underlined\"\n+  defaultActiveId=\"javascript\"\n+  queryGroup=\"language\"\n+>\n+<TabPanel id=\"javascript\" label=\"JavaScript\">\n+\n+```typescript\n+import { createClient } from '@supabase/supabase-js'\n+\n+const supabase = createClient('https://your-project.supabase.co', 'your-service-key')\n+\n+const index = supabase.storage.vectors.from('embeddings').index('documents-openai')\n+\n+// Query with a vector embedding\n+const { data, error } = await index.queryVectors({\n+  queryVector: {\n+    float32: [0.1, 0.2, 0.3 /* ... embedding of 1536 dimensions ... */],\n+  },\n+  topK: 5,\n+  returnDistance: true,\n+  returnMetadata: true,\n+})\n+\n+if (error) {\n+  console.error('Query failed:', error)\n+} else {\n+  // Results are ranked by similarity (lowest distance = most similar)\n+  data.vectors.forEach((result, rank) => {\n+    console.log(`${rank + 1}. ${result.metadata?.title}`)\n+    console.log(`   Similarity score: ${result.distance.toFixed(4)}`)\n+  })\n+}\n+```\n+\n+</TabPanel>\n+\n+<TabPanel id=\"sql\" label=\"SQL (via S3 Vector Wrapper)\">\n+\n+```sql\n+-- Setup S3 Vector Wrapper (one-time setup)\n+-- https://supabase.com/docs/guides/database/extensions/wrappers/s3_vectors\n+\n+-- Query similar vectors\n+SELECT\n+  key,\n+  metadata->>'title' as title,\n+  embd_distance(data) as distance,\n+  (1 - embd_distance(data)) as similarity_score\n+FROM s3_vectors.documents_openai\n+WHERE data <==> '[0.1, 0.2, 0.3, /* ... embedding ... */]'::embd\n+ORDER BY embd_distance(data) ASC\n+LIMIT 5;\n+```\n+\n+</TabPanel>\n+</Tabs>\n+\n+## Semantic search\n+\n+Find documents similar to a query by embedding the query text:\n+\n+<Tabs\n+  scrollable\n+  size=\"small\"\n+  type=\"underlined\"\n+  defaultActiveId=\"javascript\"\n+  queryGroup=\"language\"\n+>\n+<TabPanel id=\"javascript\" label=\"JavaScript\">\n+\n+```typescript\n+import { createClient } from '@supabase/supabase-js'\n+import OpenAI from 'openai'\n+\n+const supabase = createClient(...)\n+const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY })\n+\n+async function semanticSearch(query, topK = 5) {\n+  // Embed the query\n+  const queryEmbedding = await openai.embeddings.create({\n+    model: 'text-embedding-3-small',\n+    input: query\n+  })\n+\n+  const queryVector = queryEmbedding.data[0].embedding\n+\n+  // Search for similar vectors\n+  const { data, error } = await supabase.storage.vectors\n+    .from('embeddings')\n+    .index('documents-openai')\n+    .queryVectors({\n+      queryVector: { float32: queryVector },\n+      topK,\n+      returnDistance: true,\n+      returnMetadata: true\n+    })\n+\n+  if (error) {\n+    throw error\n+  }\n+\n+  return data.vectors.map((result) => ({\n+    id: result.key,\n+    title: result.metadata?.title,\n+    similarity: 1 - result.distance, // Convert distance to similarity (0-1)\n+    metadata: result.metadata\n+  }))\n+}\n+\n+// Usage\n+const results = await semanticSearch('How do I use vector search?')\n+results.forEach((result) => {\n+  console.log(`${result.title} (${(result.similarity * 100).toFixed(1)}% similar)`)\n+})\n+```\n+\n+</TabPanel>\n+\n+<TabPanel id=\"sql\" label=\"SQL (via S3 Vector Wrapper)\">\n+\n+```sql\n+-- Semantic search from PostgreSQL\n+-- First, generate embedding from external API and store in a variable\n+-- Then use it to query vectors\n+\n+WITH query_embedding AS (\n+  SELECT '[/* ... embedding from OpenAI API ... */]'::embd as embedding\n+)\n+SELECT\n+  key,\n+  metadata->>'title' as title,\n+  embd_distance(data) as distance,\n+  (1 - embd_distance(data)) as similarity_score\n+FROM s3_vectors.documents_openai,\n+     query_embedding\n+WHERE data <==> query_embedding.embedding\n+ORDER BY embd_distance(data) ASC\n+LIMIT 5;\n+```\n+\n+</TabPanel>\n+</Tabs>\n+\n+## Filtered similarity search\n+\n+<Tabs\n+  scrollable\n+  size=\"small\"\n+  type=\"underlined\"\n+  defaultActiveId=\"javascript\"\n+  queryGroup=\"language\"\n+>\n+<TabPanel id=\"javascript\" label=\"JavaScript\">\n+\n+```typescript\n+const index = supabase.storage.vectors\n+  .from('embeddings')\n+  .index('documents-openai')\n+\n+// Search with metadata filter\n+const { data } = await index.queryVectors({\n+  queryVector: { float32: [...embedding...] },\n+  topK: 10,\n+  filter: {\n+    // Filter by metadata fields\n+    category: 'electronics',\n+    in_stock: true,\n+    price: { $lte: 500 } // Less than or equal to 500\n+  },\n+  returnDistance: true,\n+  returnMetadata: true\n+})\n+```\n+\n+</TabPanel>\n+\n+<TabPanel id=\"sql\" label=\"SQL (via S3 Vector Wrapper)\">\n+\n+```sql\n+-- Search with metadata filters\n+SELECT\n+  key,\n+  metadata->>'title' as title,\n+  (metadata->>'price')::numeric as price,\n+  embd_distance(data) as distance,\n+  (1 - embd_distance(data)) as similarity\n+FROM s3_vectors.documents_openai\n+WHERE data <==> '[...]'::embd\n+  AND (metadata->>'category') = 'electronics'\n+  AND (metadata->>'in_stock')::boolean = true\n+  AND (metadata->>'price')::numeric <= 500\n+ORDER BY embd_distance(data) ASC\n+LIMIT 10;\n+```\n+\n+</TabPanel>\n+</Tabs>\n+\n+## Retrieving specific vectors\n+\n+<Tabs\n+  scrollable\n+  size=\"small\"\n+  type=\"underlined\"\n+  defaultActiveId=\"javascript\"\n+  queryGroup=\"language\"\n+>\n+<TabPanel id=\"javascript\" label=\"JavaScript\">\n+\n+```typescript\n+const index = supabase.storage.vectors.from('embeddings').index('documents-openai')\n+\n+const { data, error } = await index.getVectors({\n+  keys: ['doc-1', 'doc-2', 'doc-3'],\n+  returnData: true,\n+  returnMetadata: true,\n+})\n+\n+if (!error) {\n+  data.vectors.forEach((vector) => {\n+    console.log(`${vector.key}: ${vector.metadata?.title}`)\n+  })\n+}\n+```\n+\n+</TabPanel>\n+\n+<TabPanel id=\"sql\" label=\"SQL (via S3 Vector Wrapper)\">\n+\n+```sql\n+-- Retrieve specific vectors by key\n+SELECT\n+  key,\n+  data as embedding,\n+  metadata\n+FROM s3_vectors.documents_openai\n+WHERE key IN ('doc-1', 'doc-2', 'doc-3');\n+```\n+\n+</TabPanel>\n+</Tabs>\n+\n+## Listing vectors\n+\n+<Tabs\n+  scrollable\n+  size=\"small\"\n+  type=\"underlined\"\n+  defaultActiveId=\"javascript\"\n+  queryGroup=\"language\"\n+>\n+<TabPanel id=\"javascript\" label=\"JavaScript\">\n+\n+```typescript\n+const index = supabase.storage.vectors.from('embeddings').index('documents-openai')\n+\n+let nextToken = undefined\n+let pageCount = 0\n+\n+do {\n+  const { data, error } = await index.listVectors({\n+    maxResults: 100,\n+    nextToken,\n+    returnData: false, // Don't return embeddings for faster response\n+    returnMetadata: true,\n+  })\n+\n+  if (error) break\n+\n+  pageCount++\n+  console.log(`Page ${pageCount}: ${data.vectors.length} vectors`)\n+\n+  data.vectors.forEach((vector) => {\n+    console.log(`  - ${vector.key}: ${vector.metadata?.title}`)\n+  })\n+\n+  nextToken = data.nextToken\n+} while (nextToken)\n+```\n+\n+</TabPanel>\n+\n+<TabPanel id=\"sql\" label=\"SQL (via S3 Vector Wrapper)\">\n+\n+```sql\n+-- List all vectors with pagination\n+SELECT\n+  key,\n+  metadata\n+FROM s3_vectors.documents_openai\n+ORDER BY key ASC\n+LIMIT 100\n+OFFSET 0;\n+\n+-- To paginate, increase OFFSET for next page:\n+-- OFFSET 100 for page 2, OFFSET 200 for page 3, etc.\n+```\n+\n+</TabPanel>\n+</Tabs>\n+\n+## Hybrid search: Vectors + relational data\n+\n+Combine similarity search with SQL filtering and joins:\n+\n+<Tabs\n+  scrollable\n+  size=\"small\"\n+  type=\"underlined\"\n+  defaultActiveId=\"javascript\"\n+  queryGroup=\"language\"\n+>\n+<TabPanel id=\"javascript\" label=\"JavaScript\">\n+\n+```typescript\n+async function hybridSearch(queryVector, filters) {\n+  const index = supabase.storage.vectors.from('embeddings').index('documents-openai')\n+\n+  // Get similar vectors with filters\n+  const { data: vectorResults } = await index.queryVectors({\n+    queryVector: { float32: queryVector },\n+    topK: 100,\n+    filter: filters,\n+    returnDistance: true,\n+    returnMetadata: true,\n+  })\n+\n+  // Get additional details from relational database\n+  const { data: details } = await supabase\n+    .from('documents')\n+    .select('*')\n+    .in(\n+      'id',\n+      vectorResults.vectors.map((v) => v.metadata?.doc_id)\n+    )\n+\n+  // Merge results\n+  return vectorResults.vectors.map((vector) => {\n+    const detail = details?.find((d) => d.id === vector.metadata?.doc_id)\n+    return {\n+      ...vector,\n+      ...detail,\n+    }\n+  })\n+}\n+```\n+\n+</TabPanel>\n+\n+<TabPanel id=\"sql\" label=\"SQL (via S3 Vector Wrapper)\">\n+\n+```sql\n+-- Hybrid search: vectors + relational data join\n+SELECT\n+  v.key as vector_id,\n+  v.metadata->>'title' as vector_title,\n+  d.id as document_id,\n+  d.full_text,\n+  d.author,\n+  d.created_at,\n+  embd_distance(v.data) as similarity_score\n+FROM s3_vectors.documents_openai v\n+LEFT JOIN public.documents d\n+  ON v.metadata->>'doc_id' = d.id::text\n+WHERE v.data <==> '[...]'::embd\n+  AND embd_distance(v.data) < 0.3  -- High similarity threshold\n+  AND d.category = 'articles'\n+ORDER BY embd_distance(v.data) ASC\n+LIMIT 50;\n+```\n+\n+</TabPanel>\n+</Tabs>\n+\n+## Real-world examples\n+\n+### RAG (retrieval-augmented generation)\n+\n+```typescript\n+import OpenAI from 'openai'\n+import { createClient } from '@supabase/supabase-js'\n+\n+async function retrieveContextForLLM(userQuery) {\n+  const supabase = createClient(...)\n+  const openai = new OpenAI()\n+\n+  // 1. Embed the user query\n+  const queryEmbedding = await openai.embeddings.create({\n+    model: 'text-embedding-3-small',\n+    input: userQuery\n+  })\n+\n+  // 2. Retrieve relevant documents\n+  const { data: vectorResults } = await supabase.storage.vectors\n+    .from('embeddings')\n+    .index('documents-openai')\n+    .queryVectors({\n+      queryVector: { float32: queryEmbedding.data[0].embedding },\n+      topK: 5,\n+      returnMetadata: true\n+    })\n+\n+  // 3. Use vectors to augment LLM prompt\n+  const context = vectorResults.vectors\n+    .map(v => v.metadata?.content || '')\n+    .join('\\n\\n')\n+\n+  const response = await openai.chat.completions.create({\n+    model: 'gpt-4',\n+    messages: [\n+      {\n+        role: 'system',\n+        content: `Use the following context to answer the user's question:\\n\\n${context}`\n+      },\n+      {\n+        role: 'user',\n+        content: userQuery\n+      }\n+    ]\n+  })\n+\n+  return response.choices[0].message.content\n+}\n+```\n+\n+### Product recommendations\n+\n+```typescript\n+async function recommendProducts(userEmbedding, topK = 5) {\n+  const supabase = createClient(...)\n+\n+  // Find similar products\n+  const { data } = await supabase.storage.vectors\n+    .from('embeddings')\n+    .index('products-openai')\n+    .queryVectors({\n+      queryVector: { float32: userEmbedding },\n+      topK,\n+      filter: {\n+        in_stock: true\n+      },\n+      returnMetadata: true\n+    })\n+\n+  return data.vectors.map((result) => ({\n+    id: result.metadata?.product_id,\n+    name: result.metadata?.name,\n+    price: result.metadata?.price,\n+    similarity: 1 - result.distance\n+  }))\n+}\n+```\n+\n+### Filtering before similarity search\n+\n+```typescript\n+// Use metadata filters to reduce search scope\n+const { data } = await index.queryVectors({\n+  queryVector,\n+  topK: 100,\n+  filter: {\n+    category: 'electronics', // Pre-filter by category\n+  },\n+})\n+```\n+\n+## Next steps\n+\n+- [Store vectors](/docs/guides/storage/vector/storing-vectors)\n+- [Work with vector indexes](/docs/guides/storage/vector/working-with-indexes)\n+- [Explore vector bucket limits](/docs/guides/storage/vector/limits)\ndiff --git a/apps/docs/content/guides/storage/vector/storing-vectors.mdx b/apps/docs/content/guides/storage/vector/storing-vectors.mdx\nnew file mode 100644\nindex 0000000000000..c3ce2ed43b21a\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/vector/storing-vectors.mdx\n@@ -0,0 +1,411 @@\n+---\n+title: 'Storing Vectors'\n+subtitle: 'Insert and update vector embeddings with metadata using the JavaScript SDK or Postgres.'\n+---\n+\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n+\n+Expect rapid changes, limited features, and possible breaking updates. [Share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n+\n+</Admonition>\n+\n+Once you've created a bucket and index, you can start storing vectors. Vectors can include optional metadata for filtering and enrichment during queries.\n+\n+## Basic vector insertion\n+\n+<Tabs\n+  scrollable\n+  size=\"small\"\n+  type=\"underlined\"\n+  defaultActiveId=\"javascript\"\n+  queryGroup=\"language\"\n+>\n+<TabPanel id=\"javascript\" label=\"JavaScript\">\n+\n+```typescript\n+import { createClient } from '@supabase/supabase-js'\n+\n+const supabase = createClient('https://your-project.supabase.co', 'your-service-key')\n+\n+// Get bucket and index\n+const bucket = supabase.storage.vectors.from('embeddings')\n+const index = bucket.index('documents-openai')\n+\n+// Insert vectors\n+const { error } = await index.putVectors({\n+  vectors: [\n+    {\n+      key: 'doc-1',\n+      data: {\n+        float32: [0.1, 0.2, 0.3 /* ... rest of embedding ... */],\n+      },\n+      metadata: {\n+        title: 'Getting Started with Vector Buckets',\n+        source: 'documentation',\n+      },\n+    },\n+    {\n+      key: 'doc-2',\n+      data: {\n+        float32: [0.4, 0.5, 0.6 /* ... rest of embedding ... */],\n+      },\n+      metadata: {\n+        title: 'Advanced Vector Search',\n+        source: 'blog',\n+      },\n+    },\n+  ],\n+})\n+\n+if (error) {\n+  console.error('Error storing vectors:', error)\n+} else {\n+  console.log('✓ Vectors stored successfully')\n+}\n+```\n+\n+</TabPanel>\n+\n+<TabPanel id=\"sql\" label=\"SQL (via S3 Vector Wrapper)\">\n+\n+```sql\n+-- Setup S3 Vector Wrapper (one-time setup)\n+-- https://supabase.com/docs/guides/database/extensions/wrappers/s3_vectors\n+\n+-- Insert vectors into the index\n+INSERT INTO s3_vectors.documents_openai (key, data, metadata)\n+VALUES\n+  (\n+    'doc-1',\n+    '[0.1, 0.2, 0.3, /* ... rest of embedding ... */]'::embd,\n+    '{\"title\": \"Getting Started with Vector Buckets\", \"source\": \"documentation\"}'::jsonb\n+  ),\n+  (\n+    'doc-2',\n+    '[0.4, 0.5, 0.6, /* ... rest of embedding ... */]'::embd,\n+    '{\"title\": \"Advanced Vector Search\", \"source\": \"blog\"}'::jsonb\n+  );\n+```\n+\n+</TabPanel>\n+</Tabs>\n+\n+## Storing vectors from Embeddings API\n+\n+Generate embeddings using an LLM API and store them directly:\n+\n+<Tabs\n+  scrollable\n+  size=\"small\"\n+  type=\"underlined\"\n+  defaultActiveId=\"javascript\"\n+  queryGroup=\"language\"\n+>\n+<TabPanel id=\"javascript\" label=\"JavaScript\">\n+\n+```typescript\n+import { createClient } from '@supabase/supabase-js'\n+import OpenAI from 'openai'\n+\n+const supabase = createClient('https://your-project.supabase.co', 'your-service-key')\n+\n+const openai = new OpenAI({\n+  apiKey: process.env.OPENAI_API_KEY,\n+})\n+\n+// Documents to embed and store\n+const documents = [\n+  { id: '1', title: 'How to Train Your AI', content: 'Guide for training models...' },\n+  { id: '2', title: 'Vector Search Best Practices', content: 'Tips for semantic search...' },\n+  {\n+    id: '3',\n+    title: 'Building RAG Systems',\n+    content: 'Implementing retrieval-augmented generation...',\n+  },\n+]\n+\n+// Generate embeddings\n+const embeddings = await openai.embeddings.create({\n+  model: 'text-embedding-3-small',\n+  input: documents.map((doc) => doc.content),\n+})\n+\n+// Prepare vectors for storage\n+const vectors = documents.map((doc, index) => ({\n+  key: doc.id,\n+  data: {\n+    float32: embeddings.data[index].embedding,\n+  },\n+  metadata: {\n+    title: doc.title,\n+    source: 'knowledge_base',\n+    created_at: new Date().toISOString(),\n+  },\n+}))\n+\n+// Store vectors in batches (max 500 per request)\n+const bucket = supabase.storage.vectors.from('embeddings')\n+const vectorIndex = bucket.index('documents-openai')\n+\n+for (let i = 0; i < vectors.length; i += 500) {\n+  const batch = vectors.slice(i, i + 500)\n+  const { error } = await vectorIndex.putVectors({ vectors: batch })\n+\n+  if (error) {\n+    console.error(`Error storing batch ${i / 500 + 1}:`, error)\n+  } else {\n+    console.log(`✓ Stored batch ${i / 500 + 1} (${batch.length} vectors)`)\n+  }\n+}\n+```\n+\n+</TabPanel>\n+\n+<TabPanel id=\"sql\" label=\"SQL (via S3 Vector Wrapper)\">\n+\n+```sql\n+-- Insert vectors with pre-generated embeddings\n+INSERT INTO s3_vectors.documents_openai (key, data, metadata)\n+VALUES\n+  (\n+    '1',\n+    '[0.1, 0.2, 0.3, /* ... rest of embedding ... */]'::embd,\n+    '{\"title\": \"How to Train Your AI\", \"source\": \"knowledge_base\", \"created_at\": \"2025-01-01T00:00:00Z\"}'::jsonb\n+  ),\n+  (\n+    '2',\n+    '[0.4, 0.5, 0.6, /* ... rest of embedding ... */]'::embd,\n+    '{\"title\": \"Vector Search Best Practices\", \"source\": \"knowledge_base\", \"created_at\": \"2025-01-01T00:00:00Z\"}'::jsonb\n+  ),\n+  (\n+    '3',\n+    '[0.7, 0.8, 0.9, /* ... rest of embedding ... */]'::embd,\n+    '{\"title\": \"Building RAG Systems\", \"source\": \"knowledge_base\", \"created_at\": \"2025-01-01T00:00:00Z\"}'::jsonb\n+  );\n+```\n+\n+</TabPanel>\n+</Tabs>\n+\n+## Updating vectors\n+\n+<Tabs\n+  scrollable\n+  size=\"small\"\n+  type=\"underlined\"\n+  defaultActiveId=\"javascript\"\n+  queryGroup=\"language\"\n+>\n+<TabPanel id=\"javascript\" label=\"JavaScript\">\n+\n+```typescript\n+const index = bucket.index('documents-openai')\n+\n+// Update a vector (same key)\n+const { error } = await index.putVectors({\n+  vectors: [\n+    {\n+      key: 'doc-1',\n+      data: {\n+        float32: [0.15, 0.25, 0.35 /* ... updated embedding ... */],\n+      },\n+      metadata: {\n+        title: 'Getting Started with Vector Buckets - Updated',\n+        updated_at: new Date().toISOString(),\n+      },\n+    },\n+  ],\n+})\n+\n+if (!error) {\n+  console.log('✓ Vector updated successfully')\n+}\n+```\n+\n+</TabPanel>\n+\n+<TabPanel id=\"sql\" label=\"SQL (via S3 Vector Wrapper)\">\n+\n+```sql\n+-- Update a vector (delete and re-insert)\n+DELETE FROM s3_vectors.documents_openai WHERE key = 'doc-1';\n+\n+INSERT INTO s3_vectors.documents_openai (key, data, metadata)\n+VALUES (\n+  'doc-1',\n+  '[0.15, 0.25, 0.35, /* ... updated embedding ... */]'::embd,\n+  '{\"title\": \"Getting Started with Vector Buckets - Updated\", \"updated_at\": \"2025-01-01T00:00:00Z\"}'::jsonb\n+);\n+```\n+\n+</TabPanel>\n+</Tabs>\n+\n+## Deleting vectors\n+\n+<Tabs\n+  scrollable\n+  size=\"small\"\n+  type=\"underlined\"\n+  defaultActiveId=\"javascript\"\n+  queryGroup=\"language\"\n+>\n+<TabPanel id=\"javascript\" label=\"JavaScript\">\n+\n+```typescript\n+const index = bucket.index('documents-openai')\n+\n+// Delete specific vectors\n+const { error } = await index.deleteVectors({\n+  keys: ['doc-1', 'doc-2'],\n+})\n+\n+if (!error) {\n+  console.log('✓ Vectors deleted successfully')\n+}\n+```\n+\n+</TabPanel>\n+\n+<TabPanel id=\"sql\" label=\"SQL (via S3 Vector Wrapper)\">\n+\n+```sql\n+-- Delete vectors by key\n+DELETE FROM s3_vectors.documents_openai\n+WHERE key IN ('doc-1', 'doc-2');\n+```\n+\n+</TabPanel>\n+</Tabs>\n+\n+## Metadata best practices\n+\n+Metadata makes vectors more useful by enabling filtering and context:\n+\n+```typescript\n+const vectors = [\n+  {\n+    key: 'product-001',\n+    data: { float32: [...] },\n+    metadata: {\n+      product_id: 'prod-001',\n+      category: 'electronics',\n+      price: 299.99,\n+      in_stock: true,\n+      tags: ['laptop', 'portable'],\n+      description: 'High-performance ultrabook'\n+    }\n+  },\n+  {\n+    key: 'product-002',\n+    data: { float32: [...] },\n+    metadata: {\n+      product_id: 'prod-002',\n+      category: 'electronics',\n+      price: 99.99,\n+      in_stock: true,\n+      tags: ['headphones', 'wireless'],\n+      description: 'Noise-cancelling wireless headphones'\n+    }\n+  }\n+]\n+\n+const { error } = await index.putVectors({ vectors })\n+```\n+\n+### Metadata field guidelines\n+\n+- **Keep it lightweight** - Metadata is returned with query results, so large values increase response size\n+- **Use consistent types** - Store the same field with consistent data types across vectors\n+- **Index key fields** - Mark fields you'll filter by to improve query performance\n+- **Avoid nested objects** - While supported, flat structures are easier to filter\n+\n+## Batch processing large datasets\n+\n+For storing large numbers of vectors efficiently:\n+\n+```typescript\n+import { createClient } from '@supabase/supabase-js'\n+import fs from 'fs'\n+\n+const supabase = createClient(...)\n+const index = supabase.storage.vectors\n+  .from('embeddings')\n+  .index('documents-openai')\n+\n+// Read embeddings from file\n+const embeddingsFile = fs.readFileSync('embeddings.jsonl', 'utf-8')\n+const lines = embeddingsFile.split('\\n').filter(line => line.trim())\n+\n+const vectors = lines.map((line, idx) => {\n+  const { key, embedding, metadata } = JSON.parse(line)\n+  return {\n+    key,\n+    data: { float32: embedding },\n+    metadata\n+  }\n+})\n+\n+// Process in batches\n+const BATCH_SIZE = 500\n+let processed = 0\n+\n+for (let i = 0; i < vectors.length; i += BATCH_SIZE) {\n+  const batch = vectors.slice(i, i + BATCH_SIZE)\n+\n+  try {\n+    const { error } = await index.putVectors({ vectors: batch })\n+\n+    if (error) throw error\n+\n+    processed += batch.length\n+    console.log(`Progress: ${processed}/${vectors.length}`)\n+  } catch (error) {\n+    console.error(`Batch failed at offset ${i}:`, error)\n+    // Optionally implement retry logic\n+  }\n+}\n+\n+console.log('✓ All vectors stored successfully')\n+```\n+\n+## Performance optimization\n+\n+### Batch operations\n+\n+Always use batch operations for better performance:\n+\n+```typescript\n+// ❌ Inefficient - Multiple requests\n+for (const vector of vectors) {\n+  await index.putVectors({ vectors: [vector] })\n+}\n+\n+// ✅ Efficient - Single batch operation\n+await index.putVectors({ vectors })\n+```\n+\n+### Metadata considerations\n+\n+Keep metadata concise:\n+\n+```typescript\n+// ❌ Large metadata\n+metadata: {\n+  full_document_text: 'Very long document content...',\n+  detailed_analysis: { /* large object */ }\n+}\n+\n+// ✅ Lean metadata\n+metadata: {\n+  doc_id: 'doc-123',\n+  category: 'news',\n+  summary: 'Brief summary'\n+}\n+```\n+\n+## Next steps\n+\n+- [Query vectors with similarity search](/docs/guides/storage/vector/querying-vectors)\n+- [Work with vector indexes](/docs/guides/storage/vector/working-with-indexes)\n+- [Explore vector bucket limits](/docs/guides/storage/vector/limits)\ndiff --git a/apps/docs/content/guides/storage/vector/working-with-indexes.mdx b/apps/docs/content/guides/storage/vector/working-with-indexes.mdx\nnew file mode 100644\nindex 0000000000000..3cf039aea8c16\n--- /dev/null\n+++ b/apps/docs/content/guides/storage/vector/working-with-indexes.mdx\n@@ -0,0 +1,213 @@\n+---\n+title: 'Working with Vector Indexes'\n+subtitle: 'Create, manage, and optimize vector indexes for efficient similarity search.'\n+---\n+\n+<Admonition type=\"caution\" title=\"This feature is in alpha\">\n+\n+Expect rapid changes, limited features, and possible breaking updates. [Share feedback](https://github.com/orgs/supabase/discussions/40116) as we refine the experience and expand access.\n+\n+</Admonition>\n+\n+Vector indexes organize embeddings within a bucket with consistent dimensions and distance metrics. Each index defines how similarity searches are performed across your vectors.\n+\n+## Understanding vector indexes\n+\n+An index specifies:\n+\n+- **Index Name** - Unique identifier within the bucket\n+- **Dimension** - Size of vector embeddings (e.g., 1536 for OpenAI)\n+- **Distance Metric** - Similarity calculation method (cosine, euclidean, or L2)\n+- **Data Type** - Vector format (currently `float32`)\n+\n+Think of an index as a table in a traditional database. It has a schema (dimension) and a query strategy (distance metric).\n+\n+## Creating indexes\n+\n+### Via Dashboard\n+\n+1. Open your vector bucket in the Supabase Dashboard.\n+2. Click **Create Index**.\n+3. Enter an index name (e.g., `documents-openai`).\n+4. Set the dimension matching your embeddings (e.g., `1536` for OpenAI's text-embedding-3-small).\n+5. Select the distance metric (`cosine`, `euclidean`, or `l2`).\n+6. Click **Create**.\n+\n+### Via JavaScript SDK\n+\n+```typescript\n+import { createClient } from '@supabase/supabase-js'\n+\n+const supabase = createClient('https://your-project.supabase.co', 'your-service-key')\n+\n+const bucket = supabase.storage.vectors.from('embeddings')\n+\n+// Create an index\n+const { data, error } = await bucket.createIndex({\n+  indexName: 'documents-openai',\n+  dataType: 'float32',\n+  dimension: 1536,\n+  distanceMetric: 'cosine',\n+})\n+\n+if (error) {\n+  console.error('Error creating index:', error)\n+} else {\n+  console.log('Index created:', data)\n+}\n+```\n+\n+### Choosing the right metric\n+\n+Most modern embedding models work best with **cosine** distance:\n+\n+- **OpenAI** (text-embedding-3-small, text-embedding-3-large): Cosine\n+- **Cohere** (embed-english-v3.0): Cosine\n+- **Hugging Face** (sentence-transformers): Cosine\n+- **Google** (text-embedding-004): Cosine\n+- **Llama 2** embeddings: Cosine or L2\n+\n+**Tip**: Check your embedding model's documentation for the recommended distance metric.\n+\n+**Important**: Creating an index with incorrect dimensions will cause insert and query operations to fail.\n+\n+## Managing multiple indexes\n+\n+Create multiple indexes for different use cases or embedding models:\n+\n+```typescript\n+const bucket = supabase.storage.vectors.from('embeddings')\n+\n+// Index for OpenAI embeddings\n+await bucket.createIndex({\n+  indexName: 'documents-openai',\n+  dimension: 1536,\n+  distanceMetric: 'cosine',\n+  dataType: 'float32',\n+})\n+\n+// Index for Cohere embeddings\n+await bucket.createIndex({\n+  indexName: 'documents-cohere',\n+  dimension: 1024,\n+  distanceMetric: 'cosine',\n+  dataType: 'float32',\n+})\n+\n+// Index for different use case\n+await bucket.createIndex({\n+  indexName: 'images-openai',\n+  dimension: 1536,\n+  distanceMetric: 'cosine',\n+  dataType: 'float32',\n+})\n+\n+// List all indexes\n+const { data: indexes } = await bucket.listIndexes()\n+console.log('All indexes:', indexes)\n+```\n+\n+### Use cases for multiple indexes\n+\n+- **Different embedding models** - Store vectors from OpenAI, Cohere, and local models separately\n+- **Different domains** - Maintain separate indexes for documents, images, products, etc.\n+- **A/B testing** - Compare different embedding models side-by-side\n+- **Multi-language** - Keep language-specific embeddings separate\n+\n+## Listing and inspecting indexes\n+\n+### List all indexes in a bucket\n+\n+```typescript\n+const bucket = supabase.storage.vectors.from('embeddings')\n+\n+const { data: indexes, error } = await bucket.listIndexes()\n+\n+if (!error) {\n+  indexes?.forEach((index) => {\n+    console.log(`Index: ${index.name}`)\n+    console.log(`  Dimension: ${index.dimension}`)\n+    console.log(`  Distance: ${index.distanceMetric}`)\n+  })\n+}\n+```\n+\n+### Get index details\n+\n+```typescript\n+const { data: indexDetails, error } = await bucket.getIndex('documents-openai')\n+\n+if (!error && indexDetails) {\n+  console.log(`Index: ${indexDetails.name}`)\n+  console.log(`Created at: ${indexDetails.createdAt}`)\n+  console.log(`Dimension: ${indexDetails.dimension}`)\n+  console.log(`Distance metric: ${indexDetails.distanceMetric}`)\n+}\n+```\n+\n+## Deleting indexes\n+\n+Delete an index to free storage space:\n+\n+```typescript\n+const bucket = supabase.storage.vectors.from('embeddings')\n+\n+const { error } = await bucket.deleteIndex('documents-openai')\n+\n+if (error) {\n+  console.error('Error deleting index:', error)\n+} else {\n+  console.log('Index deleted successfully')\n+}\n+```\n+\n+### Before deleting an index\n+\n+**Warning**: Deleting an index is permanent and cannot be undone.\n+\n+- **Backup important data** - Export vectors before deletion if needed\n+- **Update applications** - Ensure no code references the deleted index\n+- **Check dependencies** - Verify no active queries use the index\n+- **Plan the deletion** - Do this during low-traffic periods\n+\n+### Immutable properties\n+\n+Once created, these properties **cannot be changed**:\n+\n+- **Dimension** - Must create new index with different dimension\n+- **Distance metric** - Cannot change after creation\n+- **Data type** - Currently only `float32` supported\n+\n+### Optimizing index performance\n+\n+```typescript\n+// Good - Appropriate batch size\n+const batch = vectors.slice(0, 250)\n+await index.putVectors({ vectors: batch })\n+\n+// Good - Filter metadata before query\n+const { data } = await index.queryVectors({\n+  queryVector,\n+  topK: 5,\n+  filter: { category: 'electronics' },\n+})\n+\n+// Avoid - Single vector inserts\n+for (const vector of vectors) {\n+  await index.putVectors({ vectors: [vector] })\n+}\n+\n+// Avoid - Returning unnecessary data\n+const { data } = await index.queryVectors({\n+  queryVector,\n+  topK: 1000, // Too many results\n+  returnData: true, // Include large embeddings\n+})\n+```\n+\n+## Next steps\n+\n+- [Store vectors in indexes](/docs/guides/storage/vector/storing-vectors)\n+- [Query vectors for similarity search](/docs/guides/storage/vector/querying-vectors)\n+- [Understand vector bucket limits](/docs/guides/storage/vector/limits)\n+- [Create vector buckets](/docs/guides/storage/vector/creating-vector-buckets)\ndiff --git a/apps/docs/public/img/storage/query-analytics-schema-name.png b/apps/docs/public/img/storage/query-analytics-schema-name.png\nnew file mode 100644\nindex 0000000000000..107ae48a70eb5\nBinary files /dev/null and b/apps/docs/public/img/storage/query-analytics-schema-name.png differ\ndiff --git a/apps/docs/public/img/storage/query-analytics-with-postgres.png b/apps/docs/public/img/storage/query-analytics-with-postgres.png\nnew file mode 100644\nindex 0000000000000..e7e5b1c01a6af\nBinary files /dev/null and b/apps/docs/public/img/storage/query-analytics-with-postgres.png differ\ndiff --git a/apps/studio/components/interfaces/Storage/Storage.constants.ts b/apps/studio/components/interfaces/Storage/Storage.constants.ts\nindex f38e691985fb4..9860334c7111b 100644\n--- a/apps/studio/components/interfaces/Storage/Storage.constants.ts\n+++ b/apps/studio/components/interfaces/Storage/Storage.constants.ts\n@@ -89,5 +89,5 @@ export const BUCKET_TYPES = {\n     docsUrl: `${DOCS_URL}/guides/storage/vectors`,\n   },\n }\n-\n+export const BUCKET_TYPE_KEYS = Object.keys(BUCKET_TYPES) as Array<keyof typeof BUCKET_TYPES>\n export const DEFAULT_BUCKET_TYPE: keyof typeof BUCKET_TYPES = 'files'\ndiff --git a/packages/config/ui.config.js b/packages/config/ui.config.js\nindex 836d8dba4c776..c7cff332eca25 100644\n--- a/packages/config/ui.config.js\n+++ b/packages/config/ui.config.js\n@@ -347,10 +347,10 @@ const uiConfig = {\n           'mask-image': 'linear-gradient(to left, white 98%, transparent 100%)',\n         },\n         'input[type=\"number\"]::-webkit-outer-spin-button, input[type=\"number\"]::-webkit-inner-spin-button':\n-        {\n-          '-webkit-appearance': 'none',\n-          margin: '0',\n-        },\n+          {\n+            '-webkit-appearance': 'none',\n+            margin: '0',\n+          },\n       })\n       addVariant('data-open-parent', '[data-state=\"open\"] &')\n       addVariant('data-closed-parent', '[data-state=\"closed\"] &')\ndiff --git a/supa-mdx-lint/Rule001HeadingCase.toml b/supa-mdx-lint/Rule001HeadingCase.toml\nindex 39a8cb4496761..5e559e3a6529f 100644\n--- a/supa-mdx-lint/Rule001HeadingCase.toml\n+++ b/supa-mdx-lint/Rule001HeadingCase.toml\n@@ -60,9 +60,11 @@ may_uppercase = [\n     \"Docker\",\n     \"Drain\",\n     \"Drizzle\",\n+\t\"DuckDB\",\n     \"Edge Functions?\",\n     \"Editor\",\n     \"Egress\",\n+\t\"Embeddings API\",\n     \"Enterprise\",\n     \"Enterprise Plan\",\n     \"Events\",\n@@ -148,6 +150,7 @@ may_uppercase = [\n     \"OrbStack\",\n     \"OrioleDB\",\n     \"PGAudit\",\n+\t\"Pandas\",\n     \"PgBouncer\",\n     \"Phoenix\",\n     \"Pro Plan\",\n@@ -227,6 +230,7 @@ may_uppercase = [\n     \"Vault\",\n     \"VSCode\",\n     \"Vecs\",\n+\t\"Vector\",\n     \"Vercel\",\n     \"Vercel Marketplace\",\n     \"Visual Studio Code\",\ndiff --git a/supa-mdx-lint/Rule003Spelling.toml b/supa-mdx-lint/Rule003Spelling.toml\nindex ed6eace5b1db6..bb972d24e2135 100644\n--- a/supa-mdx-lint/Rule003Spelling.toml\n+++ b/supa-mdx-lint/Rule003Spelling.toml\n@@ -31,6 +31,7 @@ allow_list = [\n     \"BootFailure\",\n     \"[Bb]reakpoints?\",\n     \"[Bb]uilt-ins?\",\n+\t\"[Cc]atalogs?\",\n     \"[Cc]hangelogs?\",\n     \"[Cc]odebases?\",\n     \"[Cc]odepaths?\",\n@@ -45,6 +46,7 @@ allow_list = [\n     \"[Cc]ryptography\",\n     \"[Cc]ryptosystem\",\n     \"[Cc]utover\",\n+\t\"[Dd]ata[Ff]rames?\",\n     \"[Dd]atasets?\",\n     \"[Dd]atasources?\",\n     \"[Dd]e facto\",\n@@ -52,6 +54,7 @@ allow_list = [\n     \"[Dd]evs?\",\n     \"[Dd]iff(s|ing|ed)?\",\n     \"[Dd]ropdown\",\n+\t\"DuckDB\",\n     \"EarlyDrop\",\n     \"[Ee]nqueues?\",\n     \"[Ee]ntrypoints?\",\n",
			"diffSize": 99073,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "897678caa16804358ed15af78d4f7d347c37d935",
			"message": "feat(docs): rewrite realtime protocol including version 2.0.0 (#40600)",
			"user": "edgurgel",
			"timestamp": "2025-11-24T20:53:43Z",
			"author": {
				"name": "Eduardo Gurgel",
				"email": "eduardo.gurgel@supabase.io",
				"username": "edgurgel"
			},
			"files": {
				"added": [],
				"modified": ["apps/docs/content/guides/realtime/protocol.mdx"],
				"removed": []
			},
			"diff": "diff --git a/apps/docs/content/guides/realtime/protocol.mdx b/apps/docs/content/guides/realtime/protocol.mdx\nindex 59aa688ce6d31..bc7bbae988aed 100644\n--- a/apps/docs/content/guides/realtime/protocol.mdx\n+++ b/apps/docs/content/guides/realtime/protocol.mdx\n@@ -12,7 +12,7 @@ To start the connection we use the WebSocket URL, which for:\n - self-hosted projects: `wss://<HOST>:<PORT>/socket/websocket?apikey=<API_KEY>`\n \n {/* supa-mdx-lint-disable-next-line Rule003Spelling */}\n-As an example, using the [websocat](https://github.com/vi/websocat), you would run the following command in your terminal:\n+As an example, using [websocat](https://github.com/vi/websocat), you would run the following command in your terminal:\n \n ```bash\n # With Supabase\n@@ -24,78 +24,209 @@ websocat \"wss://<HOST>:<PORT>/socket/websocket?apikey=<API_KEY>\"\n \n During this stage you can also set other URL params:\n \n-- `log_level`: sets the log level to be used by this connection to help you debug potential issues\n+- `vsn`: sets the protocol version. Possible values are `1.0.0` and `2.0.0`. Defaults to `1.0.0`.\n+- `log_level`: sets the log level to be used by this connection to help you debug potential issues. This only affects server side logs.\n \n-After this you would need to send the `phx_join` event to the server to join the Channel.\n+After connecting a `phx_join` event must be sent to the server to join a channel. The next sections outline the different messages types and events that are supported.\n \n ## Protocol messages\n \n-### Payload format\n+Messages can be serialized in different formats. The Realtime protocol supports two versions: `1.0.0` and `2.0.0`.\n \n-All messages sent to the server or received from the server follow the same structure:\n+## 1.0.0\n \n-```ts\n+Version 1.0.0 is extremely simple. It uses JSON as the serialization format for messages. The underlying WebSocket messages are all text frames.\n+\n+Messages contain the following fields:\n+\n+- `event`: The type of event being sent or received. Example `phx_join`, `postgres_changes`, `broadcast`, etc.\n+- `topic`: The topic to which the message belongs. This is a string that identifies the channel or context of the message.\n+- `payload`: The data associated with the event. This can be any JSON-serializable data structure, such as an object or an array.\n+- `ref`: A unique reference ID for the message. This is useful to track replies to a specific message.\n+- `join_ref`: A unique reference ID to uniquely identify a joined topic for pushes, broadcasts, replies, etc.\n+\n+Example:\n+\n+```json\n {\n-   \"event\": string,\n-   \"topic\": string,\n-   \"payload\": any,\n-   \"ref\": string\n+  \"topic\": \"realtime:presence-room\",\n+  \"event\": \"phx_join\",\n+  \"payload\": {\n+    \"config\": {\n+      \"broadcast\": {\n+        \"ack\": false,\n+        \"self\": false\n+      },\n+      \"presence\": {\n+        \"enabled\": false\n+      },\n+      \"private\": false\n+    }\n+  },\n+  \"ref\": \"1\",\n+  \"join_ref\": \"1\"\n }\n ```\n \n-- `event`: The type of event being sent or received. This can be a specific event like `phx_join`, `postgres_changes`, etc.\n-- `topic`: The topic to which the message belongs. This is usually a string that identifies the channel or context of the message.\n-- `payload`: The data associated with the event. This can be any JSON-serializable data structure, such as an object or an array.\n-- `ref`: A unique reference ID for the message. This is used to track the message and its response on the client side when a reply is needed to proceed.\n+## 2.0.0\n \n-### Event types\n+Version 2.0.0 uses text and binary WebSocket frames.\n \n-The following are the event types from the Realtime protocol:\n-| Event Type | Description | Client Sent | Server Sent | Requires Ref |\n-|------------|-------------|--------------|-------------|--------------|\n-| `phx_join` | Initial message to join a channel and configure features | ✅ | ⛔ | ✅ |\n-| `phx_close` | Message from server to signal channel closed | ⛔ | ✅ | ⛔ |\n-| `phx_leave` | Message to leave a channel | ✅ | ⛔ | ✅ |\n-| `phx_error` | Error message sent by the server when an error occurs | ⛔ | ✅ | ⛔ |\n-| `phx_reply` | Response to a `phx_join` or other requests | ⛔ | ✅ | ⛔ |\n-| `heartbeat` | Heartbeat message to keep the connection alive | ✅ | ✅ | ✅ |\n-| `access_token` | Message to update the access token | ✅ | ⛔ | ⛔ |\n-| `system` | System messages to inform about the status of the Postgres subscription | ⛔ | ✅ | ⛔ |\n-| `broadcast` | Broadcast message sent to all clients in a channel | ✅ | ✅ | ⛔ |\n-| `presence` | Presence state update sent after joining a channel | ✅ | ⛔ | ⛔ |\n-| `presence_state` | Presence state sent by the server on join | ⛔ | ✅ | ⛔ |\n-| `presence_diff` | Presence state diff update sent after a change in presence state | ⛔ | ✅ | ⛔ |\n-| `postgres_changes` | Postgres CDC message containing changes to the database | ⛔ | ✅ | ⛔ |\n+### Text frames\n \n-Each one of these events has a specific payload field structure that defines the data it carries. Below are the details for each event type payload.\n+Text frames are always JSON encoded, but unlike version 1.0.0, they use a JSON array where the element order must be exactly:\n \n-#### Payload of phx_join\n+- `join_ref`\n+- `ref`\n+- `topic`\n+- `event`\n+- `payload`\n \n-This is the initial message required to join a channel. The client sends this message to the server to join a specific topic and configure the features it wants to use, such as Postgres changes, presence, and broadcasting.\n+Example:\n \n-```ts\n-{\n-   \"config\": {\n+```json\n+[\n+  \"1\",\n+  \"1\",\n+  \"realtime:presence-room\",\n+  \"phx_join\",\n+  {\n+    \"config\": {\n       \"broadcast\": {\n-            \"ack\": boolean,\n-            \"self\": boolean\n-            },\n+        \"ack\": false,\n+        \"self\": false\n+      },\n       \"presence\": {\n-         \"enabled\": boolean,\n-         \"key\": string\n-         },\n-      \"postgres_changes\": [\n-                  {\n-                     \"event\": string,\n-                     \"schema\": string,\n-                     \"table\": string,\n-                     \"filter\": string\n-                  }\n-            ]\n-      \"private\": boolean\n-\n-   },\n-   \"access_token\": string\n+        \"enabled\": false\n+      },\n+      \"private\": false\n+    }\n+  }\n+]\n+```\n+\n+### Binary frames\n+\n+The two special message types have a well defined binary format where the first byte defines the type of message. Both are used to send and receive broadcast events. See the [client](#client-sent-events) and [server](#server-sent-events) sent events for more details.\n+\n+| Code | Type                | Description                   |\n+| ---- | ------------------- | ----------------------------- |\n+| 3    | USER_BROADCAST_PUSH | User-initiated broadcast push |\n+| 4    | USER_BROADCAST      | User broadcast message        |\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### User Broadcast Push\n+\n+```\n+ 0                   1                   2                   3\n+ 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+|  Type (0x03)  | Join Ref Size |   Ref Size    |  Topic Size   |\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+|User Event Size| Payload Enc.  |  Join Ref (variable length)   |\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+|                      Ref (variable length)                    |\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+|                     Topic (variable length)                   |\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+|                  User Event (variable length)                 |\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+|                User Payload (variable length)                 |\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+```\n+\n+**Field Descriptions:**\n+\n+- **Type**: 1 byte, value = 0x03\n+- **Join Ref Size**: 1 byte, size of join reference string (max 255)\n+- **Ref Size**: 1 byte, size of reference string (max 255)\n+- **Topic Size**: 1 byte, size of topic string (max 255)\n+- **User Event Size**: 1 byte, size of user event string (max 255)\n+- **Payload Encoding**: 1 byte (0 = binary, 1 = JSON)\n+- **Join Ref**: Variable length string\n+- **Ref**: Variable length string\n+- **Topic**: Variable length string\n+- **User Event**: Variable length string\n+- **User Payload**: Variable length payload data\n+\n+#### User Broadcast\n+\n+```\n+ 0                   1                   2                   3\n+ 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+|  Type (0x04)  |  Topic Size   |User Event Size| Metadata Size |\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+| Payload Enc.  |          Topic (variable length)              |\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+|                  User Event (variable length)                 |\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+|                   Metadata (variable length)                  |\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+|                User Payload (variable length)                 |\n++-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n+```\n+\n+**Field Descriptions:**\n+\n+- **Type**: 1 byte, value = 0x04\n+- **Topic Size**: 1 byte, size of topic string (max 255)\n+- **User Event Size**: 1 byte, size of user event string (max 255)\n+- **Metadata Size**: 1 byte, size of metadata JSON string (max 255)\n+- **Payload Encoding**: 1 byte (0 = binary, 1 = JSON)\n+- **Topic**: Variable length string\n+- **User Event**: Variable length string\n+- **Metadata**: Variable length JSON string\n+- **User Payload**: Variable length payload data\n+\n+## Event types\n+\n+Messages for all events are encoded as text frames using JSON except with the `broadcast` event type which can happen on both text and binary frames.\n+\n+### Client sent events\n+\n+| Event Type     | Description                                              | Requires Ref | Requires Join Ref |\n+| -------------- | -------------------------------------------------------- | ------------ | ----------------- |\n+| `phx_join`     | Initial message to join a channel and configure features | ✅           | ✅                |\n+| `phx_leave`    | Message to leave a channel                               | ✅           | ✅                |\n+| `heartbeat`    | Heartbeat message to keep the connection alive           | ✅           | ⛔                |\n+| `access_token` | Message to update the access token                       | ✅           | ✅                |\n+| `broadcast`    | Broadcast message sent to all clients in a channel       | ✅           | ✅                |\n+| `presence`     | Presence state update sent after joining a channel       | ✅           | ✅                |\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### phx_join\n+\n+This is the initial message required to join a channel. The client sends this message to the server to join a specific topic and configure the features it wants to use, such as Postgres changes, Presence, and Broadcast. The payload of the `phx_join` event contains the configuration options for the channel.\n+\n+```ts\n+{\n+  \"config\": {\n+    \"broadcast\": {\n+      \"ack\": boolean,\n+      \"self\": boolean,\n+      \"replay\" : {\n+        \"since\": integer,\n+        \"limit\": integer\n+      }\n+    },\n+    \"presence\": {\n+      \"enabled\": boolean,\n+      \"key\": string\n+    },\n+    \"postgres_changes\": [\n+      {\n+        \"event\": string,\n+        \"schema\": string,\n+        \"table\": string,\n+        \"filter\": string\n+      }\n+    ]\n+    \"private\": boolean\n+  },\n+  \"access_token\": string\n }\n ```\n \n@@ -104,6 +235,9 @@ This is the initial message required to join a channel. The client sends this me\n   - `broadcast`: Configuration options for broadcasting messages\n     - `ack`: Acknowledge broadcast messages\n     - `self`: Include the sender in broadcast messages\n+    - `replay`: Configuration options for broadcast replay (Optional)\n+      - `since`: Replay messages since a specific timestamp in milliseconds\n+      - `limit`: Limit the number of replayed messages (Optional)\n   - `presence`: Configuration options for presence tracking\n     - `enabled`: Whether presence tracking is enabled for this channel\n     - `key`: Key to be used for presence tracking, if not specified or empty, a UUID will be generated and used\n@@ -112,23 +246,243 @@ This is the initial message required to join a channel. The client sends this me\n     - `schema`: Schema of the table to listen to, accepts `*` wildcard to listen to all schemas\n     - `table`: Table of the database to listen to, accepts `*` wildcard to listen to all tables\n     - `filter`: Filter to be used when pulling changes from database. Read more about filters in the usage docs for [Postgres Changes](/docs/guides/realtime/postgres-changes?queryGroups=language&language=js#filtering-for-specific-changes)\n-- `access_token`: Optional access token for authentication, if not provided, the server will use the default access token.\n+- `access_token`: Optional access token for authentication, if not provided, the server will use the API key.\n \n-#### Payload of phx_close\n+Example on protocol version `2.0.0`:\n \n-This message is sent by the server to signal that the channel has been closed. Payload will be empty object.\n+```json\n+[\n+  \"3\",\n+  \"5\",\n+  \"realtime:chat-room\",\n+  \"phx_join\",\n+  {\n+    \"config\": {\n+      \"broadcast\": {\n+        \"ack\": false,\n+        \"self\": true,\n+        \"replay\": {\n+          \"since\": 1763407103911,\n+          \"limit\": 10\n+        }\n+      },\n+      \"presence\": {\n+        \"key\": \"user_id-827\",\n+        \"enabled\": true\n+      },\n+      \"postgres_changes\": [],\n+      \"private\": true\n+    }\n+  }\n+]\n+```\n \n-#### Payload of phx_leave\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### phx_leave\n \n This message is sent by the client to leave a channel. It can be used to clean up resources or stop listening for events on that channel. Payload should be empty object.\n \n-#### Payload of phx_error\n+Example on protocol version `2.0.0`:\n+\n+```json\n+[\"1\", \"3\", \"realtime:avatar-stack-demo\", \"phx_leave\", {}]\n+```\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### heartbeat\n+\n+The heartbeat message should be sent at least every 25 seconds to avoid a connection timeout. Payload should be an empty object.\n+\n+For heartbeat, the topic `phoenix` is used as this special message is not connected to a specific channel.\n+\n+Example on protocol version `2.0.0`:\n+\n+```json\n+[null, \"26\", \"phoenix\", \"heartbeat\", {}]\n+```\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### access_token\n+\n+Used to setup a new token to be used by Realtime for authentication and to refresh the token to prevent a private channel from closing when the token expires.\n+\n+```ts\n+{\n+   \"access_token\": string\n+}\n+```\n+\n+- `access_token`: The new access token to be used for authentication. Either to change it or to refresh it.\n+\n+Example on protocol version `2.0.0`:\n+\n+```json\n+[\n+  \"10\",\n+  \"1\",\n+  \"realtime:chat-room\",\n+  \"access_token\",\n+  {\n+    \"access_token\": \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiYWRtaW4iOnRydWUsImlhdCI6MTUxNjIzOTAyMn0.KMUFsIDTnFmyG3nMiGM6H9FNFUROf3wh7SmqJp-QV30\"\n+  }\n+]\n+```\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### broadcast (text frame)\n+\n+Used to send a broadcast event to all clients in a channel.\n+\n+The `payload` field contains the event name and the data to broadcast.\n+\n+```ts\n+{\n+   \"event\": string,\n+   \"payload\": json,\n+   \"type\": \"broadcast\"\n+}\n+```\n+\n+- `event`: The name of the user event to broadcast.\n+- `payload`: The user data associated with the event, which can be any JSON-serializable data structure.\n+- `type`: The type of message, which must always be `broadcast`.\n+\n+Example on protocol version `2.0.0`:\n+\n+```json\n+[\n+  \"10\",\n+  \"1\",\n+  \"realtime:chat-room\",\n+  \"broadcast\",\n+  {\n+    \"event\": \"user-event\",\n+    \"type\": \"broadcast\",\n+    \"payload\": {\n+      \"content\": \"Hello, World!\",\n+      \"createdAt\": \"2025-11-17T21:14:14Z\",\n+      \"id\": \"9b823349-71c0-465b-9a83-a63aa2a9ae6d\",\n+      \"username\": \"VCSHLD556nQD-B-vUTJJ3\"\n+    }\n+  }\n+]\n+```\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### broadcast (binary frame)\n+\n+See the [User Broadcast Push](#user-broadcast-push) section for the binary frame structure.\n+\n+This message is a streamlined version of the text frame broadcast event that also supports non-JSON payloads.\n+Below is the same example from the previous section, showing the binary frame structure with hexadecimal values for the header and plain text for the remaining fields:\n+\n+- Join Ref: `10`\n+- Ref: `1`\n+- Topic: `realtime:chat-room`\n+- Payload encoding being JSON\n+- User Event: `user-event`\n+- User Payload\n+\n+```\n+0x03                      // Type\n+0x02                      // Join Ref Size\n+0x01                      // Ref Size\n+0x12                      // Topic Size\n+0x0A                      // User Event Size\n+0x01                      // Payload Encoding (1 = JSON)\n+10                        // Actual Join Ref\n+1                         // Actual Ref\n+realtime:chat-room        // Topic\n+user-event                // User Event\n+{                         // User Event Payload\n+  \"content\": \"Hello, World!\",\n+  \"createdAt\": \"2025-11-17T21:14:14Z\",\n+  \"id\": \"9b823349-71c0-465b-9a83-a63aa2a9ae6d\",\n+  \"username\": \"VCSHLD556nQD-B-vUTJJ3\"\n+}\n+```\n+\n+The payload encoding is just a hint for the client to know if the payload should be treated as JSON or not.\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### presence\n+\n+Used to send presence metadata after joining a channel. The payload contains the presence information to be tracked by the server.\n+This metadata is then sent back to all clients in the channel via `presence_state` and `presence_diff` events.\n+\n+```ts\n+{\n+   \"type\": \"presence\",\n+   \"event\": \"track\",\n+   \"payload\": json\n+}\n+```\n+\n+Example on protocol version `2.0.0`:\n+\n+```json\n+[\n+  \"1\",\n+  \"5\",\n+  \"realtime:presence-room\",\n+  \"presence\",\n+  {\n+    \"type\": \"presence\",\n+    \"event\": \"track\",\n+    \"payload\": {\n+      \"name\": \"Alice\",\n+      \"color\": \"hsl(29, 100%, 70%)\"\n+    }\n+  }\n+]\n+```\n+\n+### Server sent events\n+\n+| Event Type         | Description                                                             | Requires Ref | Requires Join Ref |\n+| ------------------ | ----------------------------------------------------------------------- | ------------ | ----------------- |\n+| `phx_close`        | Message from server to signal channel closed                            | ✅           | ✅                |\n+| `phx_error`        | Error message sent by the server when an error occurs                   | ✅           | ✅                |\n+| `phx_reply`        | Response to a `phx_join` or other requests                              | ✅           | ✅\\*              |\n+| `system`           | System messages to inform about the status of the Postgres subscription | ⛔           | ⛔                |\n+| `broadcast`        | Broadcast message sent to all clients in a channel                      | ⛔           | ⛔                |\n+| `presence_state`   | Presence state sent by the server on join                               | ⛔           | ⛔                |\n+| `presence_diff`    | Presence state diff update sent after a change in presence state        | ⛔           | ⛔                |\n+| `postgres_changes` | Postgres CDC message containing changes to the database                 | ⛔           | ⛔                |\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### phx_close\n+\n+This message is sent by the server to signal that the channel has been closed. Payload will be empty object.\n+\n+Example on protocol version `2.0.0`:\n+\n+```json\n+[\"3\", \"3\", \"realtime:avatar-stack-demo\", \"phx_close\", {}]\n+```\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### phx_error\n \n This message is sent by the server when an unexpected error occurs in the channel. Payload will be an empty object\n \n-#### Payload of phx_reply\n+```json\n+[\"3\", \"3\", \"realtime:avatar-stack-demo\", \"phx_error\", {}]\n+```\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### phx_reply\n \n-These messages are sent by the server on messages that expect a response. Their response can vary with the type of usage.\n+The server sends these messages in response to client requests that require acknowledgment.\n \n ```ts\n {\n@@ -140,7 +494,7 @@ These messages are sent by the server on messages that expect a response. Their\n - `status`: The status of the response, can be `ok` or `error`.\n - `response`: The response data, which can vary based on the event that was replied to\n \n-##### Payload of phx_reply response to phx_join\n+`phx_join` has a specific response structure outlined below.\n \n Contains the status of the join request and any additional information requested in the `phx_join` payload.\n \n@@ -163,17 +517,35 @@ Contains the status of the join request and any additional information requested\n   - `schema`: The schema of the table the client is subscribed to\n   - `table`: The table the client is subscribed to\n \n-##### Payload of phx_reply response to presence\n+Example on protocol version `2.0.0`:\n \n-When replying to presence events, it returns an empty object.\n-\n-##### Payload of phx_reply response on heartbeat\n+```json\n+[\n+  \"1\",\n+  \"1\",\n+  \"realtime:chat-room\",\n+  \"phx_reply\",\n+  {\n+    \"status\": \"ok\",\n+    \"response\": {\n+      \"postgres_changes\": [\n+        {\n+          \"id\": 106243155,\n+          \"event\": \"*\",\n+          \"schema\": \"public\",\n+          \"table\": \"test\"\n+        }\n+      ]\n+    }\n+  }\n+]\n+```\n \n-When replying to heartbeat events, it returns an empty object.\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n \n-#### Payload of system\n+#### system\n \n-System messages are sent by the server to inform the client about the status of Realtime channel subscriptions.\n+The server sends system messages to inform clients about the status of their Realtime channel subscriptions.\n \n ```ts\n {\n@@ -189,35 +561,116 @@ System messages are sent by the server to inform the client about the status of\n - `extension`: The extension that sent the message.\n - `channel`: The channel to which the message belongs, such as `realtime:room1`.\n \n-#### Payload of heartbeat\n-\n-The heartbeat message should be sent at least every 25 seconds to avoid a connection timeout. Payload should be empty object.\n-\n-For heartbeat, use the topic `phoenix` as it needs to be sent to the WebSocket server itself and not to a channel:\n+Example on protocol version `2.0.0`:\n \n ```json\n-{ \"topic\": \"phoenix\", \"event\": \"heartbeat\", \"payload\": {}, \"ref\": \"8\" }\n+[\n+  \"13\",\n+  null,\n+  \"realtime:chat-room\",\n+  \"system\",\n+  {\n+    \"message\": \"Subscribed to PostgreSQL\",\n+    \"status\": \"ok\",\n+    \"extension\": \"postgres_changes\",\n+    \"channel\": \"main\"\n+  }\n+]\n ```\n \n-#### Payload of access_token\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### broadcast (text frame)\n+\n+{/* supa-mdx-lint-disable-next-line Rule003Spelling */}\n \n-Used to setup a new token to be used by Realtime for authentication and to refresh the token to prevent the channel from closing.\n+This is the structure of broadcast events received by all clients subscribed to a channel. The `payload` field contains the event name and data that was broadcasted.\n \n ```ts\n {\n-   \"access_token\": string\n+  \"event\": string,\n+  \"meta\" : {\n+    \"id\" : uuid,\n+    \"replayed\" : boolean\n+  },\n+  \"payload\": json,\n+  \"type\": \"broadcast\"\n }\n ```\n \n-- `access_token`: The new access token to be used for authentication. Either to change it or to refresh it.\n+- `event`: The name of the user event to broadcast.\n+- `meta`: Metadata about the broadcast message. Not always present.\n+  - `id`: A unique identifier for the broadcast message in UUID format.\n+  - `replayed`: A boolean indicating whether the message is a replayed message. Not always present\n+- `payload`: The user data associated with the event, which can be any JSON-serializable data structure.\n+- `type`: The type of message, which must always be `broadcast` for broadcast messages.\n+\n+Example on protocol version `2.0.0`:\n+\n+```json\n+[\n+  null,\n+  null,\n+  \"realtime:chat-room\",\n+  \"broadcast\",\n+  {\n+    \"event\": \"message\",\n+    \"type\": \"broadcast\",\n+    \"meta\": {\n+      \"id\": \"006554ce-d22d-469c-877a-88bef47214a3\"\n+    },\n+    \"payload\": {\n+      \"id\": \"513edcc1-4cbc-4274-aa26-c195f7e8c090\",\n+      \"content\": \"oi\",\n+      \"username\": \"hpK9jN2iY-I2HioHWr5ml\",\n+      \"createdAt\": \"2025-11-18T22:44:29Z\"\n+    }\n+  }\n+]\n+```\n \n-#### Payload of postgres_changes\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n \n-Server sent message with a change from a listened schema and table. This message is sent when a change occurs in the database that the client is subscribed to. The payload contains the details of the change, including the schema, table, event type, and the new and old values.\n+#### broadcast (binary frame)\n+\n+See the [User Broadcast](#user-broadcast) section for the binary frame structure.\n+\n+This message is a streamlined version of the text frame broadcast event that also supports non-JSON payloads.\n+Below is the same example from the previous section, showing the binary frame structure with hexadecimal values for the header and plain text for the remaining fields:\n+\n+- Topic: `realtime:chat-room`\n+- Payload encoding being JSON\n+- Metadata: `{\"id\":\"006554ce-d22d-469c-877a-88bef47214a3\"}`\n+- User Event: `message`\n+- User Payload\n+\n+```\n+0x04                                          // Type\n+0x12                                          // Topic Size\n+0x07                                          // User Event Size\n+0x2D                                          // Metadata Size\n+0x01                                          // Payload Encoding (1 = JSON)\n+realtime:chat-room                            // Topic\n+message                                       // User Event\n+{\"id\":\"006554ce-d22d-469c-877a-88bef47214a3\"} // Metadata\n+{                                             // User Event Payload\n+  \"id\": \"513edcc1-4cbc-4274-aa26-c195f7e8c090\",\n+  \"content\": \"oi\",\n+  \"username\": \"hpK9jN2iY-I2HioHWr5ml\",\n+  \"createdAt\": \"2025-11-18T22:44:29Z\"\n+}\n+```\n+\n+The metadata field is JSON encoded. The payload encoding is just a hint for the client to know if the payload should be treated as JSON or not.\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n+\n+#### postgres_changes\n+\n+The server sends this message when a database change occurs in a subscribed schema and table. The payload contains the details of the change, including the schema, table, event type, and the new and old records.\n \n ```ts\n {\n-   ,\n    \"ids\": [\n       number\n    ],\n@@ -225,53 +678,83 @@ Server sent message with a change from a listened schema and table. This message\n       \"schema\": string,\n       \"table\": string,\n       \"commit_timestamp\": string,\n-      \"eventType\": \"*\" | \"INSERT\" | \"UPDATE\" | \"DELETE\",\n-      \"new\": {\n+      \"type\": \"*\" | \"INSERT\" | \"UPDATE\" | \"DELETE\",\n+      \"columns\": [\n+        {\n+          \"name\": string,\n+          \"type\": string\n+        }\n+      ]\n+      \"record\": {\n          [key: string]: boolean | number | string | null\n       },\n-      \"old\": {\n+      \"old_record\": {\n          [key: string]: boolean | number | string | null\n       },\n-      \"errors\": string | null,\n-      \"latency\": number\n+      \"errors\": string | null\n    }\n }\n ```\n \n-- `ids`: An array of unique identifiers for the changes that occurred.\n+- `ids`: An array of unique identifiers matching the subscription when joining the channel.\n - `data`: An object containing the details of the change:\n   - `schema`: The schema of the table where the change occurred.\n   - `table`: The table where the change occurred.\n   - `commit_timestamp`: The timestamp when the change was committed to the database.\n-  - `eventType`: The type of event that occurred, such as `INSERT`, `UPDATE`, `DELETE`, or `*` for all events.\n-  - `new`: An object representing the new values after the change, with keys as column names and values as their corresponding values.\n-  - `old`: An object representing the old values before the change, with keys as column names and values as their corresponding values.\n+  - `type`: The type of event that occurred, such as `INSERT`, `UPDATE`, `DELETE`, or `*` for all events.\n+  - `columns`: An array of objects representing the columns of the table, each containing:\n+    - `name`: The name of the column.\n+    - `type`: The data type of the column.\n+  - `record`: An object representing the new values after the change, with keys as column names and values as their corresponding values.\n+  - `old_record`: An object representing the old values before the change, with keys as column names and values as their corresponding values.\n   - `errors`: Any errors that occurred during the change, if applicable.\n-  - `latency`: The latency of the change event, in milliseconds.\n \n-### Payload of broadcast\n-\n-Structure of the broadcast event to be sent to all clients in a channel. The `payload` field contains the event name and the data to broadcast.\n-\n-```ts\n-{\n-   \"event\": string,\n-   \"payload\": json,\n-   \"type\": \"broadcast\"\n-}\n+```json\n+[\n+  null,\n+  null,\n+  \"realtime:chat-room\",\n+  \"postgres_changes\",\n+  {\n+    \"ids\": [104868189],\n+    \"data\": {\n+      \"schema\": \"public\",\n+      \"table\": \"test\",\n+      \"commit_timestamp\": \"2025-11-19T00:22:40.877Z\",\n+      \"type\": \"UPDATE\",\n+      \"columns\": [\n+        {\n+          \"name\": \"id\",\n+          \"type\": \"int8\"\n+        },\n+        {\n+          \"name\": \"created_at\",\n+          \"type\": \"timestamptz\"\n+        },\n+        {\n+          \"name\": \"text\",\n+          \"type\": \"text\"\n+        }\n+      ],\n+      \"record\": {\n+        \"id\": 46,\n+        \"text\": \"content\",\n+        \"created_at\": \"2025-11-03T09:32:55+00:00\"\n+      },\n+      \"old_record\": {\n+        \"id\": 46\n+      },\n+      \"errors\": null\n+    }\n+  }\n+]\n ```\n \n-- `event`: The name of the event to broadcast.\n-- `payload`: The data associated with the event, which can be any JSON-serializable data structure.\n-- `type`: The type of message, which is always `broadcast` for broadcast messages.\n-\n-### Payload of presence\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n \n-Presence messages are used to track the online status of clients in a channel. When a client joins or leaves a channel, a presence message is sent to all clients in that channel.\n+#### presence_state\n \n-### Payload of presence_state\n-\n-After joining, the server sends a `presence_state` message to a client with presence information. The payload field contains keys in UUID format, where each key represents a client and its value is a JSON object containing information about that client.\n+After joining, the server sends a `presence_state` message to a client with presence information. The payload field contains keys, where each key represents a client and its value is a JSON object containing information about that client. The key is defined by the client when joining the channel. If not specified, a UUID is automatically generated.\n \n ```ts\n {\n@@ -279,46 +762,123 @@ After joining, the server sends a `presence_state` message to a client with pres\n       metas: [\n          {\n             phx_ref: string,\n-            name: string,\n-            t: float\n+            [key: string]: any\n          }\n       ]\n    }\n }\n ```\n \n-- `key`: The UUID of the client.\n+- `key`: The client key.\n - `metas`: An array of metadata objects for the client, each containing:\n   - `phx_ref`: A unique reference ID for the metadata.\n-  - `name`: The name of the client.\n-  - `t`: A timestamp indicating when the client joined or last updated its presence state.\n+  - Any other custom fields defined by the client, such as `name`.\n+\n+Example on protocol version `2.0.0`:\n+\n+```json\n+[\n+  \"4\",\n+  null,\n+  \"realtime:cursor-room\",\n+  \"presence_state\",\n+  {\n+    \"2wCojG1xWgxG2ZxwocvSX\": {\n+      \"metas\": [\n+        {\n+          \"phx_ref\": \"GHlA1fShRjMmZhnL\",\n+          \"color\": \"hsl(204, 100%, 70%)\",\n+          \"key\": \"2wCojG1xWgxG2ZxwocvSX\"\n+        }\n+      ]\n+    },\n+    \"6eorYR7andHiq-7tCkmxQ\": {\n+      \"metas\": [\n+        {\n+          \"phx_ref\": \"GHk99Q_ez6-GzaeG\",\n+          \"color\": \"hsl(7, 100%, 70%)\",\n+          \"key\": \"6eorYR7andHiq-7tCkmxQ\"\n+        }\n+      ]\n+    },\n+    \"FOeQUamq3OLOWAAZK8iH3\": {\n+      \"metas\": [\n+        {\n+          \"phx_ref\": \"GHk-wA8Z61GGzeoG\",\n+          \"color\": \"hsl(212, 100%, 70%)\",\n+          \"key\": \"FOeQUamq3OLOWAAZK8iH3\"\n+        }\n+      ]\n+    }\n+  }\n+]\n+```\n+\n+{/* supa-mdx-lint-disable-next-line Rule001HeadingCase */}\n \n-### Payload of presence_diff\n+#### presence_diff\n \n-After a change to the presence state, such as a client joining or leaving, the server sends a presence_diff message to update the client's view of the presence state. The payload field contains two keys, `joins` and `leaves`, which represent clients that have joined and left, respectively. The values associated with each key are UUIDs of the clients.\n+After a change to the presence state, such as a client joining or leaving, the server sends a presence_diff message to update the client's view of the presence state. The payload field contains two keys, `joins` and `leaves`, which represent clients that have joined and left, respectively. Each key is either specified by the client when joining the channel or automatically generated as a UUID.\n \n ```ts\n {\n-   \"joins\": {\n-      metas: [{\n-         phx_ref: string,\n-         name: string,\n-         t: float\n-      }]\n-   },\n-   \"leaves\": {\n-      metas: [{\n-         phx_ref: string,\n-         name: string,\n-         t: float\n-      }]\n-   }\n+  \"joins\": {\n+    [key: string]: {\n+      metas: [\n+        {\n+          phx_ref: string,\n+          [key: string]: any\n+        }\n+      ]\n+    }\n+  },\n+  \"leaves\": {\n+    [key: string]: {\n+      metas: [\n+        {\n+          phx_ref: string,\n+          [key: string]: any\n+        }\n+      ]\n+    }\n+  }\n }\n ```\n \n - `joins`: An object containing metadata for clients that have joined the channel, with keys as UUIDs and values as metadata objects.\n - `leaves`: An object containing metadata for clients that have left the channel, with keys as UUIDs and values as metadata objects.\n \n-## REST API\n+Example on protocol version `2.0.0`:\n \n-The Realtime protocol is primarily designed for WebSocket communication, but it can also be accessed via a REST API. This allows you to interact with the Realtime service using standard HTTP methods.\n+```json\n+[\n+  null,\n+  null,\n+  \"realtime:cursor-room\",\n+  \"presence_diff\",\n+  {\n+    \"joins\": {\n+      \"XnAJXkZVEJuBYZcp9GCG5\": {\n+        \"metas\": [\n+          {\n+            \"phx_ref\": \"GHlE8VLvxuKGzQJN\",\n+            \"color\": \"hsl(60, 100%, 70%)\",\n+            \"user\": \"123\"\n+          }\n+        ]\n+      }\n+    },\n+    \"leaves\": {\n+      \"ouCsaiOdKZ9yauoy4x5pv\": {\n+        \"metas\": [\n+          {\n+            \"phx_ref\": \"GHlE8HyhSPAmZgdB\",\n+            \"color\": \"hsl(72, 100%, 70%)\",\n+            \"user\": \"456\"\n+          }\n+        ]\n+      }\n+    }\n+  }\n+]\n+```\n",
			"diffSize": 35435,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "7747ef0b294fbe89ad5cc7faf41b0175be96d386",
			"message": "fix filtering in events page (#40697)\n\n* fix filtering in events page\n\n* make agency on-demand",
			"user": "stylessh",
			"timestamp": "2025-11-24T19:01:24Z",
			"author": {
				"name": "Alan Daniel",
				"email": "stylesshjs@gmail.com",
				"username": "stylessh"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/www/_events/2025-11-20-supabase-agency-webinar.mdx",
					"apps/www/app/events/context.tsx",
					"apps/www/app/events/page.tsx",
					"apps/www/components/Events/new/EventBanner.tsx",
					"apps/www/components/Events/new/EventClientRenderer.tsx",
					"apps/www/components/Events/new/EventList.tsx",
					"apps/www/lib/events.ts"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/www/_events/2025-11-20-supabase-agency-webinar.mdx b/apps/www/_events/2025-11-20-supabase-agency-webinar.mdx\nindex 25e633aeb1f81..d3e034d306b7b 100644\n--- a/apps/www/_events/2025-11-20-supabase-agency-webinar.mdx\n+++ b/apps/www/_events/2025-11-20-supabase-agency-webinar.mdx\n@@ -8,7 +8,7 @@ meta_description: >-\n   Learn how leading agencies use Postgres expertise and strategic services to\n   command premium pricing while competitors race to the bottom on AI-built MVPs.\n type: webinar\n-onDemand: false\n+onDemand: true\n date: '2025-11-20T07:00:00.000-08:00'\n timezone: America/Los_Angeles\n duration: 45 mins\ndiff --git a/apps/www/app/events/context.tsx b/apps/www/app/events/context.tsx\nindex 5f847f6afa794..eddb07b5d232f 100644\n--- a/apps/www/app/events/context.tsx\n+++ b/apps/www/app/events/context.tsx\n@@ -2,13 +2,14 @@\n \n import { createContext, useContext, useState, useEffect, useMemo, ReactNode } from 'react'\n import { SupabaseEvent, SUPABASE_HOST } from '~/lib/eventsTypes'\n-import { cover } from 'three/src/extras/TextureUtils.js'\n \n interface EventsContextValue {\n   // Events data\n   allEvents: SupabaseEvent[]\n   filteredEvents: SupabaseEvent[]\n+  filteredOnDemandEvents: SupabaseEvent[]\n   staticEvents: SupabaseEvent[]\n+  onDemandEvents: SupabaseEvent[]\n   lumaEvents: SupabaseEvent[]\n   featuredEvent: SupabaseEvent | undefined\n \n@@ -30,9 +31,10 @@ const EventsContext = createContext<EventsContextValue | undefined>(undefined)\n interface EventsProviderProps {\n   children: ReactNode\n   staticEvents: SupabaseEvent[]\n+  onDemandEvents: SupabaseEvent[]\n }\n \n-export function EventsProvider({ children, staticEvents }: EventsProviderProps) {\n+export function EventsProvider({ children, staticEvents, onDemandEvents }: EventsProviderProps) {\n   const [lumaEvents, setLumaEvents] = useState<SupabaseEvent[]>([])\n   const [isLoading, setIsLoading] = useState(true)\n   const [searchQuery, setSearchQuery] = useState('')\n@@ -99,9 +101,12 @@ export function EventsProvider({ children, staticEvents }: EventsProviderProps)\n   }, [staticEvents, lumaEvents])\n \n   // Calculate categories with counts\n+  // - Webinar: count only upcoming webinars (not on-demand)\n+  // - On-demand: count only on-demand events\n   const categories = useMemo(() => {\n     const categoryCounts: { [key: string]: number } = { all: 0 }\n \n+    // Count upcoming events (excluding on-demand)\n     allEvents.forEach((event) => {\n       categoryCounts.all += 1\n \n@@ -110,8 +115,15 @@ export function EventsProvider({ children, staticEvents }: EventsProviderProps)\n       })\n     })\n \n+    // Count on-demand events separately\n+    onDemandEvents.forEach((event) => {\n+      categoryCounts.all += 1\n+      // Add to 'on-demand' category instead of 'webinar'\n+      categoryCounts['on-demand'] = (categoryCounts['on-demand'] || 0) + 1\n+    })\n+\n     return categoryCounts\n-  }, [allEvents])\n+  }, [allEvents, onDemandEvents])\n \n   // Toggle category selection\n   const toggleCategory = (category: string) => {\n@@ -135,8 +147,13 @@ export function EventsProvider({ children, staticEvents }: EventsProviderProps)\n     })\n   }\n \n-  // Filter events by search query and category\n+  // Filter upcoming events by search query and category\n   const filteredEvents = useMemo(() => {\n+    // If 'on-demand' is selected, don't show upcoming events\n+    if (selectedCategories.includes('on-demand') && !selectedCategories.includes('all')) {\n+      return []\n+    }\n+\n     let filtered = allEvents\n \n     // Filter by categories (multiple selection)\n@@ -167,6 +184,31 @@ export function EventsProvider({ children, staticEvents }: EventsProviderProps)\n     })\n   }, [allEvents, selectedCategories, searchQuery])\n \n+  // Filter on-demand events separately by search query and category\n+  const filteredOnDemandEvents = useMemo(() => {\n+    // If specific categories are selected (not 'all' and not 'on-demand'), don't show on-demand events\n+    if (!selectedCategories.includes('all') && !selectedCategories.includes('on-demand')) {\n+      return []\n+    }\n+\n+    let filtered = onDemandEvents\n+\n+    // Filter by search query\n+    if (searchQuery.trim()) {\n+      const query = searchQuery.toLowerCase()\n+      filtered = filtered.filter((event) => {\n+        const titleMatch = event.title?.toLowerCase().includes(query)\n+        const descriptionMatch = event.description?.toLowerCase().includes(query)\n+        const locationMatch = event.location?.toLowerCase().includes(query)\n+        const tagsMatch = event.tags?.some((tag) => tag.toLowerCase().includes(query))\n+\n+        return titleMatch || descriptionMatch || locationMatch || tagsMatch\n+      })\n+    }\n+\n+    return filtered\n+  }, [onDemandEvents, selectedCategories, searchQuery])\n+\n   // Featured event: nearest upcoming event, or if none, the most recent past event\n   const featuredEvent = useMemo(() => {\n     if (allEvents.length === 0) return undefined\n@@ -208,7 +250,9 @@ export function EventsProvider({ children, staticEvents }: EventsProviderProps)\n   const value: EventsContextValue = {\n     allEvents,\n     filteredEvents,\n+    filteredOnDemandEvents,\n     staticEvents,\n+    onDemandEvents,\n     lumaEvents,\n     isLoading,\n     searchQuery,\ndiff --git a/apps/www/app/events/page.tsx b/apps/www/app/events/page.tsx\nindex b2e202162c910..0d674c52f32ed 100644\n--- a/apps/www/app/events/page.tsx\n+++ b/apps/www/app/events/page.tsx\n@@ -10,7 +10,7 @@ export const metadata: Metadata = {\n \n export default async function EventsPage() {\n   // This needs to be server-side as we use FS api.\n-  const staticEvents = await getStaticEvents()\n+  const { upcomingEvents, onDemandEvents } = await getStaticEvents()\n \n-  return <EventClientRenderer staticEvents={staticEvents.upcomingEvents} />\n+  return <EventClientRenderer staticEvents={upcomingEvents} onDemandEvents={onDemandEvents} />\n }\ndiff --git a/apps/www/components/Events/new/EventBanner.tsx b/apps/www/components/Events/new/EventBanner.tsx\nindex 66aae718c2f55..2b91e00114b15 100644\n--- a/apps/www/components/Events/new/EventBanner.tsx\n+++ b/apps/www/components/Events/new/EventBanner.tsx\n@@ -3,7 +3,7 @@\n import { CalendarIcon, MapPinIcon } from 'lucide-react'\n import Image from 'next/image'\n import Link from 'next/link'\n-import { cn, Button } from 'ui'\n+import { cn, Button, Badge } from 'ui'\n import { useEvents } from '~/app/events/context'\n import { formatHosts } from '~/lib/eventsUtils'\n \n@@ -17,7 +17,9 @@ export function EventBanner() {\n   if (!featuredEvent) return null\n \n   return (\n-    <section className={cn('grid md:grid-cols-[minmax(320px,35%),1fr] gap-6 lg:gap-12')}>\n+    <section\n+      className={cn('grid md:grid-cols-[minmax(320px,35%),1fr] items-start gap-6 lg:gap-12')}\n+    >\n       <CoverImage url={featuredEvent.cover_url} />\n \n       <article className=\"flex flex-col md:justify-center gap-6 lg:py-2\">\n@@ -140,14 +142,20 @@ const LocationWidget = ({ location }: { location?: string }) => {\n const CoverImage = ({ url }: { url?: string }) => {\n   if (!url)\n     return (\n-      <div className=\"w-full bg-surface-100 aspect-square border rounded-lg hidden md:grid place-items-center\">\n+      <div className=\"w-full bg-surface-100 aspect-square border rounded-lg hidden md:grid place-items-center relative\">\n         <Logo />\n+        <Badge variant=\"brand\" className=\"absolute bottom-4 right-4\">\n+          Upcoming\n+        </Badge>\n       </div>\n     )\n \n   return (\n     <div className=\"w-full bg-surface-100 hidden md:block aspect-square border rounded-lg overflow-hidden relative\">\n       <img src={url} alt=\"Event Cover\" className=\"object-cover object-center w-full\" />\n+      <Badge variant=\"brand\" className=\"absolute bottom-4 right-4\">\n+        Upcoming\n+      </Badge>\n     </div>\n   )\n }\ndiff --git a/apps/www/components/Events/new/EventClientRenderer.tsx b/apps/www/components/Events/new/EventClientRenderer.tsx\nindex 21568b7fdd458..248c0b852eec7 100644\n--- a/apps/www/components/Events/new/EventClientRenderer.tsx\n+++ b/apps/www/components/Events/new/EventClientRenderer.tsx\n@@ -7,9 +7,15 @@ import { EventBanner } from '~/components/Events/new/EventBanner'\n import { EventsProvider } from '~/app/events/context'\n import { EventGallery } from './EventGallery'\n \n-export function EventClientRenderer({ staticEvents }: { staticEvents: SupabaseEvent[] }) {\n+export function EventClientRenderer({\n+  staticEvents,\n+  onDemandEvents,\n+}: {\n+  staticEvents: SupabaseEvent[]\n+  onDemandEvents: SupabaseEvent[]\n+}) {\n   return (\n-    <EventsProvider staticEvents={staticEvents}>\n+    <EventsProvider staticEvents={staticEvents} onDemandEvents={onDemandEvents}>\n       <DefaultLayout className=\"flex flex-col\">\n         <SectionContainer className=\"border-x border-b !py-8\">\n           <h1 className=\"h3 !p-0 !m-0\">\ndiff --git a/apps/www/components/Events/new/EventList.tsx b/apps/www/components/Events/new/EventList.tsx\nindex 83fe3f71d13c5..41e4033274f58 100644\n--- a/apps/www/components/Events/new/EventList.tsx\n+++ b/apps/www/components/Events/new/EventList.tsx\n@@ -16,7 +16,7 @@ const CATEGORIES_FILTERS = [\n ]\n \n export function EventList() {\n-  const { isLoading, filteredEvents } = useEvents()\n+  const { isLoading, filteredEvents, filteredOnDemandEvents } = useEvents()\n \n   const getCategoryLabel = (value: string) => {\n     const category = CATEGORIES_FILTERS.find((cat) => cat.value === value)\n@@ -27,7 +27,7 @@ export function EventList() {\n     return <EventListSkeleton />\n   }\n \n-  // Group events by date\n+  // Group upcoming events by date\n   const eventsByDate = filteredEvents.reduce(\n     (acc, event) => {\n       const eventDate = new Date(event.date).toLocaleDateString('en-US', {\n@@ -46,6 +46,9 @@ export function EventList() {\n     {} as Record<string, typeof filteredEvents>\n   )\n \n+  const hasUpcomingEvents = Object.keys(eventsByDate).length > 0\n+  const hasOnDemandEvents = filteredOnDemandEvents.length > 0\n+\n   return (\n     <div className=\"flex flex-col gap-y-8 min-h-72\">\n       {Object.entries(eventsByDate).map(([date, events], index) => (\n@@ -99,8 +102,55 @@ export function EventList() {\n         </div>\n       ))}\n \n-      {/* emtpy state */}\n-      {Object.keys(eventsByDate).length === 0 && (\n+      {/* On-demand events section */}\n+      {hasOnDemandEvents && (\n+        <div className=\"flex flex-col gap-y-2 relative mt-8\">\n+          <div className=\"absolute top-2 -left-[calc(48px+11px)] rounded-full size-1.5 bg-foreground-muted\" />\n+\n+          <h3 className=\"text-foreground-light font-normal\">On Demand</h3>\n+\n+          <div className=\"flex flex-col gap-y-4\">\n+            {filteredOnDemandEvents.map((event, idx) => (\n+              <div\n+                key={`on-demand-${idx}-${event.url}`}\n+                className=\"bg-surface-100 border rounded-md p-3 flex justify-between items-start relative\"\n+              >\n+                <Link\n+                  className=\"inset-0 absolute\"\n+                  href={event.url}\n+                  target={event.url.startsWith('http') ? '_blank' : '_self'}\n+                  title=\"Go to event page\"\n+                  aria-hidden\n+                />\n+\n+                <div className=\"flex flex-col gap-2\">\n+                  <h3>{event.title}</h3>\n+\n+                  <div className=\"flex gap-2 items-center text-sm text-foreground-light\">\n+                    <div className=\"size-5 rounded-full border bg-gradient-to-br from-background-surface-100 to-background-surface-200 relative\">\n+                      {event.hosts[0]?.avatar_url && (\n+                        <img\n+                          src={event.hosts[0].avatar_url}\n+                          alt={event.hosts[0].name || 'Host image'}\n+                          className=\"absolute inset-0 w-full h-full object-cover rounded-full\"\n+                        />\n+                      )}\n+                    </div>\n+                    Hosted by {formatHosts(event.hosts).displayText}\n+                  </div>\n+                </div>\n+\n+                {event.categories.map((tag, idx) => (\n+                  <Badge key={`tag-${idx}`}>{getCategoryLabel(tag)}</Badge>\n+                ))}\n+              </div>\n+            ))}\n+          </div>\n+        </div>\n+      )}\n+\n+      {/* empty state */}\n+      {!hasUpcomingEvents && !hasOnDemandEvents && (\n         <div className=\"self-center text-muted my-auto flex flex-col items-center gap-y-4\">\n           <Rows3Icon className=\"size-8\" />\n           <p className=\"\">Oops! No events found.</p>\ndiff --git a/apps/www/lib/events.ts b/apps/www/lib/events.ts\nindex 9a05822af50e2..f686c08e93bfa 100644\n--- a/apps/www/lib/events.ts\n+++ b/apps/www/lib/events.ts\n@@ -252,7 +252,11 @@ export const getStaticEvents = async (): Promise<{\n         thumb: post.thumb || '',\n         cover_url: (post as any).cover_url || '',\n         path: post.path || '',\n-        url: post.url || '',\n+        // For webinars, use internal path; for other events, use external link if available\n+        url:\n+          (post as any).type === 'webinar'\n+            ? post.url || post.path || ''\n+            : post.link?.href || post.url || post.path || '',\n         tags: post.tags || [],\n         categories: post.categories || [],\n         timezone: (post as any).timezone || 'America/Los_Angeles',\n",
			"diffSize": 13233,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "b70942811213d079a1b7ec312ec277aa0a3fb939",
			"message": "fix: accept apple non-domain client ids (#40756)",
			"user": "hf",
			"timestamp": "2025-11-24T18:59:16Z",
			"author": {
				"name": "Stojan Dimitrovski",
				"email": "sdimitrovski@gmail.com",
				"username": "hf"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/Auth/AuthProvidersFormValidation.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Auth/AuthProvidersFormValidation.tsx b/apps/studio/components/interfaces/Auth/AuthProvidersFormValidation.tsx\nindex e7dfdf7d0f331..1d2ef2b241661 100644\n--- a/apps/studio/components/interfaces/Auth/AuthProvidersFormValidation.tsx\n+++ b/apps/studio/components/interfaces/Auth/AuthProvidersFormValidation.tsx\n@@ -523,7 +523,7 @@ const EXTERNAL_PROVIDER_APPLE = {\n     EXTERNAL_APPLE_CLIENT_ID: string()\n       .matches(/^\\S+$/, 'Client IDs should not contain spaces.')\n       .matches(\n-        /^([a-z0-9-]+\\.[a-z0-9-]+(\\.[a-z0-9-]+)*(,[a-z0-9-]+\\.[a-z0-9-]+(\\.[a-z0-9-]+)*)*)$/i,\n+        /^([a-z0-9-]+(\\.[a-z0-9-]+)*(,[a-z0-9-]+(\\.[a-z0-9-]+)*)*)$/i,\n         'Invalid characters. Each ID should follow a reverse-domain style string (e.g. com.example.app). Use commas to separate multiple IDs.'\n       )\n       .when('EXTERNAL_APPLE_ENABLED', {\n",
			"diffSize": 892,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "51305ab6c03f5b06bb4564c00a9e3be4c51ee4a9",
			"message": "feat: jwt signing keys front-and-center (#40752)",
			"user": "hf",
			"timestamp": "2025-11-24T18:08:10Z",
			"author": {
				"name": "Stojan Dimitrovski",
				"email": "sdimitrovski@gmail.com",
				"username": "hf"
			},
			"files": {
				"added": ["apps/studio/pages/project/[ref]/settings/jwt/legacy.tsx"],
				"modified": [
					"apps/docs/content/guides/auth/signing-keys.mdx",
					"apps/studio/components/layouts/JWTKeys/JWTKeysLayout.tsx",
					"apps/studio/next.config.js",
					"apps/studio/pages/project/[ref]/settings/jwt/index.tsx"
				],
				"removed": [
					"apps/studio/pages/project/[ref]/settings/jwt/signing-keys.tsx"
				]
			},
			"diff": "diff --git a/apps/docs/content/guides/auth/signing-keys.mdx b/apps/docs/content/guides/auth/signing-keys.mdx\nindex f78a3f671ba69..672979e4c08c1 100644\n--- a/apps/docs/content/guides/auth/signing-keys.mdx\n+++ b/apps/docs/content/guides/auth/signing-keys.mdx\n@@ -36,7 +36,7 @@ We've designed the Signing keys system to address many problems the legacy syste\n \n You can start migrating away from the legacy JWT secret through the Supabase dashboard. This process does not cause downtime for your application.\n \n-1. Start off by clicking the _Migrate JWT secret_ button on the [JWT signing keys](/dashboard/project/_/settings/jwt/signing-keys) page. This step will import the existing legacy JWT secret into the new JWT signing keys system. Once this process completes, you will no longer be able to rotate the legacy JWT secret using the old system.\n+1. Start off by clicking the _Migrate JWT secret_ button on the [JWT signing keys](/dashboard/project/_/settings/jwt) page. This step will import the existing legacy JWT secret into the new JWT signing keys system. Once this process completes, you will no longer be able to rotate the legacy JWT secret using the old system.\n 2. Simultaneously, we're creating a new asymmetric JWT signing key for you to rotate to. This key starts off as standby key -- meaning it's being advertised as a key that Supabase Auth will use in the future to create JWTs.\n 3. If you're not ready to switch away from the legacy JWT secret right now, you can stop here without any issue. If you wish to use a different signing key -- either to use a different signing algorithm (RSA, Elliptic Curve or shared secret) or to import a private key or shared secret you already have -- feel free to move the standby key to _Previously used_ before finally moving it to _Revoked._\n 4. If you do wish to start using the standby key for all new JWT use the _Rotate keys_ button. A few important notes:\n@@ -176,7 +176,7 @@ supabase gen signing-key --algorithm ES256\n \n Make sure you store this private key in a secure location, as it will not be extractable from Supabase.\n \n-To import the generated private key to your project, create a [new standby key](/dashboard/project/_/settings/jwt/signing-keys) from the dashboard:\n+To import the generated private key to your project, create a [new standby key](/dashboard/project/_/settings/jwt) from the dashboard:\n \n ```json\n {\ndiff --git a/apps/studio/components/layouts/JWTKeys/JWTKeysLayout.tsx b/apps/studio/components/layouts/JWTKeys/JWTKeysLayout.tsx\nindex 03ea980a382df..7b004ca2b330b 100644\n--- a/apps/studio/components/layouts/JWTKeys/JWTKeysLayout.tsx\n+++ b/apps/studio/components/layouts/JWTKeys/JWTKeysLayout.tsx\n@@ -3,27 +3,21 @@ import { ScaffoldContainer } from 'components/layouts/Scaffold'\n import { PropsWithChildren } from 'react'\n \n import { useParams } from 'common'\n-import { useIsFeatureEnabled } from 'hooks/misc/useIsFeatureEnabled'\n \n const JWTKeysLayout = ({ children }: PropsWithChildren) => {\n   const { ref: projectRef } = useParams()\n-  const { projectSettingsLegacyJwtKeys } = useIsFeatureEnabled(['project_settings:legacy_jwt_keys'])\n \n   const navigationItems = [\n-    ...(projectSettingsLegacyJwtKeys\n-      ? [\n-          {\n-            label: 'Legacy JWT Secret',\n-            href: `/project/${projectRef}/settings/jwt`,\n-            id: 'legacy-jwt-keys',\n-          },\n-        ]\n-      : []),\n     {\n       label: 'JWT Signing Keys',\n-      href: `/project/${projectRef}/settings/jwt/signing-keys`,\n+      href: `/project/${projectRef}/settings/jwt`,\n       id: 'signing-keys',\n     },\n+    {\n+      label: 'Legacy JWT Secret',\n+      href: `/project/${projectRef}/settings/jwt/legacy`,\n+      id: 'legacy-jwt-keys',\n+    },\n   ]\n \n   return (\ndiff --git a/apps/studio/next.config.js b/apps/studio/next.config.js\nindex 78783e6833bae..4770c4ea9bb5d 100644\n--- a/apps/studio/next.config.js\n+++ b/apps/studio/next.config.js\n@@ -242,6 +242,11 @@ const nextConfig = {\n         destination: '/org/_/billing',\n         permanent: true,\n       },\n+      {\n+        permanent: true,\n+        source: '/project/:ref/settings/jwt/signing-keys',\n+        destination: '/project/:ref/settings/jwt',\n+      },\n       {\n         source: '/project/:ref/database/api-logs',\n         destination: '/project/:ref/logs/edge-logs',\ndiff --git a/apps/studio/pages/project/[ref]/settings/jwt/index.tsx b/apps/studio/pages/project/[ref]/settings/jwt/index.tsx\nindex ea17e0136c028..1013828e9ed5d 100644\n--- a/apps/studio/pages/project/[ref]/settings/jwt/index.tsx\n+++ b/apps/studio/pages/project/[ref]/settings/jwt/index.tsx\n@@ -1,70 +1,39 @@\n-import JWTSettings from 'components/interfaces/JwtSecrets/jwt-settings'\n+import { PermissionAction } from '@supabase/shared-types/out/constants'\n+\n+import { JWTSecretKeysTable } from 'components/interfaces/JwtSecrets/jwt-secret-keys-table'\n import DefaultLayout from 'components/layouts/DefaultLayout'\n import JWTKeysLayout from 'components/layouts/JWTKeys/JWTKeysLayout'\n import SettingsLayout from 'components/layouts/ProjectSettingsLayout/SettingsLayout'\n+import NoPermission from 'components/ui/NoPermission'\n+import { GenericSkeletonLoader } from 'components/ui/ShimmeringLoader'\n+import { useAsyncCheckPermissions } from 'hooks/misc/useCheckPermissions'\n import type { NextPageWithLayout } from 'types'\n \n-import { JwtSecretUpdateError, JwtSecretUpdateStatus } from '@supabase/shared-types/out/events'\n-import { useQueryClient } from '@tanstack/react-query'\n-import { useParams } from 'common'\n-import { JWT_SECRET_UPDATE_ERROR_MESSAGES } from 'components/interfaces/JwtSecrets/jwt.constants'\n-import { UnknownInterface } from 'components/ui/UnknownInterface'\n-import { useJwtSecretUpdatingStatusQuery } from 'data/config/jwt-secret-updating-status-query'\n-import { configKeys } from 'data/config/keys'\n-import { useIsFeatureEnabled } from 'hooks/misc/useIsFeatureEnabled'\n-import { useEffect, useRef } from 'react'\n-import { toast } from 'sonner'\n-\n-const JWTKeysLegacyPage: NextPageWithLayout = () => {\n-  const client = useQueryClient()\n-  const { ref: projectRef } = useParams()\n-  const { projectSettingsLegacyJwtKeys } = useIsFeatureEnabled(['project_settings:legacy_jwt_keys'])\n-\n-  const { data } = useJwtSecretUpdatingStatusQuery(\n-    { projectRef },\n-    { enabled: projectSettingsLegacyJwtKeys }\n+const JWTSigningKeysPage: NextPageWithLayout = () => {\n+  const { can: canReadAPIKeys, isSuccess: isPermissionsLoaded } = useAsyncCheckPermissions(\n+    PermissionAction.READ,\n+    'auth_signing_keys'\n   )\n-  const jwtSecretUpdateStatus = data?.jwtSecretUpdateStatus\n-  const jwtSecretUpdateError = data?.jwtSecretUpdateError\n-\n-  const previousJwtSecretUpdateStatus = useRef<JwtSecretUpdateStatus>()\n-  const { Failed, Updated, Updating } = JwtSecretUpdateStatus\n-  const jwtSecretUpdateErrorMessage =\n-    JWT_SECRET_UPDATE_ERROR_MESSAGES[jwtSecretUpdateError as JwtSecretUpdateError]\n-\n-  useEffect(() => {\n-    if (previousJwtSecretUpdateStatus.current === Updating) {\n-      switch (jwtSecretUpdateStatus) {\n-        case Updated:\n-          client.invalidateQueries({ queryKey: configKeys.api(projectRef) })\n-          client.invalidateQueries({ queryKey: configKeys.settings(projectRef) })\n-          client.invalidateQueries({ queryKey: configKeys.postgrest(projectRef) })\n-          toast.success('Successfully updated JWT secret')\n-          break\n-        case Failed:\n-          toast.error(`JWT secret update failed: ${jwtSecretUpdateErrorMessage}`)\n-          break\n-      }\n-    }\n-\n-    previousJwtSecretUpdateStatus.current = jwtSecretUpdateStatus\n-  }, [jwtSecretUpdateStatus])\n-\n-  if (!projectSettingsLegacyJwtKeys) {\n-    return <UnknownInterface urlBack={`/project/${projectRef}/settings/jwt/signing-keys`} />\n-  }\n \n   return (\n-    <JWTKeysLayout>\n-      <JWTSettings />\n-    </JWTKeysLayout>\n+    <>\n+      {!isPermissionsLoaded ? (\n+        <GenericSkeletonLoader />\n+      ) : !canReadAPIKeys ? (\n+        <NoPermission isFullPage resourceText=\"access your project's API keys\" />\n+      ) : (\n+        <JWTSecretKeysTable />\n+      )}\n+    </>\n   )\n }\n \n-JWTKeysLegacyPage.getLayout = (page) => (\n+JWTSigningKeysPage.getLayout = (page) => (\n   <DefaultLayout>\n-    <SettingsLayout>{page}</SettingsLayout>\n+    <SettingsLayout>\n+      <JWTKeysLayout>{page}</JWTKeysLayout>\n+    </SettingsLayout>\n   </DefaultLayout>\n )\n \n-export default JWTKeysLegacyPage\n+export default JWTSigningKeysPage\ndiff --git a/apps/studio/pages/project/[ref]/settings/jwt/legacy.tsx b/apps/studio/pages/project/[ref]/settings/jwt/legacy.tsx\nnew file mode 100644\nindex 0000000000000..ea17e0136c028\n--- /dev/null\n+++ b/apps/studio/pages/project/[ref]/settings/jwt/legacy.tsx\n@@ -0,0 +1,70 @@\n+import JWTSettings from 'components/interfaces/JwtSecrets/jwt-settings'\n+import DefaultLayout from 'components/layouts/DefaultLayout'\n+import JWTKeysLayout from 'components/layouts/JWTKeys/JWTKeysLayout'\n+import SettingsLayout from 'components/layouts/ProjectSettingsLayout/SettingsLayout'\n+import type { NextPageWithLayout } from 'types'\n+\n+import { JwtSecretUpdateError, JwtSecretUpdateStatus } from '@supabase/shared-types/out/events'\n+import { useQueryClient } from '@tanstack/react-query'\n+import { useParams } from 'common'\n+import { JWT_SECRET_UPDATE_ERROR_MESSAGES } from 'components/interfaces/JwtSecrets/jwt.constants'\n+import { UnknownInterface } from 'components/ui/UnknownInterface'\n+import { useJwtSecretUpdatingStatusQuery } from 'data/config/jwt-secret-updating-status-query'\n+import { configKeys } from 'data/config/keys'\n+import { useIsFeatureEnabled } from 'hooks/misc/useIsFeatureEnabled'\n+import { useEffect, useRef } from 'react'\n+import { toast } from 'sonner'\n+\n+const JWTKeysLegacyPage: NextPageWithLayout = () => {\n+  const client = useQueryClient()\n+  const { ref: projectRef } = useParams()\n+  const { projectSettingsLegacyJwtKeys } = useIsFeatureEnabled(['project_settings:legacy_jwt_keys'])\n+\n+  const { data } = useJwtSecretUpdatingStatusQuery(\n+    { projectRef },\n+    { enabled: projectSettingsLegacyJwtKeys }\n+  )\n+  const jwtSecretUpdateStatus = data?.jwtSecretUpdateStatus\n+  const jwtSecretUpdateError = data?.jwtSecretUpdateError\n+\n+  const previousJwtSecretUpdateStatus = useRef<JwtSecretUpdateStatus>()\n+  const { Failed, Updated, Updating } = JwtSecretUpdateStatus\n+  const jwtSecretUpdateErrorMessage =\n+    JWT_SECRET_UPDATE_ERROR_MESSAGES[jwtSecretUpdateError as JwtSecretUpdateError]\n+\n+  useEffect(() => {\n+    if (previousJwtSecretUpdateStatus.current === Updating) {\n+      switch (jwtSecretUpdateStatus) {\n+        case Updated:\n+          client.invalidateQueries({ queryKey: configKeys.api(projectRef) })\n+          client.invalidateQueries({ queryKey: configKeys.settings(projectRef) })\n+          client.invalidateQueries({ queryKey: configKeys.postgrest(projectRef) })\n+          toast.success('Successfully updated JWT secret')\n+          break\n+        case Failed:\n+          toast.error(`JWT secret update failed: ${jwtSecretUpdateErrorMessage}`)\n+          break\n+      }\n+    }\n+\n+    previousJwtSecretUpdateStatus.current = jwtSecretUpdateStatus\n+  }, [jwtSecretUpdateStatus])\n+\n+  if (!projectSettingsLegacyJwtKeys) {\n+    return <UnknownInterface urlBack={`/project/${projectRef}/settings/jwt/signing-keys`} />\n+  }\n+\n+  return (\n+    <JWTKeysLayout>\n+      <JWTSettings />\n+    </JWTKeysLayout>\n+  )\n+}\n+\n+JWTKeysLegacyPage.getLayout = (page) => (\n+  <DefaultLayout>\n+    <SettingsLayout>{page}</SettingsLayout>\n+  </DefaultLayout>\n+)\n+\n+export default JWTKeysLegacyPage\ndiff --git a/apps/studio/pages/project/[ref]/settings/jwt/signing-keys.tsx b/apps/studio/pages/project/[ref]/settings/jwt/signing-keys.tsx\ndeleted file mode 100644\nindex 1013828e9ed5d..0000000000000\n--- a/apps/studio/pages/project/[ref]/settings/jwt/signing-keys.tsx\n+++ /dev/null\n@@ -1,39 +0,0 @@\n-import { PermissionAction } from '@supabase/shared-types/out/constants'\n-\n-import { JWTSecretKeysTable } from 'components/interfaces/JwtSecrets/jwt-secret-keys-table'\n-import DefaultLayout from 'components/layouts/DefaultLayout'\n-import JWTKeysLayout from 'components/layouts/JWTKeys/JWTKeysLayout'\n-import SettingsLayout from 'components/layouts/ProjectSettingsLayout/SettingsLayout'\n-import NoPermission from 'components/ui/NoPermission'\n-import { GenericSkeletonLoader } from 'components/ui/ShimmeringLoader'\n-import { useAsyncCheckPermissions } from 'hooks/misc/useCheckPermissions'\n-import type { NextPageWithLayout } from 'types'\n-\n-const JWTSigningKeysPage: NextPageWithLayout = () => {\n-  const { can: canReadAPIKeys, isSuccess: isPermissionsLoaded } = useAsyncCheckPermissions(\n-    PermissionAction.READ,\n-    'auth_signing_keys'\n-  )\n-\n-  return (\n-    <>\n-      {!isPermissionsLoaded ? (\n-        <GenericSkeletonLoader />\n-      ) : !canReadAPIKeys ? (\n-        <NoPermission isFullPage resourceText=\"access your project's API keys\" />\n-      ) : (\n-        <JWTSecretKeysTable />\n-      )}\n-    </>\n-  )\n-}\n-\n-JWTSigningKeysPage.getLayout = (page) => (\n-  <DefaultLayout>\n-    <SettingsLayout>\n-      <JWTKeysLayout>{page}</JWTKeysLayout>\n-    </SettingsLayout>\n-  </DefaultLayout>\n-)\n-\n-export default JWTSigningKeysPage\n",
			"diffSize": 13200,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "34ca04300c191b818d369141de5d889cf6228208",
			"message": "feat: make publishable, secret api keys page front-and-center (#40751)",
			"user": "hf",
			"timestamp": "2025-11-24T18:08:00Z",
			"author": {
				"name": "Stojan Dimitrovski",
				"email": "sdimitrovski@gmail.com",
				"username": "hf"
			},
			"files": {
				"added": [
					"apps/studio/pages/project/[ref]/settings/api-keys/legacy.tsx"
				],
				"modified": [
					"apps/docs/content/guides/api/api-keys.mdx",
					"apps/studio/components/layouts/APIKeys/APIKeysLayout.tsx",
					"apps/studio/next.config.js",
					"apps/studio/pages/project/[ref]/settings/api-keys/index.tsx"
				],
				"removed": ["apps/studio/pages/project/[ref]/settings/api-keys/new.tsx"]
			},
			"diff": "diff --git a/apps/docs/content/guides/api/api-keys.mdx b/apps/docs/content/guides/api/api-keys.mdx\nindex 2fc1380334783..6b32efd7ac19c 100644\n--- a/apps/docs/content/guides/api/api-keys.mdx\n+++ b/apps/docs/content/guides/api/api-keys.mdx\n@@ -117,7 +117,7 @@ The secret key is an improvement over the old JWT-based `service_role` key, and\n Below are some starting guidelines on how to securely work with secret keys:\n \n - Always work with secret keys on computers you fully own or control.\n-- Use secure & encrypted send tools to share API keys with others (often provided by good password managers), but prefer the [API Keys](/dashboard/project/_/settings/api-keys/new) dashboard instead.\n+- Use secure & encrypted send tools to share API keys with others (often provided by good password managers), but prefer the [API Keys](/dashboard/project/_/settings/api-keys) dashboard instead.\n - Prefer encrypting them when stored in files or environment variables.\n - Do not add in source control, especially for CI scripts and tools. Prefer using the tool's native secrets capability instead.\n - Prefer using a separate secret key for each separate backend component of your application, so that if one is found to be vulnerable or to have leaked the key you will only need to change it and not all.\n@@ -129,7 +129,7 @@ Below are some starting guidelines on how to securely work with secret keys:\n \n Don't rush if this has happened, or you are suspecting it has. Make sure you have fully considered the situation and have remediated the root cause of the suspicion or vulnerability **first**. Consider using the [OWASP Risk Rating Methodology](https://owasp.org/www-community/OWASP_Risk_Rating_Methodology) as an easy way to identify the severity of the incident and to plan your next steps.\n \n-Rotating a secret key (`sb_secret_...`) is easy and painless. Use the [API Keys](/dashboard/project/_/settings/api-keys/new) dashboard to create a new secret API key, then replace it with the compromised key. Once all components are using the new key, delete the compromised one.\n+Rotating a secret key (`sb_secret_...`) is easy and painless. Use the [API Keys](/dashboard/project/_/settings/api-keys) dashboard to create a new secret API key, then replace it with the compromised key. Once all components are using the new key, delete the compromised one.\n \n **Deleting a secret key is irreversible and once done it will be gone forever.**\n \n@@ -154,7 +154,7 @@ As the publishable and secret keys are no longer JWT-based, there are some known\n \n If you know or suspect that the JWT secret itself is leaked, refer to the section on [rotating the JWT](#what-to-do-if-a-secret-key-or-servicerole-has-been-leaked-or-compromised).\n \n-If the JWT secret is secure, prefer substituting the `service_role` JWT-based key with a new secret key which you can create in the [API Keys](/dashboard/project/_/settings/api-keys/new) dashboard. This will prevent downtime for your application.\n+If the JWT secret is secure, prefer substituting the `service_role` JWT-based key with a new secret key which you can create in the [API Keys](/dashboard/project/_/settings/api-keys) dashboard. This will prevent downtime for your application.\n \n ### Can I still use my old `anon` and `service-role` API keys after enabling the publishable and secret keys?\n \n@@ -162,7 +162,7 @@ Yes. This allows you to transition between the API keys with zero downtime by gr\n \n ### How do I deactivate the `anon` and `service_role` JWT-based API keys after moving to publishable and secret keys?\n \n-You can do this in the [API Keys](/dashboard/project/_/settings/api-keys/new) dashboard. To prevent downtime in your application's components, use the last used indicators on the page to confirm that these are no longer used before deactivating.\n+You can do this in the [API Keys](/dashboard/project/_/settings/api-keys) dashboard. To prevent downtime in your application's components, use the last used indicators on the page to confirm that these are no longer used before deactivating.\n \n You can re-activate them should you need to.\n \ndiff --git a/apps/studio/components/layouts/APIKeys/APIKeysLayout.tsx b/apps/studio/components/layouts/APIKeys/APIKeysLayout.tsx\nindex b466ba23c72b7..8ee3779dcc50a 100644\n--- a/apps/studio/components/layouts/APIKeys/APIKeysLayout.tsx\n+++ b/apps/studio/components/layouts/APIKeys/APIKeysLayout.tsx\n@@ -9,13 +9,13 @@ const ApiKeysLayout = ({ children }: PropsWithChildren) => {\n \n   const navigationItems = [\n     {\n-      label: 'API Keys',\n-      href: `/project/${projectRef}/settings/api-keys/new`,\n+      label: 'Publishable and secret API keys',\n+      href: `/project/${projectRef}/settings/api-keys`,\n       id: 'new-keys',\n     },\n     {\n-      label: 'Legacy API Keys',\n-      href: `/project/${projectRef}/settings/api-keys`,\n+      label: 'Legacy anon, service_role API keys',\n+      href: `/project/${projectRef}/settings/api-keys/legacy`,\n       id: 'legacy-keys',\n     },\n   ]\ndiff --git a/apps/studio/next.config.js b/apps/studio/next.config.js\nindex 8fd06b57628d8..78783e6833bae 100644\n--- a/apps/studio/next.config.js\n+++ b/apps/studio/next.config.js\n@@ -159,6 +159,11 @@ const nextConfig = {\n         destination: '/project/:ref/storage/files/buckets/:bucketId',\n         permanent: true,\n       },\n+      {\n+        permanent: true,\n+        source: '/project/:ref/settings/api-keys/new',\n+        destination: '/project/:ref/settings/api-keys',\n+      },\n       {\n         source: '/project/:ref/settings/storage',\n         destination: '/project/:ref/storage/files/settings',\ndiff --git a/apps/studio/pages/project/[ref]/settings/api-keys/index.tsx b/apps/studio/pages/project/[ref]/settings/api-keys/index.tsx\nindex 373744e45115b..99e475e2c9d52 100644\n--- a/apps/studio/pages/project/[ref]/settings/api-keys/index.tsx\n+++ b/apps/studio/pages/project/[ref]/settings/api-keys/index.tsx\n@@ -1,25 +1,34 @@\n+import {\n+  ApiKeysCreateCallout,\n+  ApiKeysFeedbackBanner,\n+} from 'components/interfaces/APIKeys/ApiKeysIllustrations'\n+import { useApiKeysVisibility } from 'components/interfaces/APIKeys/hooks/useApiKeysVisibility'\n+import { PublishableAPIKeys } from 'components/interfaces/APIKeys/PublishableAPIKeys'\n+import { SecretAPIKeys } from 'components/interfaces/APIKeys/SecretAPIKeys'\n import ApiKeysLayout from 'components/layouts/APIKeys/APIKeysLayout'\n import DefaultLayout from 'components/layouts/DefaultLayout'\n import SettingsLayout from 'components/layouts/ProjectSettingsLayout/SettingsLayout'\n-import { DisplayApiSettings } from 'components/ui/ProjectSettings/DisplayApiSettings'\n-import { ToggleLegacyApiKeysPanel } from 'components/ui/ProjectSettings/ToggleLegacyApiKeys'\n-import { useIsFeatureEnabled } from 'hooks/misc/useIsFeatureEnabled'\n+import { DisableInteraction } from 'components/ui/DisableInteraction'\n import type { NextPageWithLayout } from 'types'\n+import { Separator } from 'ui'\n \n-const ApiKeysLegacyPage: NextPageWithLayout = () => {\n-  const { projectSettingsShowDisableLegacyApiKeys } = useIsFeatureEnabled([\n-    'project_settings:show_disable_legacy_api_keys',\n-  ])\n+const ApiKeysNewPage: NextPageWithLayout = () => {\n+  const { shouldDisableUI, canInitApiKeys } = useApiKeysVisibility()\n \n   return (\n     <>\n-      <DisplayApiSettings showTitle={false} showNotice={false} />\n-      {projectSettingsShowDisableLegacyApiKeys && <ToggleLegacyApiKeysPanel />}\n+      {canInitApiKeys && <ApiKeysCreateCallout />}\n+      <ApiKeysFeedbackBanner />\n+      <DisableInteraction disabled={shouldDisableUI} className=\"flex flex-col gap-8\">\n+        <PublishableAPIKeys />\n+        <Separator />\n+        <SecretAPIKeys />\n+      </DisableInteraction>\n     </>\n   )\n }\n \n-ApiKeysLegacyPage.getLayout = (page) => (\n+ApiKeysNewPage.getLayout = (page) => (\n   <DefaultLayout>\n     <SettingsLayout>\n       <ApiKeysLayout>{page}</ApiKeysLayout>\n@@ -27,4 +36,4 @@ ApiKeysLegacyPage.getLayout = (page) => (\n   </DefaultLayout>\n )\n \n-export default ApiKeysLegacyPage\n+export default ApiKeysNewPage\ndiff --git a/apps/studio/pages/project/[ref]/settings/api-keys/legacy.tsx b/apps/studio/pages/project/[ref]/settings/api-keys/legacy.tsx\nnew file mode 100644\nindex 0000000000000..a7b2cde1fbd0d\n--- /dev/null\n+++ b/apps/studio/pages/project/[ref]/settings/api-keys/legacy.tsx\n@@ -0,0 +1,26 @@\n+import ApiKeysLayout from 'components/layouts/APIKeys/APIKeysLayout'\n+import DefaultLayout from 'components/layouts/DefaultLayout'\n+import SettingsLayout from 'components/layouts/ProjectSettingsLayout/SettingsLayout'\n+import { DisplayApiSettings } from 'components/ui/ProjectSettings/DisplayApiSettings'\n+import { ToggleLegacyApiKeysPanel } from 'components/ui/ProjectSettings/ToggleLegacyApiKeys'\n+import { useIsFeatureEnabled } from 'hooks/misc/useIsFeatureEnabled'\n+import type { NextPageWithLayout } from 'types'\n+\n+const ApiKeysLegacyPage: NextPageWithLayout = () => {\n+  return (\n+    <>\n+      <DisplayApiSettings showTitle={false} showNotice={false} />\n+      <ToggleLegacyApiKeysPanel />\n+    </>\n+  )\n+}\n+\n+ApiKeysLegacyPage.getLayout = (page) => (\n+  <DefaultLayout>\n+    <SettingsLayout>\n+      <ApiKeysLayout>{page}</ApiKeysLayout>\n+    </SettingsLayout>\n+  </DefaultLayout>\n+)\n+\n+export default ApiKeysLegacyPage\ndiff --git a/apps/studio/pages/project/[ref]/settings/api-keys/new.tsx b/apps/studio/pages/project/[ref]/settings/api-keys/new.tsx\ndeleted file mode 100644\nindex 99e475e2c9d52..0000000000000\n--- a/apps/studio/pages/project/[ref]/settings/api-keys/new.tsx\n+++ /dev/null\n@@ -1,39 +0,0 @@\n-import {\n-  ApiKeysCreateCallout,\n-  ApiKeysFeedbackBanner,\n-} from 'components/interfaces/APIKeys/ApiKeysIllustrations'\n-import { useApiKeysVisibility } from 'components/interfaces/APIKeys/hooks/useApiKeysVisibility'\n-import { PublishableAPIKeys } from 'components/interfaces/APIKeys/PublishableAPIKeys'\n-import { SecretAPIKeys } from 'components/interfaces/APIKeys/SecretAPIKeys'\n-import ApiKeysLayout from 'components/layouts/APIKeys/APIKeysLayout'\n-import DefaultLayout from 'components/layouts/DefaultLayout'\n-import SettingsLayout from 'components/layouts/ProjectSettingsLayout/SettingsLayout'\n-import { DisableInteraction } from 'components/ui/DisableInteraction'\n-import type { NextPageWithLayout } from 'types'\n-import { Separator } from 'ui'\n-\n-const ApiKeysNewPage: NextPageWithLayout = () => {\n-  const { shouldDisableUI, canInitApiKeys } = useApiKeysVisibility()\n-\n-  return (\n-    <>\n-      {canInitApiKeys && <ApiKeysCreateCallout />}\n-      <ApiKeysFeedbackBanner />\n-      <DisableInteraction disabled={shouldDisableUI} className=\"flex flex-col gap-8\">\n-        <PublishableAPIKeys />\n-        <Separator />\n-        <SecretAPIKeys />\n-      </DisableInteraction>\n-    </>\n-  )\n-}\n-\n-ApiKeysNewPage.getLayout = (page) => (\n-  <DefaultLayout>\n-    <SettingsLayout>\n-      <ApiKeysLayout>{page}</ApiKeysLayout>\n-    </SettingsLayout>\n-  </DefaultLayout>\n-)\n-\n-export default ApiKeysNewPage\n",
			"diffSize": 10933,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "e1f758ad40c7ec7a0f8fce50518b222c871da390",
			"message": "fix(editor): correct 'Close to the Right' behavior when invoked on inactive tab (#40709)\n\nfix(editor): correct 'Close to the Right' behavior when invoked on inactive tabs\n\nCo-authored-by: Ali Waseem <waseema393@gmail.com>",
			"user": "marsou001",
			"timestamp": "2025-11-24T15:24:25Z",
			"author": {
				"name": "Marouane Souda",
				"email": "61951643+marsou001@users.noreply.github.com",
				"username": "marsou001"
			},
			"files": {
				"added": [],
				"modified": ["apps/studio/components/layouts/Tabs/Tabs.tsx"],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/layouts/Tabs/Tabs.tsx b/apps/studio/components/layouts/Tabs/Tabs.tsx\nindex 0816bd0a3f9d8..02744f6c4e517 100644\n--- a/apps/studio/components/layouts/Tabs/Tabs.tsx\n+++ b/apps/studio/components/layouts/Tabs/Tabs.tsx\n@@ -116,8 +116,15 @@ export const EditorTabs = () => {\n           ? tabs.openTabs.filter((x) => !x.startsWith('sql'))\n           : tabs.openTabs.filter((x) => x.startsWith('sql'))\n       const tabIdx = openedTabs.indexOf(tabId)\n+      const activeTabIdx = openedTabs.indexOf(tabs.activeTab!)\n       const tabsToClose = openedTabs.slice(tabIdx + 1)\n       tabs.removeTabs(tabsToClose)\n+\n+      const isActiveTabClosed = tabIdx < activeTabIdx\n+      if (isActiveTabClosed) {\n+        const id = editor === 'table' ? tabId.split('-')[1] : tabId.split('sql-')[1]\n+        router.push(`/project/${ref}/${editor === 'table' ? 'editor' : 'sql'}/${id}`)\n+      }\n     }\n   }\n \n",
			"diffSize": 918,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "eca56b0ee5fc1f1865a5bfbe80d5c1227e726909",
			"message": "[bot] Decrease ESLint ratchet baselines (#40712)\n\nchore: decrease ESLint ratchet baselines\n\nCo-authored-by: github-actions[bot] <github-actions[bot]@users.noreply.github.com>\nCo-authored-by: Ali Waseem <waseema393@gmail.com>",
			"user": "github-actions[bot]",
			"timestamp": "2025-11-24T15:12:57Z",
			"author": {
				"name": "github-actions[bot]",
				"email": "41898282+github-actions[bot]@users.noreply.github.com",
				"username": "github-actions[bot]"
			},
			"files": {
				"added": [],
				"modified": ["apps/studio/.github/eslint-rule-baselines.json"],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/.github/eslint-rule-baselines.json b/apps/studio/.github/eslint-rule-baselines.json\nindex 1b765189d8b44..a2729485e4510 100644\n--- a/apps/studio/.github/eslint-rule-baselines.json\n+++ b/apps/studio/.github/eslint-rule-baselines.json\n@@ -1,9 +1,9 @@\n {\n   \"rules\": {\n-    \"react-hooks/exhaustive-deps\": 236,\n+    \"react-hooks/exhaustive-deps\": 230,\n     \"import/no-anonymous-default-export\": 62,\n     \"@tanstack/query/exhaustive-deps\": 19,\n-    \"@tanstack/query/no-deprecated-options\": 2\n+    \"@tanstack/query/no-deprecated-options\": 0\n   },\n   \"ruleFiles\": {\n     \"react-hooks/exhaustive-deps\": {\n@@ -67,7 +67,6 @@\n       \"components/interfaces/Organization/BillingSettings/Subscription/PaymentMethodSelection.tsx\": 2,\n       \"components/interfaces/Organization/BillingSettings/Subscription/PlanUpdateSidePanel.tsx\": 1,\n       \"components/interfaces/Organization/IntegrationSettings/IntegrationSettings.tsx\": 1,\n-      \"components/interfaces/Organization/TeamSettings/UpdateRolesPanel/UpdateRolesPanel.tsx\": 1,\n       \"components/interfaces/Organization/Usage/Compute.tsx\": 1,\n       \"components/interfaces/ProjectAPIDocs/Content/Entity.tsx\": 1,\n       \"components/interfaces/ProjectAPIDocs/Content/RPC.tsx\": 1,\n@@ -93,7 +92,6 @@\n       \"components/interfaces/Settings/Database/ConnectionPooling/ConnectionPooling.tsx\": 1,\n       \"components/interfaces/Settings/Database/SSLConfiguration.tsx\": 1,\n       \"components/interfaces/Settings/General/ComplianceConfig/ProjectComplianceMode.tsx\": 1,\n-      \"components/interfaces/Settings/General/TransferProjectPanel/TransferProjectButton.tsx\": 1,\n       \"components/interfaces/Settings/Infrastructure/InfrastructureConfiguration/DeployNewReplicaPanel.tsx\": 1,\n       \"components/interfaces/Settings/Infrastructure/InfrastructureConfiguration/InstanceConfiguration.tsx\": 1,\n       \"components/interfaces/Settings/Logs/LogTable.tsx\": 2,\n@@ -101,9 +99,7 @@\n       \"components/interfaces/Settings/Logs/PreviewFilterPanel.tsx\": 1,\n       \"components/interfaces/SignIn/SignInPartner.tsx\": 1,\n       \"components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/CopyEnvButton.tsx\": 1,\n-      \"components/interfaces/Storage/StorageExplorer/FileExplorerHeader.tsx\": 2,\n       \"components/interfaces/Storage/StorageExplorer/FileExplorerRowEditing.tsx\": 1,\n-      \"components/interfaces/Storage/StorageExplorer/StorageExplorer.tsx\": 2,\n       \"components/interfaces/Storage/StorageSettings/StorageSettings.tsx\": 1,\n       \"components/interfaces/Storage/VectorBuckets/CreateVectorBucketDialog.tsx\": 1,\n       \"components/interfaces/Storage/VectorBuckets/CreateVectorTableSheet.tsx\": 1,\n@@ -112,7 +108,7 @@\n       \"components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/JsonEditor/index.tsx\": 2,\n       \"components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/RowEditor.tsx\": 1,\n       \"components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/TextEditor.tsx\": 2,\n-      \"components/interfaces/TableGridEditor/SidePanelEditor/TableEditor/TableEditor.tsx\": 2,\n+      \"components/interfaces/TableGridEditor/SidePanelEditor/TableEditor/TableEditor.tsx\": 1,\n       \"components/interfaces/TableGridEditor/SidePanelEditor/TableEditor/TableQuickstart/QuickstartAIWidget.tsx\": 1,\n       \"components/interfaces/TableGridEditor/SidePanelEditor/TableEditor/TableQuickstart/useAITableGeneration.ts\": 2,\n       \"components/interfaces/TableGridEditor/TableDefinition.tsx\": 1,\n@@ -122,6 +118,7 @@\n       \"components/layouts/ProjectLayout/ConnectingState.tsx\": 1,\n       \"components/layouts/ProjectLayout/LayoutHeader/FeedbackDropdown/FeedbackWidget.tsx\": 2,\n       \"components/layouts/ProjectLayout/LayoutSidebar/LayoutSidebarProvider.tsx\": 1,\n+      \"components/layouts/ProjectLayout/PausedState/PauseDisabledState.tsx\": 1,\n       \"components/layouts/ProjectLayout/index.tsx\": 1,\n       \"components/layouts/SQLEditorLayout/SQLEditorNavV2/SQLEditorNav.tsx\": 4,\n       \"components/layouts/SQLEditorLayout/SQLEditorNavV2/SQLEditorTreeViewItem.tsx\": 2,\n@@ -159,6 +156,7 @@\n       \"hooks/ui/useCsvFileDrop.ts\": 1,\n       \"hooks/ui/useHotKey.ts\": 2,\n       \"pages/forgot-password-mfa.tsx\": 1,\n+      \"pages/integrations/vercel/[slug]/deploy-button/new-project.tsx\": 1,\n       \"pages/integrations/vercel/install.tsx\": 1,\n       \"pages/logout.tsx\": 1,\n       \"pages/new/[slug].tsx\": 4,\n@@ -170,7 +168,6 @@\n       \"pages/project/[ref]/editor/index.tsx\": 1,\n       \"pages/project/[ref]/integrations/[id]/[pageId]/index.tsx\": 1,\n       \"pages/project/[ref]/logs/explorer/index.tsx\": 1,\n-      \"pages/project/[ref]/reports/postgrest.tsx\": 1,\n       \"pages/project/[ref]/settings/jwt/index.tsx\": 1,\n       \"pages/project/[ref]/sql/quickstarts.tsx\": 1,\n       \"pages/project/[ref]/sql/templates.tsx\": 1,\n@@ -261,9 +258,6 @@\n       \"hooks/analytics/useProjectUsageStats.tsx\": 1,\n       \"hooks/analytics/useSingleLog.tsx\": 1\n     },\n-    \"@tanstack/query/no-deprecated-options\": {\n-      \"data/config/jwt-secret-updating-status-query.ts\": 1,\n-      \"data/config/project-upgrade-status-query.ts\": 1\n-    }\n+    \"@tanstack/query/no-deprecated-options\": {}\n   }\n }\n",
			"diffSize": 5120,
			"diffTruncated": false,
			"filterResult": {
				"included": false,
				"excludeReason": "bot"
			}
		},
		{
			"sha": "bb6e1f6fe7af73c771d63ce12bc8456aaa01e18b",
			"message": "fix: update wording in support ticket confirmation (#40748)\n\n* fix: update wording in support ticket confirmation\n\n* apply suggestion from @mildtomato\n\nCo-authored-by: Jonathan Summers-Muir <MildTomato@users.noreply.github.com>\n\n---------\n\nCo-authored-by: Jonathan Summers-Muir <MildTomato@users.noreply.github.com>",
			"user": "hf",
			"timestamp": "2025-11-24T14:37:15Z",
			"author": {
				"name": "Stojan Dimitrovski",
				"email": "sdimitrovski@gmail.com",
				"username": "hf"
			},
			"files": {
				"added": [],
				"modified": ["apps/studio/components/interfaces/Support/Success.tsx"],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Support/Success.tsx b/apps/studio/components/interfaces/Support/Success.tsx\nindex 1ad3a17cbe111..0ef8d6a3f86f8 100644\n--- a/apps/studio/components/interfaces/Support/Success.tsx\n+++ b/apps/studio/components/interfaces/Support/Success.tsx\n@@ -47,7 +47,7 @@ export const Success = ({\n         {selectedProject !== NO_PROJECT_MARKER && (\n           <p className=\"text-sm text-foreground-light\">\n             Your ticket has been logged for the project{' '}\n-            <span className=\"text-foreground\">{projectName}</span>, reference ID:{' '}\n+            <span className=\"text-foreground\">{projectName}</span> with Project ID:{' '}\n             <span className=\"text-foreground\">{selectedProject}</span>.\n           </p>\n         )}\n",
			"diffSize": 780,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "ec1371d4b6aad6226ba917aaaabbc171a64a76bb",
			"message": "docs: cancel subscription (#40741)\n\nExplicit docs around cancellation as folks dont seem to find it under downgrade sometimes - also helps with AI discoverability",
			"user": "kevcodez",
			"timestamp": "2025-11-24T14:01:40Z",
			"author": {
				"name": "Kevin Grüneberg",
				"email": "k.grueneberg1994@gmail.com",
				"username": "kevcodez"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/docs/content/guides/platform/manage-your-subscription.mdx",
					"apps/docs/public/img/guides/platform/upgrade-to-pro-plan-modal--dark.png",
					"apps/docs/public/img/guides/platform/upgrade-to-pro-plan-modal--light.png"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/docs/content/guides/platform/manage-your-subscription.mdx b/apps/docs/content/guides/platform/manage-your-subscription.mdx\nindex 38b72d38e2760..1724b17f99d2b 100644\n--- a/apps/docs/content/guides/platform/manage-your-subscription.mdx\n+++ b/apps/docs/content/guides/platform/manage-your-subscription.mdx\n@@ -59,6 +59,12 @@ The plan line item (e.g. Pro Plan) gets charged upfront, whereas all usage charg\n \n If you got charged after downgrading to the Free Plan, you had excessive usage in the previous billing cycle. You can check your invoices to see what exactly you were charged for.\n \n+### Cancel subscription\n+\n+To cancel your subscription, go to your [organization's billing settings](/dashboard/org/_/billing), click \"Change subscription plan\" and select the Free Plan. The cancellation is immediate, refer to [downgrade docs](#downgrade) for full details.\n+\n+Cancellations are fully self-serve. Your Free Plan subscription will run indefinitely unless you delete the organization through your [organization's settings](/dashboard/org/_/general).\n+\n ## Manage your payment methods\n \n You can add multiple payment methods, but only one can be active at a time.\ndiff --git a/apps/docs/public/img/guides/platform/upgrade-to-pro-plan-modal--dark.png b/apps/docs/public/img/guides/platform/upgrade-to-pro-plan-modal--dark.png\nindex b17b44873837f..297e6ba8658e8 100644\nBinary files a/apps/docs/public/img/guides/platform/upgrade-to-pro-plan-modal--dark.png and b/apps/docs/public/img/guides/platform/upgrade-to-pro-plan-modal--dark.png differ\ndiff --git a/apps/docs/public/img/guides/platform/upgrade-to-pro-plan-modal--light.png b/apps/docs/public/img/guides/platform/upgrade-to-pro-plan-modal--light.png\nindex f72adcb42bba2..01e030bcac8b4 100644\nBinary files a/apps/docs/public/img/guides/platform/upgrade-to-pro-plan-modal--light.png and b/apps/docs/public/img/guides/platform/upgrade-to-pro-plan-modal--light.png differ\n",
			"diffSize": 1942,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "d653617cdd59088b9bfbba82a3ed040bd765961c",
			"message": "chore(studio): improve inline code styling (#40724)\n\n* sweep language\n\n* update class docs\n\n* additional\n\n* basic docs\n\n* sweep relevant instances\n\n* replace text-code\n\n* additional in sweep\n\n* Tiny fix\n\n* prettier\n\n---------\n\nCo-authored-by: Joshen Lim <joshenlimek@gmail.com>",
			"user": "dnywh",
			"timestamp": "2025-11-24T08:34:30Z",
			"author": {
				"name": "Danny White",
				"email": "3104761+dnywh@users.noreply.github.com",
				"username": "dnywh"
			},
			"files": {
				"added": ["apps/design-system/content/docs/typography.mdx"],
				"modified": [
					"apps/design-system/config/docs.ts",
					"apps/studio/components/grid/components/grid/GridError.tsx",
					"apps/studio/components/interfaces/Advisors/EnableRuleModal.tsx",
					"apps/studio/components/interfaces/App/FeaturePreview/CLSPreview.tsx",
					"apps/studio/components/interfaces/Auth/AuditLogsForm.tsx",
					"apps/studio/components/interfaces/Auth/BasicAuthSettingsForm.tsx",
					"apps/studio/components/interfaces/Auth/Policies/PolicyEditorPanel/PolicyDetailsV2.tsx",
					"apps/studio/components/interfaces/BranchManagement/CreateBranchModal.tsx",
					"apps/studio/components/interfaces/Database/ETL/UpdateVersionModal.tsx",
					"apps/studio/components/interfaces/Database/Extensions/EnableExtensionModal.tsx",
					"apps/studio/components/interfaces/Database/Hooks/HooksList/HookList.tsx",
					"apps/studio/components/interfaces/Database/ProtectedSchemaWarning.tsx",
					"apps/studio/components/interfaces/Database/Tables/ColumnList.tsx",
					"apps/studio/components/interfaces/Database/Tables/TableList.tsx",
					"apps/studio/components/interfaces/Home/NewProjectPanel/APIKeys.tsx",
					"apps/studio/components/interfaces/Integrations/CronJobs/CreateCronJobSheet/CreateCronJobSheet.tsx",
					"apps/studio/components/interfaces/Integrations/CronJobs/CronJobPage.tsx",
					"apps/studio/components/interfaces/Integrations/Queues/QueueTab.tsx",
					"apps/studio/components/interfaces/Integrations/Queues/QueuesSettings.tsx",
					"apps/studio/components/interfaces/Integrations/Queues/SingleQueue/QueueSettings.tsx",
					"apps/studio/components/interfaces/Integrations/Wrappers/CreateIcebergWrapperSheet.tsx",
					"apps/studio/components/interfaces/Integrations/Wrappers/CreateWrapperSheet.tsx",
					"apps/studio/components/interfaces/Integrations/Wrappers/EditWrapperSheet.tsx",
					"apps/studio/components/interfaces/Integrations/Wrappers/OverviewTab.tsx",
					"apps/studio/components/interfaces/ProjectCreation/SecurityOptions.tsx",
					"apps/studio/components/interfaces/Realtime/RealtimeSettings.tsx",
					"apps/studio/components/interfaces/SQLEditor/RunQueryWarningModal.tsx",
					"apps/studio/components/interfaces/Settings/API/HardenAPIModal.tsx",
					"apps/studio/components/interfaces/Settings/API/PostgrestConfig.tsx",
					"apps/studio/components/interfaces/Settings/Database/NetworkRestrictions/AddRestrictionModal.tsx",
					"apps/studio/components/interfaces/Settings/Database/NetworkRestrictions/RemoveRestrictionModal.tsx",
					"apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainActivate.tsx",
					"apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainVerify.tsx",
					"apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainsConfigureHostname.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx",
					"apps/studio/components/interfaces/Storage/AnalyticsBuckets/CreateAnalyticsBucketModal.tsx",
					"apps/studio/components/interfaces/TableGridEditor/GridHeaderActions.tsx",
					"apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ColumnEditor/ColumnType.tsx",
					"apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ForeignKeySelector/ForeignKeySelector.tsx",
					"apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ForeignKeySelector/ForeignKeySelector.utils.tsx",
					"apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/ForeignRowSelector/ForeignRowSelector.tsx",
					"apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/SpreadsheetImport/SpreadsheetImportPreview.tsx",
					"apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/TableEditor/ForeignKeysManagement/ForeignKeyRow.tsx",
					"apps/studio/components/ui/ProjectSettings/DisplayApiSettings.tsx",
					"apps/studio/pages/project/[ref]/database/column-privileges.tsx",
					"apps/studio/styles/typography.scss",
					"packages/config/ui.config.js",
					"packages/ui-patterns/src/Toc/toc.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/design-system/config/docs.ts b/apps/design-system/config/docs.ts\nindex c517b8a066c76..834cb30c46063 100644\n--- a/apps/design-system/config/docs.ts\n+++ b/apps/design-system/config/docs.ts\n@@ -25,6 +25,11 @@ export const docsConfig: DocsConfig = {\n           href: '/docs/color-usage',\n           items: [],\n         },\n+        {\n+          title: 'Typography',\n+          href: '/docs/typography',\n+          items: [],\n+        },\n         {\n           title: 'Theming',\n           href: '/docs/theming',\n@@ -36,9 +41,9 @@ export const docsConfig: DocsConfig = {\n           items: [],\n         },\n         {\n-          items: [],\n-          href: '/docs/ui-patterns/accessibility',\n           title: 'Accessibility',\n+          href: '/docs/accessibility',\n+          items: [],\n         },\n       ],\n     },\ndiff --git a/apps/design-system/content/docs/ui-patterns/accessibility.mdx b/apps/design-system/content/docs/accessibility.mdx\nsimilarity index 100%\nrename from apps/design-system/content/docs/ui-patterns/accessibility.mdx\nrename to apps/design-system/content/docs/accessibility.mdx\ndiff --git a/apps/design-system/content/docs/typography.mdx b/apps/design-system/content/docs/typography.mdx\nnew file mode 100644\nindex 0000000000000..d6c36ca61c38c\n--- /dev/null\n+++ b/apps/design-system/content/docs/typography.mdx\n@@ -0,0 +1,15 @@\n+---\n+title: Typography\n+description: An overview of all available typography CSS variables.\n+---\n+\n+Some reusable patterns work better as CSS variables, or “shorthands”, than as components. Typography is one of these cases, since its usage and context vary widely.\n+\n+The shorthands below are composed of core [Tailwind utility classes](../docs/tailwind-classes). You can view the full list of shorthands in [`typography.scss`](https://github.com/supabase/supabase/blob/master/apps/studio/styles/typography.scss).\n+\n+## Shorthands\n+\n+| Value              | Usage                                                                        |\n+| ------------------ | ---------------------------------------------------------------------------- |\n+| `text-code-inline` | Apply to a `code` element for inline code or similar custom inline content   |\n+| `text-brand-link`  | Supabase green text that meets contrast requirements in light and dark modes |\ndiff --git a/apps/studio/components/grid/components/grid/GridError.tsx b/apps/studio/components/grid/components/grid/GridError.tsx\nindex 9999466ef57a7..824efe789e65f 100644\n--- a/apps/studio/components/grid/components/grid/GridError.tsx\n+++ b/apps/studio/components/grid/components/grid/GridError.tsx\n@@ -84,7 +84,7 @@ const InvalidSyntaxError = ({ error }: { error?: any }) => {\n         Verify that your filter values are correct before applying the filters again.\n       </p>\n       <p className=\"text-sm text-foreground-lighter prose max-w-full !mb-4\">\n-        Error: <code className=\"text-xs\">{error.message}</code>\n+        Error: <code className=\"text-code-inline\">{error.message}</code>\n       </p>\n \n       <Button type=\"default\" onClick={() => onApplyFilters([])}>\n@@ -117,7 +117,7 @@ const InvalidOrderingOperatorError = ({ error }: { error: any }) => {\n         again.\n       </p>\n       <p className=\"text-sm text-foreground-lighter prose max-w-full !mb-4\">\n-        Error: <code className=\"text-xs\">{error.message}</code>\n+        Error: <code className=\"text-code-inline\">{error.message}</code>\n       </p>\n \n       <Button type=\"default\" onClick={() => onApplySorts([])}>\ndiff --git a/apps/studio/components/interfaces/Advisors/EnableRuleModal.tsx b/apps/studio/components/interfaces/Advisors/EnableRuleModal.tsx\nindex 10f55aabad59f..571735b0e3afa 100644\n--- a/apps/studio/components/interfaces/Advisors/EnableRuleModal.tsx\n+++ b/apps/studio/components/interfaces/Advisors/EnableRuleModal.tsx\n@@ -48,7 +48,7 @@ export const EnableRuleModal = ({ lint, rule }: EnableRuleModalProps) => {\n       </DialogTrigger>\n       <DialogContent size=\"small\">\n         <DialogHeader>\n-          <DialogTitle>Confirm to enable rule</DialogTitle>\n+          <DialogTitle>Enable rule</DialogTitle>\n         </DialogHeader>\n         <DialogSectionSeparator />\n         <DialogSection>\ndiff --git a/apps/studio/components/interfaces/App/FeaturePreview/CLSPreview.tsx b/apps/studio/components/interfaces/App/FeaturePreview/CLSPreview.tsx\nindex 748ec6cec44d7..036990b4a678a 100644\n--- a/apps/studio/components/interfaces/App/FeaturePreview/CLSPreview.tsx\n+++ b/apps/studio/components/interfaces/App/FeaturePreview/CLSPreview.tsx\n@@ -27,7 +27,7 @@ export const CLSPreview = () => {\n           <WarningIcon />\n           <AlertTitle_Shadcn_>\n             Changes to column privileges will not be reflected in migrations when running{' '}\n-            <code className=\"text-xs\">supabase db diff</code>.\n+            <code className=\"text-code-inline\">supabase db diff</code>.\n           </AlertTitle_Shadcn_>\n           <AlertDescription_Shadcn_>\n             Column privileges are not supported in the current version of the Supabase CLI.\ndiff --git a/apps/studio/components/interfaces/Auth/AuditLogsForm.tsx b/apps/studio/components/interfaces/Auth/AuditLogsForm.tsx\nindex 1b3a726bb0b05..41eb312f2c0d1 100644\n--- a/apps/studio/components/interfaces/Auth/AuditLogsForm.tsx\n+++ b/apps/studio/components/interfaces/Auth/AuditLogsForm.tsx\n@@ -128,9 +128,7 @@ export const AuditLogsForm = () => {\n                             rel=\"noopener noreferrer\"\n                             href={`/project/${projectRef}/editor/${auditLogTable?.id}`}\n                           >\n-                            <code className=\"text-xs bg-surface-200 px-1 py-0.5 rounded\">\n-                              {AUDIT_LOG_ENTRIES_TABLE}\n-                            </code>\n+                            <code className=\"text-code-inline\">{AUDIT_LOG_ENTRIES_TABLE}</code>\n                           </InlineLink>{' '}\n                           table.\n                           <br />\ndiff --git a/apps/studio/components/interfaces/Auth/BasicAuthSettingsForm.tsx b/apps/studio/components/interfaces/Auth/BasicAuthSettingsForm.tsx\nindex 109aee659470a..4712b5f8914f2 100644\n--- a/apps/studio/components/interfaces/Auth/BasicAuthSettingsForm.tsx\n+++ b/apps/studio/components/interfaces/Auth/BasicAuthSettingsForm.tsx\n@@ -247,14 +247,15 @@ export const BasicAuthSettingsForm = () => {\n                     <WarningIcon />\n                     <div>\n                       <AlertTitle_Shadcn_>\n-                        Anonymous users will use the <code className=\"text-xs\">authenticated</code>{' '}\n-                        role when signing in\n+                        Anonymous users will use the{' '}\n+                        <code className=\"text-code-inline\">authenticated</code> role when signing in\n                       </AlertTitle_Shadcn_>\n                       <AlertDescription_Shadcn_ className=\"flex flex-col gap-y-3\">\n                         <p>\n                           As a result, anonymous users will be subjected to RLS policies that apply\n-                          to the <code className=\"text-xs\">public</code> and{' '}\n-                          <code className=\"text-xs\">authenticated</code> roles. We strongly advise{' '}\n+                          to the <code className=\"text-code-inline\">public</code> and{' '}\n+                          <code className=\"text-code-inline\">authenticated</code> roles. We strongly\n+                          advise{' '}\n                           <Link\n                             href={`/project/${projectRef}/auth/policies`}\n                             className=\"text-foreground underline\"\ndiff --git a/apps/studio/components/interfaces/Auth/Policies/PolicyEditorPanel/PolicyDetailsV2.tsx b/apps/studio/components/interfaces/Auth/Policies/PolicyEditorPanel/PolicyDetailsV2.tsx\nindex dc48f93087ba8..36606b5113b8d 100644\n--- a/apps/studio/components/interfaces/Auth/Policies/PolicyEditorPanel/PolicyDetailsV2.tsx\n+++ b/apps/studio/components/interfaces/Auth/Policies/PolicyEditorPanel/PolicyDetailsV2.tsx\n@@ -136,7 +136,7 @@ export const PolicyDetailsV2 = ({\n                 <FormLabel_Shadcn_ className=\"flex items-center gap-x-4\">\n                   <p className=\"text-foreground-light text-sm\">Table</p>\n                   <p className=\"text-foreground-light text-sm\">\n-                    <code className=\"text-xs\">on</code> clause\n+                    <code className=\"text-code-inline\">on</code> clause\n                   </p>\n                 </FormLabel_Shadcn_>\n                 {authContext === 'database' && (\n@@ -225,7 +225,7 @@ export const PolicyDetailsV2 = ({\n                 <FormLabel_Shadcn_ className=\"flex items-center gap-x-4\">\n                   <p className=\"text-foreground-light text-sm\">Policy Behavior</p>\n                   <p className=\"text-foreground-light text-sm\">\n-                    <code className=\"text-xs\">as</code> clause\n+                    <code className=\"text-code-inline\">as</code> clause\n                   </p>\n                 </FormLabel_Shadcn_>\n                 <FormControl_Shadcn_>\n@@ -267,7 +267,7 @@ export const PolicyDetailsV2 = ({\n                 <FormLabel_Shadcn_ className=\"flex items-center gap-x-4\">\n                   <p className=\"text-foreground-light text-sm\">Policy Command</p>\n                   <p className=\"text-foreground-light text-sm\">\n-                    <code className=\"text-xs\">for</code> clause\n+                    <code className=\"text-code-inline\">for</code> clause\n                   </p>\n                 </FormLabel_Shadcn_>\n                 <FormControl_Shadcn_>\n@@ -308,7 +308,7 @@ export const PolicyDetailsV2 = ({\n                 <FormLabel_Shadcn_ className=\"flex items-center gap-x-4\">\n                   <p className=\"text-foreground-light text-sm\">Target Roles</p>\n                   <p className=\"text-foreground-light text-sm\">\n-                    <code className=\"text-xs\">to</code> clause\n+                    <code className=\"text-code-inline\">to</code> clause\n                   </p>\n                 </FormLabel_Shadcn_>\n                 <FormControl_Shadcn_>\ndiff --git a/apps/studio/components/interfaces/BranchManagement/CreateBranchModal.tsx b/apps/studio/components/interfaces/BranchManagement/CreateBranchModal.tsx\nindex 18374b7484376..87a1cfce488d6 100644\n--- a/apps/studio/components/interfaces/BranchManagement/CreateBranchModal.tsx\n+++ b/apps/studio/components/interfaces/BranchManagement/CreateBranchModal.tsx\n@@ -564,7 +564,7 @@ export const CreateBranchModal = () => {\n                   <p className=\"text-sm text-foreground-light\">\n                     {withData ? (\n                       <>\n-                        <code className=\"text-xs font-mono\">{branchComputeSize.label}</code> compute\n+                        <code className=\"text-code-inline\">{branchComputeSize.label}</code> compute\n                         size is automatically selected to match your production branch. You may\n                         downgrade after creation or pause the branch when not in use to save cost.\n                       </>\ndiff --git a/apps/studio/components/interfaces/Database/ETL/UpdateVersionModal.tsx b/apps/studio/components/interfaces/Database/ETL/UpdateVersionModal.tsx\nindex 78439c97b4b51..8881506bd435c 100644\n--- a/apps/studio/components/interfaces/Database/ETL/UpdateVersionModal.tsx\n+++ b/apps/studio/components/interfaces/Database/ETL/UpdateVersionModal.tsx\n@@ -125,11 +125,11 @@ export const UpdateVersionModal = ({\n           <div className=\"flex flex-col gap-y-2 mt-2 pb-2\">\n             <div className=\"text-sm text-foreground prose max-w-full\">\n               <p className=\"text-foreground-light mb-1\">Current version:</p>{' '}\n-              <code className=\"text-xs\">{currentVersionName ?? 'Unknown'}</code>\n+              <code className=\"text-code-inline\">{currentVersionName ?? 'Unknown'}</code>\n             </div>\n             <div className=\"text-sm text-foreground prose max-w-full\">\n               <p className=\"text-foreground-light mb-1\">New version:</p>{' '}\n-              <code className=\"text-xs\">{newVersionName ?? 'Unknown'}</code>\n+              <code className=\"text-code-inline\">{newVersionName ?? 'Unknown'}</code>\n             </div>\n           </div>\n         </CollapsibleContent_Shadcn_>\ndiff --git a/apps/studio/components/interfaces/Database/Extensions/EnableExtensionModal.tsx b/apps/studio/components/interfaces/Database/Extensions/EnableExtensionModal.tsx\nindex 2298b219e8505..d8662ed768615 100644\n--- a/apps/studio/components/interfaces/Database/Extensions/EnableExtensionModal.tsx\n+++ b/apps/studio/components/interfaces/Database/Extensions/EnableExtensionModal.tsx\n@@ -124,8 +124,8 @@ const EnableExtensionModal = ({ visible, extension, onCancel }: EnableExtensionM\n       size=\"small\"\n       header={\n         <div className=\"flex items-baseline gap-2\">\n-          <h5 className=\"text-foreground\">Confirm to enable</h5>\n-          <code className=\"text-xs\">{extension.name}</code>\n+          <h5 className=\"text-foreground\">Enable</h5>\n+          <code className=\"text-code-inline\">{extension.name}</code>\n         </div>\n       }\n     >\ndiff --git a/apps/studio/components/interfaces/Database/Hooks/HooksList/HookList.tsx b/apps/studio/components/interfaces/Database/Hooks/HooksList/HookList.tsx\nindex 5ef24ae87f65f..4b691f27578d8 100644\n--- a/apps/studio/components/interfaces/Database/Hooks/HooksList/HookList.tsx\n+++ b/apps/studio/components/interfaces/Database/Hooks/HooksList/HookList.tsx\n@@ -96,7 +96,7 @@ export const HookList = ({\n             </Table.td>\n             <Table.td className=\"hidden xl:table-cell\">\n               <p className=\"truncate\" title={url}>\n-                <code className=\"font-mono text-xs\">{method}</code>: {url}\n+                <code className=\"text-code-inline\">{method}</code>: {url}\n               </p>\n             </Table.td>\n             <Table.td className=\"text-right\">\ndiff --git a/apps/studio/components/interfaces/Database/ProtectedSchemaWarning.tsx b/apps/studio/components/interfaces/Database/ProtectedSchemaWarning.tsx\nindex e5735bfbc5147..c00c13ad14ff4 100644\n--- a/apps/studio/components/interfaces/Database/ProtectedSchemaWarning.tsx\n+++ b/apps/studio/components/interfaces/Database/ProtectedSchemaWarning.tsx\n@@ -84,8 +84,8 @@ export const ProtectedSchemaWarning = ({\n         </p>\n       ) : reason === 'fdw' && fdwType === 's3_vectors' ? (\n         <p>\n-          The <code className=\"text-xs\">{schema}</code> schema is used by Supabase to connect to\n-          vector buckets and is read-only through the dashboard.\n+          The <code className=\"text-code-inline\">{schema}</code> schema is used by Supabase to\n+          connect to vector buckets and is read-only through the dashboard.\n         </p>\n       ) : (\n         <>\ndiff --git a/apps/studio/components/interfaces/Database/Tables/ColumnList.tsx b/apps/studio/components/interfaces/Database/Tables/ColumnList.tsx\nindex 27b48c39b1d5a..5bd11cf444fd0 100644\n--- a/apps/studio/components/interfaces/Database/Tables/ColumnList.tsx\n+++ b/apps/studio/components/interfaces/Database/Tables/ColumnList.tsx\n@@ -152,10 +152,10 @@ export const ColumnList = ({\n                       )}\n                     </Table.td>\n                     <Table.td>\n-                      <code className=\"text-xs\">{x.data_type}</code>\n+                      <code className=\"text-code-inline\">{x.data_type}</code>\n                     </Table.td>\n                     <Table.td className=\"font-mono text-xs\">\n-                      <code className=\"text-xs\">{x.format}</code>\n+                      <code className=\"text-code-inline\">{x.format}</code>\n                     </Table.td>\n                     <Table.td className=\"font-mono text-xs\">\n                       {x.is_nullable ? (\ndiff --git a/apps/studio/components/interfaces/Database/Tables/TableList.tsx b/apps/studio/components/interfaces/Database/Tables/TableList.tsx\nindex 1a6ef0b3e63d1..4faae844bb4dc 100644\n--- a/apps/studio/components/interfaces/Database/Tables/TableList.tsx\n+++ b/apps/studio/components/interfaces/Database/Tables/TableList.tsx\n@@ -427,7 +427,11 @@ export const TableList = ({\n                           {x.rows !== undefined ? x.rows.toLocaleString() : '-'}\n                         </TableCell>\n                         <TableCell className=\"hidden text-right xl:table-cell\">\n-                          {x.size !== undefined ? <code className=\"text-xs\">{x.size}</code> : '-'}\n+                          {x.size !== undefined ? (\n+                            <code className=\"text-code-inline\">{x.size}</code>\n+                          ) : (\n+                            '-'\n+                          )}\n                         </TableCell>\n                         <TableCell className=\"hidden xl:table-cell text-center\">\n                           {(realtimePublication?.tables ?? []).find(\ndiff --git a/apps/studio/components/interfaces/Home/NewProjectPanel/APIKeys.tsx b/apps/studio/components/interfaces/Home/NewProjectPanel/APIKeys.tsx\nindex 49ca5fafef116..547289182f9b0 100644\n--- a/apps/studio/components/interfaces/Home/NewProjectPanel/APIKeys.tsx\n+++ b/apps/studio/components/interfaces/Home/NewProjectPanel/APIKeys.tsx\n@@ -152,8 +152,8 @@ export const APIKeys = () => {\n                 <div className=\"space-y-2\">\n                   <p className=\"text-sm\">API Key</p>\n                   <div className=\"flex items-center space-x-1 -ml-1\">\n-                    <code className=\"text-xs\">{anonKey?.name}</code>\n-                    <code className=\"text-xs\">public</code>\n+                    <code className=\"text-code-inline\">{anonKey?.name}</code>\n+                    <code className=\"text-code-inline\">public</code>\n                   </div>\n                 </div>\n               }\ndiff --git a/apps/studio/components/interfaces/Integrations/CronJobs/CreateCronJobSheet/CreateCronJobSheet.tsx b/apps/studio/components/interfaces/Integrations/CronJobs/CreateCronJobSheet/CreateCronJobSheet.tsx\nindex c34a0ab0b9bf1..53e4232800d16 100644\n--- a/apps/studio/components/interfaces/Integrations/CronJobs/CreateCronJobSheet/CreateCronJobSheet.tsx\n+++ b/apps/studio/components/interfaces/Integrations/CronJobs/CreateCronJobSheet/CreateCronJobSheet.tsx\n@@ -366,8 +366,8 @@ export const CreateCronJobSheet = ({\n                     // @ts-ignore\n                     title={\n                       <span>\n-                        Enable <code className=\"text-xs w-min\">pg_net</code> for HTTP requests or\n-                        Edge Functions\n+                        Enable <code className=\"text-code-inline w-min\">pg_net</code> for HTTP\n+                        requests or Edge Functions\n                       </span>\n                     }\n                     description={\ndiff --git a/apps/studio/components/interfaces/Integrations/CronJobs/CronJobPage.tsx b/apps/studio/components/interfaces/Integrations/CronJobs/CronJobPage.tsx\nindex a27a755be2057..c225df0f4cd1f 100644\n--- a/apps/studio/components/interfaces/Integrations/CronJobs/CronJobPage.tsx\n+++ b/apps/studio/components/interfaces/Integrations/CronJobs/CronJobPage.tsx\n@@ -103,7 +103,7 @@ export const CronJobPage = () => {\n       with command{' '}\n       <Tooltip>\n         <TooltipTrigger asChild>\n-          <code className=\"text-xs font-mono bg-surface-200 px-1 py-0.5 rounded max-w-[200px] inline-block truncate align-bottom cursor-pointer\">\n+          <code className=\"text-code-inline max-w-[200px] inline-block truncate align-bottom cursor-pointer\">\n             {job.command}\n           </code>\n         </TooltipTrigger>\ndiff --git a/apps/studio/components/interfaces/Integrations/Queues/QueueTab.tsx b/apps/studio/components/interfaces/Integrations/Queues/QueueTab.tsx\nindex d37a0a6edb292..9f18345295f7d 100644\n--- a/apps/studio/components/interfaces/Integrations/Queues/QueueTab.tsx\n+++ b/apps/studio/components/interfaces/Integrations/Queues/QueueTab.tsx\n@@ -1,8 +1,8 @@\n import { Lock, Paintbrush, PlusCircle, Trash2 } from 'lucide-react'\n import Link from 'next/link'\n+import { parseAsBoolean, useQueryState } from 'nuqs'\n import { useMemo, useState } from 'react'\n import { toast } from 'sonner'\n-import { parseAsBoolean, useQueryState } from 'nuqs'\n \n import { useParams } from 'common'\n import { DeleteQueue } from 'components/interfaces/Integrations/Queues/SingleQueue/DeleteQueue'\n@@ -269,7 +269,7 @@ You may opt to manage your queues via any Supabase client libraries or PostgREST\n \n       <ConfirmationModal\n         visible={rlsConfirmModalOpen}\n-        title=\"Confirm to enable Row Level Security\"\n+        title=\"Enable Row Level Security\"\n         confirmLabel=\"Enable RLS\"\n         confirmLabelLoading=\"Enabling RLS\"\n         loading={isUpdatingTable}\ndiff --git a/apps/studio/components/interfaces/Integrations/Queues/QueuesSettings.tsx b/apps/studio/components/interfaces/Integrations/Queues/QueuesSettings.tsx\nindex 84aa3e82fb06c..a7c3643025ef3 100644\n--- a/apps/studio/components/interfaces/Integrations/Queues/QueuesSettings.tsx\n+++ b/apps/studio/components/interfaces/Integrations/Queues/QueuesSettings.tsx\n@@ -24,6 +24,7 @@ import { useTableUpdateMutation } from 'data/tables/table-update-mutation'\n import { useTablesQuery } from 'data/tables/tables-query'\n import { useAsyncCheckPermissions } from 'hooks/misc/useCheckPermissions'\n import { useSelectedProjectQuery } from 'hooks/misc/useSelectedProject'\n+import { IS_PLATFORM } from 'lib/constants'\n import {\n   Button,\n   Form_Shadcn_,\n@@ -36,7 +37,6 @@ import {\n import { Admonition } from 'ui-patterns'\n import ConfirmationModal from 'ui-patterns/Dialogs/ConfirmationModal'\n import { FormItemLayout } from 'ui-patterns/form/FormItemLayout/FormItemLayout'\n-import { IS_PLATFORM } from 'lib/constants'\n \n // [Joshen] Not convinced with the UI and layout but getting the functionality out first\n \n@@ -214,22 +214,24 @@ export const QueuesSettings = () => {\n                           <>\n                             <p className=\"max-w-2xl\">\n                               When enabled, you will be able to use the following functions from the{' '}\n-                              <code className=\"text-xs\">{QUEUES_SCHEMA}</code> schema to manage your\n-                              queues via any Supabase client library or PostgREST endpoints:\n+                              <code className=\"text-code-inline\">{QUEUES_SCHEMA}</code> schema to\n+                              manage your queues via any Supabase client library or PostgREST\n+                              endpoints:\n                             </p>\n                             <p className=\"mt-2\">\n-                              <code className=\"text-xs\">send</code>,{' '}\n-                              <code className=\"text-xs\">send_batch</code>,{' '}\n-                              <code className=\"text-xs\">read</code>,{' '}\n-                              <code className=\"text-xs\">pop</code>,\n-                              <code className=\"text-xs\">archive</code>, and{' '}\n-                              <code className=\"text-xs\">delete</code>\n+                              <code className=\"text-code-inline\">send</code>,{' '}\n+                              <code className=\"text-code-inline\">send_batch</code>,{' '}\n+                              <code className=\"text-code-inline\">read</code>,{' '}\n+                              <code className=\"text-code-inline\">pop</code>,\n+                              <code className=\"text-code-inline\">archive</code>, and{' '}\n+                              <code className=\"text-code-inline\">delete</code>\n                             </p>\n                             {!IS_PLATFORM ? (\n                               <div className=\"mt-6 max-w-2xl\">\n                                 When running Supabase locally with the CLI or self-hosting using\n                                 Docker Compose, you also need to update your configuration to expose\n-                                the <code className=\"text-xs\">{QUEUES_SCHEMA}</code> schema.\n+                                the <code className=\"text-code-inline\">{QUEUES_SCHEMA}</code>{' '}\n+                                schema.\n                                 <br />\n                                 <TextLink\n                                   target=\"_blank\"\n@@ -269,7 +271,7 @@ export const QueuesSettings = () => {\n                             {tablesWithoutRLS.map((x) => {\n                               return (\n                                 <li key={x.name}>\n-                                  <code className=\"text-xs\">{x.name.slice(2)}</code>\n+                                  <code className=\"text-code-inline\">{x.name.slice(2)}</code>\n                                 </li>\n                               )\n                             })}\n@@ -291,27 +293,28 @@ export const QueuesSettings = () => {\n                         <Admonition type=\"warning\" className=\"mt-2\">\n                           <p>\n                             Queues will be exposed and managed through the{' '}\n-                            <code className=\"text-xs\">{QUEUES_SCHEMA}</code> schema\n+                            <code className=\"text-code-inline\">{QUEUES_SCHEMA}</code> schema\n                           </p>\n                           <p className=\"text-foreground-light\">\n                             Database functions will be created in the{' '}\n-                            <code className=\"text-xs\">{QUEUES_SCHEMA}</code> schema upon enabling.\n-                            Call these functions via any Supabase client library or PostgREST\n-                            endpoint to manage your queues. Permissions on individual queues can\n-                            also be further managed through privileges and row level security (RLS).\n+                            <code className=\"text-code-inline\">{QUEUES_SCHEMA}</code> schema upon\n+                            enabling. Call these functions via any Supabase client library or\n+                            PostgREST endpoint to manage your queues. Permissions on individual\n+                            queues can also be further managed through privileges and row level\n+                            security (RLS).\n                           </p>\n                         </Admonition>\n                       )}\n                       {formState.dirtyFields.enable && field.value === false && (\n                         <Admonition type=\"warning\" className=\"mt-2\">\n                           <p>\n-                            The <code className=\"text-xs\">{QUEUES_SCHEMA}</code> schema will be\n-                            removed once disabled\n+                            The <code className=\"text-code-inline\">{QUEUES_SCHEMA}</code> schema\n+                            will be removed once disabled\n                           </p>\n                           <p className=\"text-foreground-light\">\n                             Ensure that the database functions from the{' '}\n-                            <code className=\"text-xs\">{QUEUES_SCHEMA}</code> schema are not in use\n-                            within your client applications before disabling.\n+                            <code className=\"text-code-inline\">{QUEUES_SCHEMA}</code> schema are not\n+                            in use within your client applications before disabling.\n                           </p>\n                         </Admonition>\n                       )}\n@@ -347,7 +350,7 @@ export const QueuesSettings = () => {\n \n       <ConfirmationModal\n         visible={rlsConfirmModalOpen}\n-        title=\"Confirm to enable Row Level Security\"\n+        title=\"Enable Row Level Security\"\n         confirmLabel=\"Enable RLS\"\n         confirmLabelLoading=\"Enabling RLS\"\n         loading={isUpdatingRls}\n@@ -361,7 +364,7 @@ export const QueuesSettings = () => {\n           {tablesWithoutRLS.map((x) => {\n             return (\n               <li key={x.id}>\n-                <code className=\"text-xs\">{x.name.slice(2)}</code>\n+                <code className=\"text-code-inline\">{x.name.slice(2)}</code>\n               </li>\n             )\n           })}\ndiff --git a/apps/studio/components/interfaces/Integrations/Queues/SingleQueue/QueueSettings.tsx b/apps/studio/components/interfaces/Integrations/Queues/SingleQueue/QueueSettings.tsx\nindex 14154c46689a6..0fa5c51edd0cb 100644\n--- a/apps/studio/components/interfaces/Integrations/Queues/SingleQueue/QueueSettings.tsx\n+++ b/apps/studio/components/interfaces/Integrations/Queues/SingleQueue/QueueSettings.tsx\n@@ -243,7 +243,7 @@ export const QueueSettings = ({}: QueueSettingsProps) => {\n             {isExposed && (\n               <>\n                 These will also determine access to each function available from the{' '}\n-                <code className=\"text-xs\">pgmq_public</code> schema.\n+                <code className=\"text-code-inline\">pgmq_public</code> schema.\n               </>\n             )}\n           </SheetDescription>\ndiff --git a/apps/studio/components/interfaces/Integrations/Wrappers/CreateIcebergWrapperSheet.tsx b/apps/studio/components/interfaces/Integrations/Wrappers/CreateIcebergWrapperSheet.tsx\nindex 49798d20ef1ea..c3938d1611511 100644\n--- a/apps/studio/components/interfaces/Integrations/Wrappers/CreateIcebergWrapperSheet.tsx\n+++ b/apps/studio/components/interfaces/Integrations/Wrappers/CreateIcebergWrapperSheet.tsx\n@@ -206,7 +206,7 @@ export const CreateIcebergWrapperSheet = ({\n                           (values?.wrapper_name ?? '').length > 0 ? (\n                             <>\n                               Your wrapper's server name will be{' '}\n-                              <code className=\"text-xs\">{values.wrapper_name}_server</code>\n+                              <code className=\"text-code-inline\">{values.wrapper_name}_server</code>\n                             </>\n                           ) : (\n                             ''\ndiff --git a/apps/studio/components/interfaces/Integrations/Wrappers/CreateWrapperSheet.tsx b/apps/studio/components/interfaces/Integrations/Wrappers/CreateWrapperSheet.tsx\nindex ec8b596be3d2c..ef74d8877127d 100644\n--- a/apps/studio/components/interfaces/Integrations/Wrappers/CreateWrapperSheet.tsx\n+++ b/apps/studio/components/interfaces/Integrations/Wrappers/CreateWrapperSheet.tsx\n@@ -220,7 +220,7 @@ export const CreateWrapperSheet = ({\n                           (values?.wrapper_name ?? '').length > 0 ? (\n                             <>\n                               Your wrapper's server name will be{' '}\n-                              <code className=\"text-xs\">{values.wrapper_name}_server</code>\n+                              <code className=\"text-code-inline\">{values.wrapper_name}_server</code>\n                             </>\n                           ) : (\n                             ''\ndiff --git a/apps/studio/components/interfaces/Integrations/Wrappers/EditWrapperSheet.tsx b/apps/studio/components/interfaces/Integrations/Wrappers/EditWrapperSheet.tsx\nindex d89f3729b5045..60bc7bc88192a 100644\n--- a/apps/studio/components/interfaces/Integrations/Wrappers/EditWrapperSheet.tsx\n+++ b/apps/studio/components/interfaces/Integrations/Wrappers/EditWrapperSheet.tsx\n@@ -215,12 +215,12 @@ export const EditWrapperSheet = ({\n                           values.wrapper_name !== initialValues.wrapper_name ? (\n                             <>\n                               Your wrapper's server name will be updated to{' '}\n-                              <code className=\"text-xs\">{values.wrapper_name}_server</code>\n+                              <code className=\"text-code-inline\">{values.wrapper_name}_server</code>\n                             </>\n                           ) : (\n                             <>\n                               Your wrapper's server name is{' '}\n-                              <code className=\"text-xs\">{values.wrapper_name}_server</code>\n+                              <code className=\"text-code-inline\">{values.wrapper_name}_server</code>\n                             </>\n                           )\n                         }\ndiff --git a/apps/studio/components/interfaces/Integrations/Wrappers/OverviewTab.tsx b/apps/studio/components/interfaces/Integrations/Wrappers/OverviewTab.tsx\nindex 5601ca56c8d3d..ecc85736351c0 100644\n--- a/apps/studio/components/interfaces/Integrations/Wrappers/OverviewTab.tsx\n+++ b/apps/studio/components/interfaces/Integrations/Wrappers/OverviewTab.tsx\n@@ -92,8 +92,8 @@ export const WrapperOverviewTab = () => {\n                   {wrapperMeta.minimumExtensionVersion}. You have version{' '}\n                   {wrappersExtension?.installed_version} installed. Please{' '}\n                   {databaseNeedsUpgrading && 'upgrade your database then '}update the extension by\n-                  disabling and enabling the <code className=\"text-xs\">wrappers</code> extension to\n-                  create this wrapper.\n+                  disabling and enabling the <code className=\"text-code-inline\">wrappers</code>{' '}\n+                  extension to create this wrapper.\n                 </p>\n                 <p className=\"text-warning\">\n                   Warning: Before reinstalling the wrapper extension, you must first remove all\ndiff --git a/apps/studio/components/interfaces/ProjectCreation/SecurityOptions.tsx b/apps/studio/components/interfaces/ProjectCreation/SecurityOptions.tsx\nindex 69fd74fed258e..9a7b08f669ad1 100644\n--- a/apps/studio/components/interfaces/ProjectCreation/SecurityOptions.tsx\n+++ b/apps/studio/components/interfaces/ProjectCreation/SecurityOptions.tsx\n@@ -116,7 +116,8 @@ export const SecurityOptions = ({\n                           // @ts-ignore\n                           description={\n                             <>\n-                              Query all tables in the <code className=\"text-xs\">public</code> schema\n+                              Query all tables in the{' '}\n+                              <code className=\"text-code-inline\">public</code> schema\n                             </>\n                           }\n                           className=\"[&>div>div>p]:text-left [&>div>div>p]:text-xs\"\n@@ -132,7 +133,7 @@ export const SecurityOptions = ({\n                           description={\n                             <>\n                               Query allowlisted tables in a dedicated{' '}\n-                              <code className=\"text-xs\">api</code> schema\n+                              <code className=\"text-code-inline\">api</code> schema\n                             </>\n                           }\n                           className=\"[&>div>div>p]:text-left [&>div>div>p]:text-xs\"\ndiff --git a/apps/studio/components/interfaces/Realtime/RealtimeSettings.tsx b/apps/studio/components/interfaces/Realtime/RealtimeSettings.tsx\nindex 5f650013484e5..d67c11d459910 100644\n--- a/apps/studio/components/interfaces/Realtime/RealtimeSettings.tsx\n+++ b/apps/studio/components/interfaces/Realtime/RealtimeSettings.tsx\n@@ -260,8 +260,10 @@ export const RealtimeSettings = () => {\n                                         <p className=\"prose max-w-full text-sm\">\n                                           Private mode is {isSettingToPrivate ? 'being ' : ''}\n                                           enabled, but no RLS policies exists on the{' '}\n-                                          <code className=\"text-xs\">realtime.messages</code> table.\n-                                          No messages will be received by users.\n+                                          <code className=\"text-code-inline\">\n+                                            realtime.messages\n+                                          </code>{' '}\n+                                          table. No messages will be received by users.\n                                         </p>\n \n                                         <Button asChild type=\"default\" className=\"mt-2\">\ndiff --git a/apps/studio/components/interfaces/SQLEditor/RunQueryWarningModal.tsx b/apps/studio/components/interfaces/SQLEditor/RunQueryWarningModal.tsx\nindex 4a37804be1cbf..e902c67a991c3 100644\n--- a/apps/studio/components/interfaces/SQLEditor/RunQueryWarningModal.tsx\n+++ b/apps/studio/components/interfaces/SQLEditor/RunQueryWarningModal.tsx\n@@ -51,8 +51,8 @@ export const RunQueryWarningModal = ({\n             <li className=\"grid pt-2 pb-3 px-4 gap-1\">\n               <span className=\"font-bold\">Query uses update without a where clause</span>\n               <span className=\"text-foreground-lighter\">\n-                Without a <code className=\"text-xs\">where</code> clause, this could update all rows\n-                in the table.\n+                Without a <code className=\"text-code-inline\">where</code> clause, this could update\n+                all rows in the table.\n               </span>\n             </li>\n           )}\ndiff --git a/apps/studio/components/interfaces/Settings/API/HardenAPIModal.tsx b/apps/studio/components/interfaces/Settings/API/HardenAPIModal.tsx\nindex 3724aa3c5d363..9d4af853bf906 100644\n--- a/apps/studio/components/interfaces/Settings/API/HardenAPIModal.tsx\n+++ b/apps/studio/components/interfaces/Settings/API/HardenAPIModal.tsx\n@@ -105,8 +105,8 @@ export const HardenAPIModal = ({ visible, onClose }: HardenAPIModalProps) => {\n         <DialogHeader>\n           <DialogTitle>Switch the default API schema</DialogTitle>\n           <DialogDescription>\n-            Expose a custom schema instead of the{' '}\n-            <code className=\"text-xs text-foreground\">public</code> schema\n+            Expose a custom schema instead of the <code className=\"text-code-inline\">public</code>{' '}\n+            schema\n           </DialogDescription>\n         </DialogHeader>\n \n@@ -114,10 +114,10 @@ export const HardenAPIModal = ({ visible, onClose }: HardenAPIModalProps) => {\n \n         <DialogSection className=\"text-sm text-foreground-light\">\n           <p>\n-            By default, the <code className=\"text-xs text-foreground\">public</code> schema is used\n-            to generate API routes. In some cases, it's better to use a custom schema. This is\n+            By default, the <code className=\"text-code-inline\">public</code> schema is used to\n+            generate API routes. In some cases, it's better to use a custom schema. This is\n             important if you use tools that generate tables in the{' '}\n-            <code className=\"text-xs text-foreground\">public</code> schema to{' '}\n+            <code className=\"text-code-inline\">public</code> schema to{' '}\n             <span className=\"text-brand\">prevent accidental exposure of data</span>.\n           </p>\n           <DocsButton\n@@ -132,8 +132,7 @@ export const HardenAPIModal = ({ visible, onClose }: HardenAPIModalProps) => {\n         <Collapsible_Shadcn_>\n           <CollapsibleTrigger_Shadcn_ className=\"py-4 px-5 w-full flex items-center justify-between text-sm\">\n             <p>\n-              1. Create a custom <code className=\"text-xs text-foreground\">api</code> schema and\n-              expose it\n+              1. Create a custom <code className=\"text-code-inline\">api</code> schema and expose it\n             </p>\n             {hasAPISchema && isAPISchemaExposed ? (\n               <Check size={16} className=\"text-brand\" />\n@@ -147,10 +146,10 @@ export const HardenAPIModal = ({ visible, onClose }: HardenAPIModalProps) => {\n           <CollapsibleContent_Shadcn_ className=\"text-sm text-foreground-light flex flex-col gap-y-4\">\n             <p className=\"mx-5\">\n               Click the button below to create a new schema named{' '}\n-              <code className=\"text-xs text-foreground\">api</code> and grant the{' '}\n-              <code className=\"text-xs text-foreground\">anon</code> and{' '}\n-              <code className=\"text-xs text-foreground\">authenticated</code> roles usage privileges\n-              on this schema. This schema will thereafter also be exposed to the Data API.\n+              <code className=\"text-code-inline\">api</code> and grant the{' '}\n+              <code className=\"text-code-inline\">anon</code> and{' '}\n+              <code className=\"text-code-inline\">authenticated</code> roles usage privileges on this\n+              schema. This schema will thereafter also be exposed to the Data API.\n             </p>\n \n             <div className=\"px-5\">\n@@ -160,8 +159,8 @@ export const HardenAPIModal = ({ visible, onClose }: HardenAPIModalProps) => {\n                   <div className=\"flex flex-col gap-y-2\">\n                     <p>\n                       The following query will be run to create the{' '}\n-                      <code className=\"text-xs text-foreground\">api</code> schema , as well as to\n-                      grant the necessary privileges to the respective roles\n+                      <code className=\"text-code-inline\">api</code> schema , as well as to grant the\n+                      necessary privileges to the respective roles\n                     </p>\n                     <CodeBlock\n                       language=\"sql\"\n@@ -195,11 +194,11 @@ export const HardenAPIModal = ({ visible, onClose }: HardenAPIModalProps) => {\n \n             <div className=\"flex flex-col gap-y-4 px-5 pb-4\">\n               <p>\n-                Under these new settings, the <code className=\"text-xs text-foreground\">anon</code>{' '}\n-                and <code className=\"text-xs text-foreground\">authenticated</code> roles can execute\n-                functions defined in the <code className=\"text-xs text-foreground\">api</code>{' '}\n-                schema, but they have no automatic permissions on any tables. On a table-by-table\n-                basis, you can grant them permissions by running the following command:\n+                Under these new settings, the <code className=\"text-code-inline\">anon</code> and{' '}\n+                <code className=\"text-code-inline\">authenticated</code> roles can execute functions\n+                defined in the <code className=\"text-code-inline\">api</code> schema, but they have\n+                no automatic permissions on any tables. On a table-by-table basis, you can grant\n+                them permissions by running the following command:\n               </p>\n               <CodeBlock\n                 language=\"sql\"\n@@ -216,8 +215,8 @@ export const HardenAPIModal = ({ visible, onClose }: HardenAPIModalProps) => {\n         <Collapsible_Shadcn_>\n           <CollapsibleTrigger_Shadcn_ className=\"py-4 px-5 w-full flex items-center justify-between text-sm\">\n             <p>\n-              2. Remove the <code className=\"text-xs text-foreground\">public</code> schema from the\n-              exposed schemas\n+              2. Remove the <code className=\"text-code-inline\">public</code> schema from the exposed\n+              schemas\n             </p>\n             {!isPublicSchemaExposed ? (\n               <Check size={16} className=\"text-brand\" />\n@@ -234,18 +233,18 @@ export const HardenAPIModal = ({ visible, onClose }: HardenAPIModalProps) => {\n                 <WarningIcon />\n                 <AlertTitle_Shadcn_ className=\"text-foreground\">\n                   Ensure that your app is no longer using the{' '}\n-                  <code className=\"text-xs text-foreground\">public</code> schema\n+                  <code className=\"text-code-inline\">public</code> schema\n                 </AlertTitle_Shadcn_>\n                 <AlertDescription_Shadcn_>\n-                  The <code className=\"text-xs text-foreground\">public</code> schema will not be\n-                  accessible via the API once its not exposed. You should be using the{' '}\n-                  <code className=\"text-xs text-foreground\">api</code> schema instead.\n+                  The <code className=\"text-code-inline\">public</code> schema will not be accessible\n+                  via the API once its not exposed. You should be using the{' '}\n+                  <code className=\"text-code-inline\">api</code> schema instead.\n                 </AlertDescription_Shadcn_>\n               </Alert_Shadcn_>\n               <p>\n                 Click the button below to remove the{' '}\n-                <code className=\"text-xs text-foreground\">public</code> schema from both Exposed\n-                schemas and Extra search path in your API configuration.\n+                <code className=\"text-code-inline\">public</code> schema from both Exposed schemas\n+                and Extra search path in your API configuration.\n               </p>\n               <ButtonTooltip\n                 type=\"primary\"\ndiff --git a/apps/studio/components/interfaces/Settings/API/PostgrestConfig.tsx b/apps/studio/components/interfaces/Settings/API/PostgrestConfig.tsx\nindex d37b7cafc2708..a76ce0f469ca4 100644\n--- a/apps/studio/components/interfaces/Settings/API/PostgrestConfig.tsx\n+++ b/apps/studio/components/interfaces/Settings/API/PostgrestConfig.tsx\n@@ -248,7 +248,7 @@ export const PostgrestConfig = () => {\n                               </p>\n                               <p>\n                                 You will see errors from the Postgrest endpoint\n-                                <code className=\"text-xs\">/rest/v1/</code>.\n+                                <code className=\"text-code-inline\">/rest/v1/</code>.\n                               </p>\n                             </AlertDescription_Shadcn_>\n                           </Alert_Shadcn_>\n@@ -316,14 +316,15 @@ export const PostgrestConfig = () => {\n                                   <>\n                                     <p className=\"prose text-sm\">\n                                       You will not be able to query tables and views in the{' '}\n-                                      <code className=\"text-xs\">public</code> schema via supabase-js\n-                                      or HTTP clients.\n+                                      <code className=\"text-code-inline\">public</code> schema via\n+                                      supabase-js or HTTP clients.\n                                     </p>\n                                     {isGraphqlExtensionEnabled && (\n                                       <>\n                                         <p className=\"prose text-sm mt-2\">\n-                                          Tables in the <code className=\"text-xs\">public</code>{' '}\n-                                          schema are still exposed over our GraphQL endpoints.\n+                                          Tables in the{' '}\n+                                          <code className=\"text-code-inline\">public</code> schema\n+                                          are still exposed over our GraphQL endpoints.\n                                         </p>\n                                         <Button asChild type=\"default\" className=\"mt-2\">\n                                           <Link href={`/project/${projectRef}/database/extensions`}>\ndiff --git a/apps/studio/components/interfaces/Settings/Database/NetworkRestrictions/AddRestrictionModal.tsx b/apps/studio/components/interfaces/Settings/Database/NetworkRestrictions/AddRestrictionModal.tsx\nindex e4e2b5c90f526..a122e44d0653c 100644\n--- a/apps/studio/components/interfaces/Settings/Database/NetworkRestrictions/AddRestrictionModal.tsx\n+++ b/apps/studio/components/interfaces/Settings/Database/NetworkRestrictions/AddRestrictionModal.tsx\n@@ -217,12 +217,13 @@ const AddRestrictionModal = ({\n               {isValidCIDR ? (\n                 <Modal.Content className=\"space-y-1\">\n                   <p className=\"text-sm\">\n-                    The address range <code className=\"text-xs\">{normalizedAddress}</code> will be\n-                    restricted\n+                    The address range <code className=\"text-code-inline\">{normalizedAddress}</code>{' '}\n+                    will be restricted\n                   </p>\n                   <p className=\"text-sm text-foreground-light\">\n-                    Selected address space: <code className=\"text-xs\">{addressRange.start}</code> to{' '}\n-                    <code className=\"text-xs\">{addressRange.end}</code>{' '}\n+                    Selected address space:{' '}\n+                    <code className=\"text-code-inline\">{addressRange.start}</code> to{' '}\n+                    <code className=\"text-code-inline\">{addressRange.end}</code>{' '}\n                   </p>\n                   <p className=\"text-sm text-foreground-light\">\n                     Number of addresses: {availableAddresses}\ndiff --git a/apps/studio/components/interfaces/Settings/Database/NetworkRestrictions/RemoveRestrictionModal.tsx b/apps/studio/components/interfaces/Settings/Database/NetworkRestrictions/RemoveRestrictionModal.tsx\nindex d923b6e73e1d7..1cd9dd1671fd4 100644\n--- a/apps/studio/components/interfaces/Settings/Database/NetworkRestrictions/RemoveRestrictionModal.tsx\n+++ b/apps/studio/components/interfaces/Settings/Database/NetworkRestrictions/RemoveRestrictionModal.tsx\n@@ -68,8 +68,8 @@ const RemoveRestrictionModal = ({\n     >\n       <Modal.Content className=\"space-y-4\">\n         <p className=\"text-sm text-foreground-light\">\n-          The IPv4 address <code className=\"text-xs\">{selectedRestriction}</code> will be removed\n-          from your list of network restrictions\n+          The IPv4 address <code className=\"text-code-inline\">{selectedRestriction}</code> will be\n+          removed from your list of network restrictions\n           {isRemovingOnlyRestriction\n             ? '.'\n             : \", and no longer have access to your project's database.\"}\ndiff --git a/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainActivate.tsx b/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainActivate.tsx\nindex 1065aeed40152..d9b155257664c 100644\n--- a/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainActivate.tsx\n+++ b/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainActivate.tsx\n@@ -78,7 +78,8 @@ const CustomDomainActivate = ({ projectRef, customDomain }: CustomDomainActivate\n               <AlertDescription_Shadcn_>\n                 <p className=\"col-span-12 text-sm lg:col-span-7 leading-6\">\n                   Your custom domain CNAME record for{' '}\n-                  <code className=\"text-xs\">{customDomain.hostname}</code> should resolve to{' '}\n+                  <code className=\"text-code-inline\">{customDomain.hostname}</code> should resolve\n+                  to{' '}\n                   {endpoint ? (\n                     <code className=\"text-xs\">{endpoint}</code>\n                   ) : (\ndiff --git a/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainVerify.tsx b/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainVerify.tsx\nindex 6560f2df3f962..44d1cea30a57b 100644\n--- a/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainVerify.tsx\n+++ b/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainVerify.tsx\n@@ -140,8 +140,8 @@ const CustomDomainVerify = () => {\n             </AlertTitle_Shadcn_>\n             <AlertDescription_Shadcn_>\n               Please add a CAA record allowing \"digicert.com\" to issue certificates for{' '}\n-              <code className=\"text-xs\">{customDomain?.hostname}</code>. For example:{' '}\n-              <code className=\"text-xs\">0 issue \"digicert.com\"</code>\n+              <code className=\"text-code-inline\">{customDomain?.hostname}</code>. For example:{' '}\n+              <code className=\"text-code-inline\">0 issue \"digicert.com\"</code>\n             </AlertDescription_Shadcn_>\n           </Alert_Shadcn_>\n         )}\ndiff --git a/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainsConfigureHostname.tsx b/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainsConfigureHostname.tsx\nindex 69983e1ae4f0f..f04b1e9d179f4 100644\n--- a/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainsConfigureHostname.tsx\n+++ b/apps/studio/components/interfaces/Settings/General/CustomDomainConfig/CustomDomainsConfigureHostname.tsx\n@@ -101,13 +101,13 @@ const CustomDomainsConfigureHostname = () => {\n                 <p className=\"col-span-12 text-sm lg:col-span-7 leading-6\">\n                   Set up a CNAME record for{' '}\n                   {values.domain ? (\n-                    <code className=\"text-xs\">{values.domain}</code>\n+                    <code className=\"text-code-inline\">{values.domain}</code>\n                   ) : (\n                     'your custom domain'\n                   )}{' '}\n                   resolving to{' '}\n                   {endpoint ? (\n-                    <code className=\"text-xs\">{endpoint}</code>\n+                    <code className=\"text-code-inline\">{endpoint}</code>\n                   ) : (\n                     \"your project's API URL\"\n                   )}{' '}\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx\nindex 7bda0f9e4b228..f422de03a43c7 100644\n--- a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/AnalyticsBucketDetails/NamespaceWithTables/TableRowComponent.tsx\n@@ -508,7 +508,7 @@ export const TableRowComponent = ({ table, schema, namespace }: TableRowComponen\n         variant=\"warning\"\n         visible={showStartReplicationModal}\n         loading={isUpdatingReplication}\n-        title=\"Confirm to enable replication for table\"\n+        title=\"Enable replication for table\"\n         confirmLabel=\"Enable replication\"\n         onCancel={() => setShowStartReplicationModal(false)}\n         onConfirm={() => onConfirmStartReplication()}\ndiff --git a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/CreateAnalyticsBucketModal.tsx b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/CreateAnalyticsBucketModal.tsx\nindex fb64c16b2f249..8f497f50d6140 100644\n--- a/apps/studio/components/interfaces/Storage/AnalyticsBuckets/CreateAnalyticsBucketModal.tsx\n+++ b/apps/studio/components/interfaces/Storage/AnalyticsBuckets/CreateAnalyticsBucketModal.tsx\n@@ -2,11 +2,10 @@ import { zodResolver } from '@hookform/resolvers/zod'\n import { PermissionAction } from '@supabase/shared-types/out/constants'\n import { Plus } from 'lucide-react'\n import { useRouter } from 'next/router'\n-import { useState } from 'react'\n+import { parseAsBoolean, useQueryState } from 'nuqs'\n import { SubmitHandler, useForm } from 'react-hook-form'\n import { toast } from 'sonner'\n import z from 'zod'\n-import { parseAsBoolean, useQueryState } from 'nuqs'\n \n import { useParams } from 'common'\n import { ButtonTooltip } from 'components/ui/ButtonTooltip'\n@@ -262,8 +261,8 @@ export const CreateAnalyticsBucketModal = ({\n                   title=\"Wrappers extension must be updated for Iceberg Wrapper support\"\n                 >\n                   <p className=\"prose max-w-full text-sm !leading-normal\">\n-                    Update the <code className=\"text-xs\">wrappers</code> extension by upgrading your\n-                    project from your{' '}\n+                    Update the <code className=\"text-code-inline\">wrappers</code> extension by\n+                    upgrading your project from your{' '}\n                     <InlineLink href={`/project/${ref}/settings/infrastructure`}>\n                       project settings\n                     </InlineLink>{' '}\ndiff --git a/apps/studio/components/interfaces/TableGridEditor/GridHeaderActions.tsx b/apps/studio/components/interfaces/TableGridEditor/GridHeaderActions.tsx\nindex 11fac7f273a3b..d4aea095088d2 100644\n--- a/apps/studio/components/interfaces/TableGridEditor/GridHeaderActions.tsx\n+++ b/apps/studio/components/interfaces/TableGridEditor/GridHeaderActions.tsx\n@@ -563,7 +563,7 @@ export const GridHeaderActions = ({ table, isRefetching }: GridHeaderActionsProp\n         <ConfirmModal\n           danger={table.rls_enabled}\n           visible={rlsConfirmModalOpen}\n-          title=\"Confirm to enable Row Level Security\"\n+          title=\"Enable Row Level Security\"\n           description=\"Are you sure you want to enable Row Level Security for this table?\"\n           buttonLabel=\"Enable RLS\"\n           buttonLoadingLabel=\"Updating\"\ndiff --git a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ColumnEditor/ColumnType.tsx b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ColumnEditor/ColumnType.tsx\nindex dc918a77b07a7..297dd0d443ccf 100644\n--- a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ColumnEditor/ColumnType.tsx\n+++ b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ColumnEditor/ColumnType.tsx\n@@ -277,15 +277,14 @@ const ColumnType = ({\n           <CriticalIcon />\n           <AlertTitle_Shadcn_>\n             {' '}\n-            It is recommended to use <code className=\"text-xs\">\n-              {recommendation.alternative}\n-            </code>{' '}\n-            instead\n+            It is recommended to use{' '}\n+            <code className=\"text-code-inline\">{recommendation.alternative}</code> instead\n           </AlertTitle_Shadcn_>\n           <AlertDescription_Shadcn_>\n             <p>\n               Postgres recommends against using the data type{' '}\n-              <code className=\"text-xs\">{value}</code> unless you have a very specific use case.\n+              <code className=\"text-code-inline\">{value}</code> unless you have a very specific use\n+              case.\n             </p>\n             <div className=\"flex items-center space-x-2 mt-3\">\n               <Button asChild type=\"default\" icon={<ExternalLink />}>\ndiff --git a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ForeignKeySelector/ForeignKeySelector.tsx b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ForeignKeySelector/ForeignKeySelector.tsx\nindex be7eee6e8d13c..c7bb451b9df63 100644\n--- a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ForeignKeySelector/ForeignKeySelector.tsx\n+++ b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ForeignKeySelector/ForeignKeySelector.tsx\n@@ -15,8 +15,8 @@ import { DocsButton } from 'components/ui/DocsButton'\n import InformationBox from 'components/ui/InformationBox'\n import { FOREIGN_KEY_CASCADE_ACTION } from 'data/database/database-query-constants'\n import { useSchemasQuery } from 'data/database/schemas-query'\n-import { useTablesQuery } from 'data/tables/tables-query'\n import { useTablesQuery as useTableRetrieveQuery } from 'data/tables/table-retrieve-query'\n+import { useTablesQuery } from 'data/tables/tables-query'\n import { useQuerySchemaState } from 'hooks/misc/useSchemaQueryState'\n import { useSelectedProjectQuery } from 'hooks/misc/useSelectedProject'\n import { DOCS_URL } from 'lib/constants'\n@@ -306,7 +306,7 @@ export const ForeignKeySelector = ({\n                 <div className=\"flex flex-col gap-y-3\">\n                   <label className=\"text-foreground-light text-sm\">\n                     Select columns from{' '}\n-                    <code className=\"text-xs\">\n+                    <code className=\"text-code-inline\">\n                       {fk.schema}.{fk.table}\n                     </code>{' '}\n                     to reference to\n@@ -421,9 +421,9 @@ export const ForeignKeySelector = ({\n                             if (x === undefined) return null\n                             return (\n                               <li key={`type-error-${idx}`}>\n-                                <code className=\"text-xs\">{fk.columns[idx]?.source}</code> (\n-                                {x.sourceType}) and{' '}\n-                                <code className=\"text-xs\">{fk.columns[idx]?.target}</code>(\n+                                <code className=\"text-code-inline\">{fk.columns[idx]?.source}</code>{' '}\n+                                ({x.sourceType}) and{' '}\n+                                <code className=\"text-code-inline\">{fk.columns[idx]?.target}</code>(\n                                 {x.targetType})\n                               </li>\n                             )\n@@ -444,7 +444,9 @@ export const ForeignKeySelector = ({\n                             return (\n                               <li key={`type-error-${idx}`}>\n                                 <div className=\"flex items-center gap-x-1\">\n-                                  <code className=\"text-xs\">{fk.columns[idx]?.source}</code>{' '}\n+                                  <code className=\"text-code-inline\">\n+                                    {fk.columns[idx]?.source}\n+                                  </code>{' '}\n                                   <ArrowRight size={14} /> {x.targetType}\n                                 </div>\n                               </li>\n@@ -472,18 +474,18 @@ export const ForeignKeySelector = ({\n                         </p>\n                         <ul className=\"mt-2 list-disc pl-4 space-y-1\">\n                           <li>\n-                            <code className=\"text-xs\">Cascade</code>: if the referencing table\n-                            represents something that is a component of what is represented by the\n-                            referenced table and cannot exist independently\n+                            <code className=\"text-code-inline\">Cascade</code>: if the referencing\n+                            table represents something that is a component of what is represented by\n+                            the referenced table and cannot exist independently\n                           </li>\n                           <li>\n-                            <code className=\"text-xs\">Restrict</code> or{' '}\n-                            <code className=\"text-xs\">No action</code>: if the two tables represent\n-                            independent objects\n+                            <code className=\"text-code-inline\">Restrict</code> or{' '}\n+                            <code className=\"text-code-inline\">No action</code>: if the two tables\n+                            represent independent objects\n                           </li>\n                           <li>\n-                            <code className=\"text-xs\">Set NULL</code> or{' '}\n-                            <code className=\"text-xs\">Set default</code>: if a foreign-key\n+                            <code className=\"text-code-inline\">Set NULL</code> or{' '}\n+                            <code className=\"text-code-inline\">Set default</code>: if a foreign-key\n                             relationship represents optional information\n                           </li>\n                         </ul>\ndiff --git a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ForeignKeySelector/ForeignKeySelector.utils.tsx b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ForeignKeySelector/ForeignKeySelector.utils.tsx\nindex 09c6866452085..fcb10df4f84bc 100644\n--- a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ForeignKeySelector/ForeignKeySelector.utils.tsx\n+++ b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/ForeignKeySelector/ForeignKeySelector.utils.tsx\n@@ -33,7 +33,7 @@ export const generateCascadeActionDescription = (\n       return (\n         <>\n           <span className=\"text-foreground-light\">{actionName}</span>: {actionVerb} a record from{' '}\n-          <code className=\"text-xs text-foreground-light\">{reference}</code> will{' '}\n+          <code className=\"text-code-inline\">{reference}</code> will{' '}\n           <span className=\"text-amber-900 opacity-75\">raise an error</span> if there are records\n           existing in this table that reference it\n         </>\n@@ -42,7 +42,7 @@ export const generateCascadeActionDescription = (\n       return (\n         <>\n           <span className=\"text-foreground-light\">{actionName}</span>: {actionVerb} a record from{' '}\n-          <code className=\"text-xs text-foreground-light\">{reference}</code> will{' '}\n+          <code className=\"text-code-inline\">{reference}</code> will{' '}\n           <span className=\"text-amber-900 opacity-75\">also {action}</span> any records that\n           reference it in this table\n         </>\n@@ -60,8 +60,7 @@ export const generateCascadeActionDescription = (\n               the transaction\n             </TooltipContent>\n           </Tooltip>\n-          : {actionVerb} a record from{' '}\n-          <code className=\"text-xs text-foreground-light\">{reference}</code> will{' '}\n+          : {actionVerb} a record from <code className=\"text-code-inline\">{reference}</code> will{' '}\n           <span className=\"text-amber-900 opacity-75\">prevent {actionVerb.toLowerCase()}</span>{' '}\n           existing referencing rows from this table.\n         </>\n@@ -70,8 +69,8 @@ export const generateCascadeActionDescription = (\n       return (\n         <>\n           <span className=\"text-foreground-light\">{actionName}</span>: {actionVerb} a record from{' '}\n-          <code className=\"text-xs text-foreground-light\">{reference}</code> will set the value of\n-          any existing records in this table referencing it to their{' '}\n+          <code className=\"text-code-inline\">{reference}</code> will set the value of any existing\n+          records in this table referencing it to their{' '}\n           <span className=\"text-amber-900 opacity-75\">default value</span>\n         </>\n       )\n@@ -79,8 +78,8 @@ export const generateCascadeActionDescription = (\n       return (\n         <>\n           <span className=\"text-foreground-light\">{actionName}</span>: {actionVerb} a record from{' '}\n-          <code className=\"text-xs text-foreground-light\">{reference}</code> will set the value of\n-          any existing records in this table referencing it{' '}\n+          <code className=\"text-code-inline\">{reference}</code> will set the value of any existing\n+          records in this table referencing it{' '}\n           <span className=\"text-amber-900 opacity-75\">to NULL</span>\n         </>\n       )\ndiff --git a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/ForeignRowSelector/ForeignRowSelector.tsx b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/ForeignRowSelector/ForeignRowSelector.tsx\nindex 9b2c8d2f4192d..b5ea64cd8686b 100644\n--- a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/ForeignRowSelector/ForeignRowSelector.tsx\n+++ b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/RowEditor/ForeignRowSelector/ForeignRowSelector.tsx\n@@ -165,7 +165,7 @@ const ForeignRowSelector = ({\n       header={\n         <div>\n           Select a record to reference from{' '}\n-          <code className=\"font-mono text-sm\">\n+          <code className=\"text-code-inline !text-sm\">\n             {schemaName}.{tableName}\n           </code>\n         </div>\ndiff --git a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/SpreadsheetImport/SpreadsheetImportPreview.tsx b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/SpreadsheetImport/SpreadsheetImportPreview.tsx\nindex bcd5239d338bf..182cfffa420bb 100644\n--- a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/SpreadsheetImport/SpreadsheetImportPreview.tsx\n+++ b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/SpreadsheetImport/SpreadsheetImportPreview.tsx\n@@ -2,14 +2,14 @@ import { AlertCircle, ArrowRight, ChevronDown, ChevronRight } from 'lucide-react\n import { useEffect, useState } from 'react'\n \n import {\n+  Alert_Shadcn_,\n+  AlertDescription_Shadcn_,\n+  AlertTitle_Shadcn_,\n   Badge,\n   Button,\n   cn,\n   Collapsible,\n   SidePanel,\n-  Alert_Shadcn_,\n-  AlertTitle_Shadcn_,\n-  AlertDescription_Shadcn_,\n   WarningIcon,\n } from 'ui'\n import type { SpreadsheetData } from './SpreadsheetImport.types'\n@@ -195,7 +195,7 @@ export const SpreadsheetImportPreview = ({\n                                   <ul className=\"ml-2 list-disc\">\n                                     {errorData.__parsed_extra.map((value: string, i: number) => (\n                                       <li key={i}>\n-                                        <code className=\"text-xs\">{value}</code>\n+                                        <code className=\"text-code-inline\">{value}</code>\n                                       </li>\n                                     ))}\n                                   </ul>\ndiff --git a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/TableEditor/ForeignKeysManagement/ForeignKeyRow.tsx b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/TableEditor/ForeignKeysManagement/ForeignKeyRow.tsx\nindex c0c54d4d1cc80..24bcc5dbbed73 100644\n--- a/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/TableEditor/ForeignKeysManagement/ForeignKeyRow.tsx\n+++ b/apps/studio/components/interfaces/TableGridEditor/SidePanelEditor/TableEditor/ForeignKeysManagement/ForeignKeyRow.tsx\n@@ -96,7 +96,7 @@ export const ForeignKeyRow = ({\n                 {x.source || '[column_name]'}\n               </code>\n               <ArrowRight size={16} />\n-              <code className=\"text-xs\">\n+              <code className=\"text-code-inline\">\n                 {foreignKey.schema}.{foreignKey.table}.{x.target}\n               </code>\n             </div>\ndiff --git a/apps/studio/components/ui/ProjectSettings/DisplayApiSettings.tsx b/apps/studio/components/ui/ProjectSettings/DisplayApiSettings.tsx\nindex 71f99c36a12f4..1a22d603d9192 100644\n--- a/apps/studio/components/ui/ProjectSettings/DisplayApiSettings.tsx\n+++ b/apps/studio/components/ui/ProjectSettings/DisplayApiSettings.tsx\n@@ -127,21 +127,21 @@ export const DisplayApiSettings = ({\n             <FormLayout\n               layout=\"horizontal\"\n               label={\n-                <>\n+                <div className=\"flex items-center space-x-1\">\n                   {x.tags?.split(',').map((x, i: number) => (\n-                    <code key={`${x}${i}`} className=\"text-xs text-code\">\n+                    <code key={`${x}${i}`} className=\"text-code-inline\">\n                       {x}\n                     </code>\n                   ))}\n                   {x.tags === 'service_role' && (\n                     <>\n-                      <code className=\"text-xs text-code !bg-destructive !text-white !border-destructive\">\n+                      <code className=\"text-code-inline !bg-destructive !text-white !border-destructive\">\n                         secret\n                       </code>\n                     </>\n                   )}\n-                  {x.tags === 'anon' && <code className=\"text-xs text-code\">public</code>}\n-                </>\n+                  {x.tags === 'anon' && <code className=\"text-code-inline\">public</code>}\n+                </div>\n               }\n               description={\n                 x.tags === 'service_role' ? (\ndiff --git a/apps/studio/pages/project/[ref]/database/column-privileges.tsx b/apps/studio/pages/project/[ref]/database/column-privileges.tsx\nindex a2921a2cd6c4f..6d28e88b2a3c8 100644\n--- a/apps/studio/pages/project/[ref]/database/column-privileges.tsx\n+++ b/apps/studio/pages/project/[ref]/database/column-privileges.tsx\n@@ -239,7 +239,7 @@ const PrivilegesPage: NextPageWithLayout = () => {\n                   <AlertCircle strokeWidth={2} />\n                   <AlertTitle_Shadcn_>\n                     Changes to column privileges will not be reflected in migrations when running{' '}\n-                    <code className=\"text-xs\">supabase db diff</code>.\n+                    <code className=\"text-code-inline\">supabase db diff</code>.\n                   </AlertTitle_Shadcn_>\n                   <AlertDescription_Shadcn_>\n                     Column privileges are not supported in the current version of the Supabase CLI.\n@@ -269,10 +269,12 @@ const PrivilegesPage: NextPageWithLayout = () => {\n                     If you remove a column privilege for a role, that role will lose all access to\n                     that column.\n                     <br />\n-                    All operations selecting <code className=\"text-xs\">*</code> (including{' '}\n-                    <code className=\"text-xs\">returning *</code> for{' '}\n-                    <code className=\"text-xs\">insert</code>, <code className=\"text-xs\">update</code>\n-                    , and <code className=\"text-xs\">delete</code>) will fail.\n+                    All operations selecting <code className=\"text-code-inline\">\n+                      *\n+                    </code> (including <code className=\"text-code-inline\">returning *</code> for{' '}\n+                    <code className=\"text-code-inline\">insert</code>,{' '}\n+                    <code className=\"text-code-inline\">update</code>, and{' '}\n+                    <code className=\"text-code-inline\">delete</code>) will fail.\n                   </AlertDescription_Shadcn_>\n                   <Button\n                     type=\"outline\"\ndiff --git a/apps/studio/styles/typography.scss b/apps/studio/styles/typography.scss\nindex b432fb93cdf9f..0f2d5569a77f9 100644\n--- a/apps/studio/styles/typography.scss\n+++ b/apps/studio/styles/typography.scss\n@@ -79,6 +79,7 @@\n     @apply truncate cursor-pointer underline underline-offset-4 decoration-foreground-muted/50 hover:decoration-foreground-lighter/80 transition-colors duration-100;\n   }\n \n+  // Pair with `code` elements for semantic consistency, e.g. <code className=\"text-code-inline\">\n   .text-code-inline {\n     @apply break-all text-xs tracking-tight bg-surface-200 border border-muted rounded-md px-1 py-0.5 text-foreground font-medium;\n   }\ndiff --git a/packages/config/ui.config.js b/packages/config/ui.config.js\nindex e017c152208ed..836d8dba4c776 100644\n--- a/packages/config/ui.config.js\n+++ b/packages/config/ui.config.js\n@@ -325,13 +325,6 @@ const uiConfig = {\n         // \"[data-state='closed'] .accordion-content-animation\": {\n         //   animation: 'slideUp 200ms ease-in',\n         // },\n-        '.text-code': {\n-          margin: '0 0.2em',\n-          padding: '0.05em 0.4em 0.05em',\n-          background: 'hsla(0, 0%, 58.8%, 0.1)',\n-          border: '1px solid hsla(0, 0%, 39.2%, 0.2)',\n-          borderRadius: '3px',\n-        },\n         '.no-scrollbar': {\n           /* Hide scrollbar for IE, Edge*/\n           '-ms-overflow-style': 'none',\n@@ -354,10 +347,10 @@ const uiConfig = {\n           'mask-image': 'linear-gradient(to left, white 98%, transparent 100%)',\n         },\n         'input[type=\"number\"]::-webkit-outer-spin-button, input[type=\"number\"]::-webkit-inner-spin-button':\n-          {\n-            '-webkit-appearance': 'none',\n-            margin: '0',\n-          },\n+        {\n+          '-webkit-appearance': 'none',\n+          margin: '0',\n+        },\n       })\n       addVariant('data-open-parent', '[data-state=\"open\"] &')\n       addVariant('data-closed-parent', '[data-state=\"closed\"] &')\ndiff --git a/packages/ui-patterns/src/Toc/toc.tsx b/packages/ui-patterns/src/Toc/toc.tsx\nindex 0b2e8159cf802..315048e9636cd 100644\n--- a/packages/ui-patterns/src/Toc/toc.tsx\n+++ b/packages/ui-patterns/src/Toc/toc.tsx\n@@ -1,11 +1,11 @@\n 'use client'\n \n-import type { TOCItemType } from './server/get-toc'\n-import * as Primitive from './toc-primitive'\n import { type ComponentProps, Fragment, type HTMLAttributes, type ReactNode, useRef } from 'react'\n-import { TocThumb } from './toc-thumb'\n import { cn, ScrollArea, ScrollViewport } from 'ui'\n import { removeAnchor } from 'ui/src/components/CustomHTMLElements/CustomHTMLElements.utils'\n+import type { TOCItemType } from './server/get-toc'\n+import * as Primitive from './toc-primitive'\n+import { TocThumb } from './toc-thumb'\n \n export interface TOCProps {\n   /**\n@@ -139,11 +139,7 @@ function TOCItem({ item }: { item: TOCItemType }) {\n     >\n       {formatTOCHeader(removeAnchor(item.title)).map((x, index) => (\n         <Fragment key={index}>\n-          {x.type === 'code' ? (\n-            <code className=\"text-xs border rounded bg-muted\">{x.value}</code>\n-          ) : (\n-            x.value\n-          )}\n+          {x.type === 'code' ? <code className=\"text-code-inline\">{x.value}</code> : x.value}\n         </Fragment>\n       ))}\n     </Primitive.TOCItem>\n",
			"diffSize": 76469,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "f9d4bd20b92f739e339038a28940f29c7dd2cd6b",
			"message": "chore: compute cost copy on plan change (#40730)",
			"user": "kevcodez",
			"timestamp": "2025-11-24T08:30:03Z",
			"author": {
				"name": "Kevin Grüneberg",
				"email": "k.grueneberg1994@gmail.com",
				"username": "kevcodez"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/Organization/BillingSettings/Subscription/SubscriptionPlanUpdateDialog.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Organization/BillingSettings/Subscription/SubscriptionPlanUpdateDialog.tsx b/apps/studio/components/interfaces/Organization/BillingSettings/Subscription/SubscriptionPlanUpdateDialog.tsx\nindex b5ee00be067c3..d90057c8ef57b 100644\n--- a/apps/studio/components/interfaces/Organization/BillingSettings/Subscription/SubscriptionPlanUpdateDialog.tsx\n+++ b/apps/studio/components/interfaces/Organization/BillingSettings/Subscription/SubscriptionPlanUpdateDialog.tsx\n@@ -352,9 +352,8 @@ export const SubscriptionPlanUpdateDialog = ({\n                           <div className=\"w-[520px] p-6\">\n                             <h3 className=\"font-medium mb-2\">Your new monthly invoice</h3>\n                             <p className=\"prose text-xs mb-2\">\n-                              Paid projects run 24/7 without pausing. First project uses Compute\n-                              Credits; additional projects start at <span translate=\"no\">$10</span>\n-                              /month regardless of usage.{' '}\n+                              First project included. Additional projects cost{' '}\n+                              <span translate=\"no\">$10</span>+/month regardless of activity.{' '}\n                               <Link\n                                 href={`${DOCS_URL}/guides/platform/manage-your-usage/compute`}\n                                 target=\"_blank\"\n@@ -587,17 +586,16 @@ export const SubscriptionPlanUpdateDialog = ({\n                   <div className=\"pb-2\">\n                     <Admonition type=\"note\">\n                       <div className=\"text-sm prose\">\n-                        Paid projects run 24/7 without pausing. First project uses Compute Credits;\n-                        additional projects cost <span translate=\"no\">$10+</span>\n-                        /month regardless of usage.{' '}\n+                        First project included. Additional projects cost{' '}\n+                        <span translate=\"no\">$10</span>+/month regardless of activity.{' '}\n+                        <Link\n+                          href={`${DOCS_URL}/guides/platform/manage-your-usage/compute`}\n+                          target=\"_blank\"\n+                          className=\"underline\"\n+                        >\n+                          Learn more\n+                        </Link>\n                       </div>\n-                      <Link\n-                        href={`${DOCS_URL}/guides/platform/manage-your-usage/compute`}\n-                        target=\"_blank\"\n-                        className=\"underline\"\n-                      >\n-                        Learn more\n-                      </Link>\n                     </Admonition>\n                   </div>\n                 )}\n",
			"diffSize": 2761,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "4766629ccfcc7a9ccd027dbd154b762736c5fbb2",
			"message": "fix: check for modified functions by eszip hash (#40603)",
			"user": "sweatybridge",
			"timestamp": "2025-11-24T06:09:11Z",
			"author": {
				"name": "Han Qiao",
				"email": "sweatybridge@gmail.com",
				"username": "sweatybridge"
			},
			"files": {
				"added": [],
				"modified": ["apps/studio/hooks/branches/useEdgeFunctionsDiff.ts"],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/hooks/branches/useEdgeFunctionsDiff.ts b/apps/studio/hooks/branches/useEdgeFunctionsDiff.ts\nindex 7f8629b974dc7..32133ad80d383 100644\n--- a/apps/studio/hooks/branches/useEdgeFunctionsDiff.ts\n+++ b/apps/studio/hooks/branches/useEdgeFunctionsDiff.ts\n@@ -86,10 +86,10 @@ export const useEdgeFunctionsDiff = ({\n   const {\n     added = [],\n     removed = [],\n-    overlap = [],\n+    modified = [],\n   } = useMemo(() => {\n     if (!currentBranchFunctions || !mainBranchFunctions) {\n-      return { added: [], removed: [], overlap: [] as typeof currentBranchFunctions }\n+      return { added: [], removed: [], modified: [] }\n     }\n \n     const currentFuncs = currentBranchFunctions ?? []\n@@ -97,18 +97,22 @@ export const useEdgeFunctionsDiff = ({\n \n     const added = currentFuncs.filter((c) => !mainFuncs.find((m) => m.slug === c.slug))\n     const removed = mainFuncs.filter((m) => !currentFuncs.find((c) => c.slug === m.slug))\n-    const overlap = currentFuncs.filter((c) => mainFuncs.find((m) => m.slug === c.slug))\n+    const modified = currentFuncs.filter((c) =>\n+      mainFuncs.find(\n+        (m) => m.slug === c.slug && (m.ezbr_sha256 === undefined || m.ezbr_sha256 !== c.ezbr_sha256)\n+      )\n+    )\n \n-    return { added, removed, overlap }\n+    return { added, removed, modified }\n   }, [currentBranchFunctions, mainBranchFunctions])\n \n-  const overlapSlugs = overlap.map((f) => f.slug)\n   const addedSlugs = added.map((f) => f.slug)\n   const removedSlugs = removed.map((f) => f.slug)\n+  const maybeModifiedSlugs = modified.map((f) => f.slug)\n \n   // Fetch function bodies ---------------------------------------------------\n   const currentBodiesQueries = useQueries({\n-    queries: overlapSlugs.map((slug) => ({\n+    queries: maybeModifiedSlugs.map((slug) => ({\n       queryKey: ['edge-function-body', currentBranchRef, slug],\n       queryFn: ({ signal }: { signal?: AbortSignal }) =>\n         getEdgeFunctionBody({ projectRef: currentBranchRef, slug }, signal),\n@@ -118,7 +122,7 @@ export const useEdgeFunctionsDiff = ({\n   })\n \n   const mainBodiesQueries = useQueries({\n-    queries: overlapSlugs.map((slug) => ({\n+    queries: maybeModifiedSlugs.map((slug) => ({\n       queryKey: ['edge-function-body', mainBranchRef, slug],\n       queryFn: ({ signal }: { signal?: AbortSignal }) =>\n         getEdgeFunctionBody({ projectRef: mainBranchRef, slug }, signal),\n@@ -173,12 +177,12 @@ export const useEdgeFunctionsDiff = ({\n   // Build lookup maps --------------------------------------------------------\n   const currentBodiesMap: Record<string, EdgeFunctionBodyData | undefined> = {}\n   currentBodiesQueries.forEach((q, idx) => {\n-    if (q.data) currentBodiesMap[overlapSlugs[idx]] = q.data\n+    if (q.data) currentBodiesMap[maybeModifiedSlugs[idx]] = q.data\n   })\n \n   const mainBodiesMap: Record<string, EdgeFunctionBodyData | undefined> = {}\n   mainBodiesQueries.forEach((q, idx) => {\n-    if (q.data) mainBodiesMap[overlapSlugs[idx]] = q.data\n+    if (q.data) mainBodiesMap[maybeModifiedSlugs[idx]] = q.data\n   })\n \n   const addedBodiesMap: Record<string, EdgeFunctionBodyData | undefined> = {}\n@@ -196,7 +200,7 @@ export const useEdgeFunctionsDiff = ({\n   const functionFileInfo: FunctionFileInfo = {}\n \n   // Process overlapping functions to determine modifications and file info\n-  overlapSlugs.forEach((slug) => {\n+  maybeModifiedSlugs.forEach((slug) => {\n     const currentBody = currentBodiesMap[slug]\n     const mainBody = mainBodiesMap[slug]\n     if (!currentBody || !mainBody) return\n@@ -229,9 +233,8 @@ export const useEdgeFunctionsDiff = ({\n \n     if (hasModifications) {\n       modifiedSlugs.push(slug)\n+      functionFileInfo[slug] = fileInfos\n     }\n-\n-    functionFileInfo[slug] = fileInfos\n   })\n \n   // Add file info for added functions\n",
			"diffSize": 3791,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "a3ec8adeaa8b20d36d96469cdd18fa1b2a1832d7",
			"message": "feat(studio): set email rate limit to 30 when enabling custom SMTP (#40638)",
			"user": "cemalkilic",
			"timestamp": "2025-11-24T04:55:15Z",
			"author": {
				"name": "Cemal Kılıç",
				"email": "cemalkilic@users.noreply.github.com",
				"username": "cemalkilic"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/Auth/SmtpForm/SmtpForm.tsx",
					"apps/studio/components/interfaces/Auth/SmtpForm/SmtpForm.utils.ts"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Auth/SmtpForm/SmtpForm.tsx b/apps/studio/components/interfaces/Auth/SmtpForm/SmtpForm.tsx\nindex bae64905289aa..01be3cbe7dcad 100644\n--- a/apps/studio/components/interfaces/Auth/SmtpForm/SmtpForm.tsx\n+++ b/apps/studio/components/interfaces/Auth/SmtpForm/SmtpForm.tsx\n@@ -149,7 +149,15 @@ export const SmtpForm = () => {\n \n   const onSubmit = (values: SmtpFormValues) => {\n     const { ENABLE_SMTP, ...rest } = values\n-    const payload = ENABLE_SMTP ? rest : defaultDisabledSmtpFormValues\n+    const basePayload = ENABLE_SMTP ? rest : defaultDisabledSmtpFormValues\n+\n+    // When enabling SMTP, set RATE_LIMIT_EMAIL_SENT to 30\n+    // When disabling, backend will handle resetting to default\n+    const isEnablingSmtp = ENABLE_SMTP && !isSmtpEnabled(authConfig)\n+    const payload = {\n+      ...basePayload,\n+      ...(isEnablingSmtp && { RATE_LIMIT_EMAIL_SENT: 30 }),\n+    }\n \n     // Format payload: Convert port to string\n     if (payload.SMTP_PORT) {\ndiff --git a/apps/studio/components/interfaces/Auth/SmtpForm/SmtpForm.utils.ts b/apps/studio/components/interfaces/Auth/SmtpForm/SmtpForm.utils.ts\nindex 40af16727c22e..b7b54b3bb37c4 100644\n--- a/apps/studio/components/interfaces/Auth/SmtpForm/SmtpForm.utils.ts\n+++ b/apps/studio/components/interfaces/Auth/SmtpForm/SmtpForm.utils.ts\n@@ -27,6 +27,5 @@ export const generateFormValues = (config?: Partial<AuthConfig>): Partial<AuthCo\n     SMTP_PASS: '',\n     SMTP_PORT: config?.SMTP_PORT ?? '465',\n     SMTP_MAX_FREQUENCY: config?.SMTP_MAX_FREQUENCY ?? 60,\n-    RATE_LIMIT_EMAIL_SENT: config?.RATE_LIMIT_EMAIL_SENT ?? 30,\n   }\n }\n",
			"diffSize": 1629,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "d990ae840e5421ab1a090115ffea10959ebb5c90",
			"message": "fix(studio): bucket naming (#40722)\n\nfix: bucket naming",
			"user": "dnywh",
			"timestamp": "2025-11-24T04:00:57Z",
			"author": {
				"name": "Danny White",
				"email": "3104761+dnywh@users.noreply.github.com",
				"username": "dnywh"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/Storage/BucketsUpgradePlan.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Storage/BucketsUpgradePlan.tsx b/apps/studio/components/interfaces/Storage/BucketsUpgradePlan.tsx\nindex 2dd500241f506..dc174ce9d6fb1 100644\n--- a/apps/studio/components/interfaces/Storage/BucketsUpgradePlan.tsx\n+++ b/apps/studio/components/interfaces/Storage/BucketsUpgradePlan.tsx\n@@ -7,7 +7,7 @@ import { BUCKET_TYPES } from './Storage.constants'\n export const BucketsUpgradePlan = ({ type }: { type: 'analytics' | 'vector' }) => {\n   return (\n     <ScaffoldSection isFullWidth>\n-      <AlphaNotice type=\"analytics\" />\n+      <AlphaNotice type={type} />\n       <aside className=\"border border-dashed w-full bg-surface-100 rounded-lg px-4 py-10 flex flex-col gap-y-4 items-center text-center gap-1 text-balance\">\n         <Bucket size={24} strokeWidth={1.5} className=\"text-foreground-light\" />\n         <div className=\"flex flex-col gap-y-1 items-center text-center\">\n@@ -19,8 +19,7 @@ export const BucketsUpgradePlan = ({ type }: { type: 'analytics' | 'vector' }) =\n                 : undefined}\n           </h3>\n           <p className=\"text-foreground-light text-sm\">\n-            Upgrade to the Pro plan to use <span className=\"capitalize\">{type}</span> Buckets for\n-            your project\n+            Upgrade to Pro to use {type} buckets for your project\n           </p>\n         </div>\n         <div className=\"flex items-center gap-x-2\">\n",
			"diffSize": 1397,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		},
		{
			"sha": "e235fd1a0557247de9a8500d4c1917397d6e0afe",
			"message": "fix(studio): entity type color contrast (#40723)\n\n* plans\n\n* fix partition entity\n\n* materialised view",
			"user": "dnywh",
			"timestamp": "2025-11-24T03:53:22Z",
			"author": {
				"name": "Danny White",
				"email": "3104761+dnywh@users.noreply.github.com",
				"username": "dnywh"
			},
			"files": {
				"added": [],
				"modified": [
					"apps/studio/components/interfaces/Organization/BillingSettings/Subscription/PlanUpdateSidePanel.tsx",
					"apps/studio/components/ui/EntityTypeIcon.tsx"
				],
				"removed": []
			},
			"diff": "diff --git a/apps/studio/components/interfaces/Organization/BillingSettings/Subscription/PlanUpdateSidePanel.tsx b/apps/studio/components/interfaces/Organization/BillingSettings/Subscription/PlanUpdateSidePanel.tsx\nindex 3ac62d2eab2e2..75d8248812c03 100644\n--- a/apps/studio/components/interfaces/Organization/BillingSettings/Subscription/PlanUpdateSidePanel.tsx\n+++ b/apps/studio/components/interfaces/Organization/BillingSettings/Subscription/PlanUpdateSidePanel.tsx\n@@ -204,13 +204,13 @@ export const PlanUpdateSidePanel = () => {\n                 >\n                   <div className=\"w-full\">\n                     <div className=\"flex items-center space-x-2\">\n-                      <p className=\"text-brand text-sm uppercase\">{plan.name}</p>\n+                      <p className=\"text-brand-link text-sm uppercase\">{plan.name}</p>\n                       {isCurrentPlan ? (\n                         <div className=\"text-xs bg-surface-300 text-foreground-light rounded px-2 py-0.5\">\n                           Current plan\n                         </div>\n                       ) : plan.nameBadge ? (\n-                        <div className=\"text-xs bg-brand-400 text-brand-600 rounded px-2 py-0.5\">\n+                        <div className=\"text-xs bg-brand-300 dark:bg-brand-400 text-brand-600 rounded px-2 py-0.5\">\n                           {plan.nameBadge}\n                         </div>\n                       ) : null}\ndiff --git a/apps/studio/components/ui/EntityTypeIcon.tsx b/apps/studio/components/ui/EntityTypeIcon.tsx\nindex 9114972669e0a..b0110b20404e8 100644\n--- a/apps/studio/components/ui/EntityTypeIcon.tsx\n+++ b/apps/studio/components/ui/EntityTypeIcon.tsx\n@@ -69,8 +69,9 @@ export const EntityTypeIcon = ({\n         'flex items-center justify-center text-xs h-4 w-4 rounded-[2px] font-bold',\n         type === ENTITY_TYPE.FOREIGN_TABLE &&\n           'text-warning-600/80 dark:text-yellow-900 bg-yellow-500',\n-        type === ENTITY_TYPE.MATERIALIZED_VIEW && 'text-purple-1000 bg-purple-500',\n-        type === ENTITY_TYPE.PARTITIONED_TABLE && 'text-foreground-light bg-border-stronger'\n+        type === ENTITY_TYPE.MATERIALIZED_VIEW && 'text-purple-1100 bg-purple-500',\n+        type === ENTITY_TYPE.PARTITIONED_TABLE &&\n+          'text-foreground-light bg-surface-400 dark:bg-border-stronger'\n       )}\n     >\n       {Object.entries(ENTITY_TYPE)\n",
			"diffSize": 2371,
			"diffTruncated": false,
			"filterResult": {
				"included": true
			}
		}
	]
}
